{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLS_sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AS5zhoWCDZ8E",
        "2EWsCZjCQcc9",
        "rkd2LdwKLWtP",
        "RStOLwF_LlTE",
        "NzkEDjxsxHCl",
        "enYnjHWXBVmO",
        "mzUVeNWeDLmy",
        "TTQFQbRLDKmq",
        "ZFb5eO8jBWSf",
        "l1fjCdxgH3aV",
        "t9CsWWXKGk-I",
        "hqbOzGU-It3f",
        "-a7uYOZzPQ2W",
        "wW9A8JM3SRW7"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomMaullin/BLMM-sandbox/blob/master/PLS_sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIMtrhFKB3Ay",
        "colab_type": "text"
      },
      "source": [
        "# PLS implementation in python\n",
        "\n",
        "This code implements the PLS algorithm for estimating the parameters of linear mixed effects models as described in [Bates (2015)](https://www.jstatsoft.org/article/view/v067i01/v67i01.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNFQ0-MpQuBm",
        "colab_type": "text"
      },
      "source": [
        "## Pip Installations\n",
        "\n",
        "Pip install everything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX02P0KvBWJr",
        "colab_type": "code",
        "outputId": "edaa48b3-7070-4219-903f-29c8ad7052b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "source": [
        "!pip install numpy\n",
        "!pip install cvxopt\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install sparse\n",
        "!pip install nilearn\n",
        "!pip install nibabel\n",
        "!pip install dask"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: sparse in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from sparse) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sparse) (1.17.3)\n",
            "Requirement already satisfied: numba>=0.45 in /usr/local/lib/python3.6/dist-packages (from sparse) (0.46.0)\n",
            "Requirement already satisfied: llvmlite>=0.30.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.45->sparse) (0.30.0)\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.17.3)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (2.3.3)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel) (0.98)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.17.3)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (1.1.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4JYRICVBtjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Python Imports\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkTBWbRKQ5ah",
        "colab_type": "text"
      },
      "source": [
        "We need:\n",
        " - `numpy` for matrix handling.\n",
        " - `scipy` for minimising the likelihood.\n",
        " - `cvxopt` for sparse cholesky.\n",
        " - `pandas` for quick reading and writing of csv files.\n",
        " - `os` for basic commandline functions\n",
        " - `time` for timing functions.\n",
        " - `matplotlib` for making displays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tebSlxvBBruv",
        "colab_type": "code",
        "outputId": "48a14d58-5efb-4061-bf96-5507826eda68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import numpy as np\n",
        "import cvxopt\n",
        "from cvxopt import cholmod, umfpack, amd, matrix, spmatrix, lapack\n",
        "import pandas as pd\n",
        "from scipy.optimize import root\n",
        "from scipy.optimize import minimize\n",
        "import scipy.sparse\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import sparse\n",
        "import nibabel as nib\n",
        "import nilearn\n",
        "import sparse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilAB3qmDMHa8",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "This section contains miscellaneous functions used to help the `PLS` function as well as the general manipulation of the Sparse Cholesky decomposition given by `cvxopt`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOtDwtrfQk_Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Sparse Cholesky Decomposition function\n",
        "\n",
        "This function takes in a square matrix **M** and outputs **P** and **L** from it's sparse cholesky decomposition of the form **PAP'=LL**'.\n",
        "\n",
        "Note: P is given as a permutation vector rather than a matrix. Also cholmod.options['supernodal'] must be set to 2.\n",
        " \n",
        "---\n",
        " \n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **M**: The matrix to be sparse cholesky decomposed as an spmatrix from the cvxopt package.\n",
        " - **perm**: Input permutation (*optional*, one will be calculated if not)\n",
        " - **retF**: Return the factorisation object or not\n",
        " - **retP**: Return the permutation or not\n",
        " - **retL**: Return the lower cholesky or not\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpyEbgrhNHzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_chol(M, perm=None, retF=False, retP=True, retL=True):\n",
        "\n",
        "    # Quick check that M is square\n",
        "    if M.size[0]!=M.size[1]:\n",
        "        raise Exception('M must be square.')\n",
        "\n",
        "    if not perm is None:\n",
        "        # Make an expression for the factorisation\n",
        "        F=cholmod.symbolic(M,p=perm)\n",
        "    else:\n",
        "        # Make an expression for the factorisation\n",
        "        F=cholmod.symbolic(M)\n",
        "\n",
        "    # Calculate the factorisation\n",
        "    cholmod.numeric(M, F)\n",
        "\n",
        "    # Empty factorisation object\n",
        "    factorisation = {}\n",
        "\n",
        "    if (retF and retL) or (retF and retP):\n",
        "\n",
        "        # Calculate the factorisation again (buggy if returning L for\n",
        "        # some reason)\n",
        "        F2=cholmod.symbolic(M,p=perm)\n",
        "        cholmod.numeric(M, F2)\n",
        "\n",
        "        # If we want to return the F object, add it to the dictionary\n",
        "        factorisation['F']=F2\n",
        "        \n",
        "    else:\n",
        "      \n",
        "      factorisation['F']=F\n",
        "\n",
        "    if retP:\n",
        "\n",
        "        # Set p to [0,...,n-1]\n",
        "        P = cvxopt.matrix(range(M.size[0]), (M.size[0],1), tc='d')\n",
        "\n",
        "        # Solve and replace p with the true permutation used\n",
        "        cholmod.solve(F, P, sys=7)\n",
        "\n",
        "        # Convert p into an integer array; more useful that way\n",
        "        P=cvxopt.matrix(np.array(P).astype(np.int64),tc='i')\n",
        "\n",
        "        # If we want to return the permutation, add it to the dictionary\n",
        "        factorisation['P']=P\n",
        "\n",
        "    if retL:\n",
        "\n",
        "        # Get the sparse cholesky factor\n",
        "        L=cholmod.getfactor(F)\n",
        "        \n",
        "        # If we want to return the factor, add it to the dictionary\n",
        "        factorisation['L']=L\n",
        "\n",
        "    # Return P and L\n",
        "    return(factorisation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xYlGmnNNnit",
        "colab_type": "text"
      },
      "source": [
        "### Inverse mapping function\n",
        "\n",
        "This function takes in a lower triangular \n",
        "block diagonal matrix, lambda, and maps it to the original vector of parameters, theta.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **Lambda**: The sparse lower triangular block diagonal matrix.\n",
        " \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59GHirQ8OGe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inv_mapping(Lambda):\n",
        "\n",
        "    # List the unique elements of lambda (in the\n",
        "    # correct order; pandas does this, numpy does\n",
        "    # not)\n",
        "    theta = pd.unique(list(cvxopt.spmatrix.trans(Lambda)))\n",
        "    return(theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsYGm--5isJY",
        "colab_type": "text"
      },
      "source": [
        "### Calculate mapping function\n",
        "\n",
        "This function takes in a vector of parameters, theta, and returns indices which maps them the to lower triangular block diagonal matrix, lambda.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **nlevels**: a vector of the number of levels for each grouping factor. e.g. nlevels=[10,2] means there are 10 levels for factor 1 and 2 levels for factor 2.\n",
        " - **nparams**: a vector of the number of variables for each grouping factor. e.g. nparams=[3,4] means there are 3 variables for factor 1 and 4 variables for factor 2.\n",
        "\n",
        "All arrays must be np arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZfxqOUitYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mapping(nlevels, nparams):\n",
        "\n",
        "    # Work out how many factors there are\n",
        "    n_f = len(nlevels)\n",
        "\n",
        "    # Quick check that nlevels and nparams are the same length\n",
        "    if len(nlevels)!=len(nparams):\n",
        "        raise Exception('The number of parameters and number of levels should be recorded for every grouping factor.')\n",
        "\n",
        "    # Work out how many lambda components needed for each factor\n",
        "    n_lamcomps = (np.multiply(nparams,(nparams+1))/2).astype(np.int64)\n",
        "\n",
        "    # Block index is the index of the next un-indexed diagonal element\n",
        "    # of Lambda\n",
        "    block_index = 0\n",
        "\n",
        "    # Row indices and column indices of theta\n",
        "    row_indices = np.array([])\n",
        "    col_indices = np.array([])\n",
        "\n",
        "    # This will have the values of theta repeated several times, once\n",
        "    # for each time each value of theta appears in lambda\n",
        "    theta_repeated_inds = np.array([])\n",
        "    \n",
        "    # Loop through factors generating the indices to map theta to.\n",
        "    for i in range(0,n_f):\n",
        "\n",
        "        # Work out the indices of a lower triangular matrix\n",
        "        # of size #variables(factor) by #variables(factor)\n",
        "        row_inds_tri, col_inds_tri = np.tril_indices(nparams[i])\n",
        "\n",
        "        # Work out theta for this block\n",
        "        theta_current_inds = np.arange(np.sum(n_lamcomps[0:i]),np.sum(n_lamcomps[0:(i+1)]))\n",
        "\n",
        "        # Work out the repeated theta\n",
        "        theta_repeated_inds = np.hstack((theta_repeated_inds, np.tile(theta_current_inds, nlevels[i])))\n",
        "\n",
        "        # For each level of the factor we must repeat the lower\n",
        "        # triangular matrix\n",
        "        for j in range(0,nlevels[i]):\n",
        "\n",
        "            # Append the row/column indices to the running list\n",
        "            row_indices = np.hstack((row_indices, (row_inds_tri+block_index)))\n",
        "            col_indices = np.hstack((col_indices, (col_inds_tri+block_index)))\n",
        "\n",
        "            # Move onto the next block\n",
        "            block_index = block_index + nparams[i]\n",
        "\n",
        "    # Create lambda as a sparse matrix\n",
        "    #lambda_theta = spmatrix(theta_repeated.tolist(), row_indices.astype(np.int64), col_indices.astype(np.int64))\n",
        "\n",
        "    # Return lambda\n",
        "    return(theta_repeated_inds, row_indices, col_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdRkv7PrrgsI",
        "colab_type": "text"
      },
      "source": [
        "### Apply mapping function\n",
        "\n",
        "The below function applies a mapping to a vector of parameters.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **theta**: the vector of theta parameters.\n",
        " - **theta_inds**: A vector specifying how many times each theta parameter should be repeated. For example, if theta=[0.1,0.8,0.3] and theta_inds=[1,1,1,2,3,3], then the values to be mapped into the sparse matrix would be [0.1,0.1,0.1,0.8,0.3,0.3].\n",
        " - **r_inds**: The row indices of the elements mapped into the sparse matrix.\n",
        " - **c_inds**: The column indices of the elements mapped into the sparse matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxUv8_r0rhFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapping(theta, theta_inds, r_inds, c_inds):\n",
        "\n",
        "    return(spmatrix(theta[theta_inds.astype(np.int64)].tolist(), r_inds.astype(np.int64), c_inds.astype(np.int64)))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhb0e2brrVI",
        "colab_type": "text"
      },
      "source": [
        "###Matrix to Vector function\n",
        "\n",
        "This function takes in a (symmetric, square) matrix and half-vectorizes it (i.e. transforms it to a vector of each of the columns of the matrix, below and including the diagonal, stacked on top of one another). Example:\n",
        "\n",
        "$$\\begin{bmatrix} a & b & c \\\\ b & d & e \\\\ c & e & f \\\\\\end{bmatrix} \\rightarrow \\begin{bmatrix} a \\\\ b \\\\ c \\\\ d \\\\ e \\\\ f \\end{bmatrix}$$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MDStAhnrrgU",
        "colab_type": "code",
        "outputId": "aa489d66-01b5-422e-e34a-5dec59bbfab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "def mat2vech(matrix):\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[0])\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[0]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(np.array([matrix[rowinds[perm],colinds[perm]]]).transpose())\n",
        "\n",
        "# Example:\n",
        "matrix1 = np.eye(3,3)\n",
        "print(matrix1*matrix1.transpose())\n",
        "print(mat2vech(matrix1*matrix1.transpose()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS5zhoWCDZ8E",
        "colab_type": "text"
      },
      "source": [
        "## Toy Dataset\n",
        "\n",
        "This section read ins and formats a toy dataset. The files used here were generated in `R` and with **True** values (those with postfix `True`) being those used to generate the data and **Estimated** (those with postfix `REst`) values being the estimates `R`'s `lmer` package generated from this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy39zwuhkn4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a data directory\n",
        "if not os.path.isdir('/Data'):\n",
        "  os.mkdir('/Data')\n",
        "  \n",
        "os.chdir('/Data')\n",
        "\n",
        "# Clone small git repo containg some csv files.\n",
        "if not os.path.isdir('/Data/BLMM-testdata'):\n",
        "  !git clone https://github.com/TomMaullin/BLMM-testdata.git\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EWsCZjCQcc9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Z matrix\n",
        "\n",
        "The below reads in Z and makes an image of Z transpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoKOwHqcEKDT",
        "colab_type": "code",
        "outputId": "6c0f6c59-7893-4631-b2b9-093db20a02de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Read in random effects design matrix and convert it into it's sparse format in\n",
        "# cvxopt.\n",
        "Z_3col=pd.read_csv('/Data/BLMM-testdata/Z_3col.csv',header=None).values\n",
        "Z = cvxopt.spmatrix(Z_3col[:,2].tolist(), (Z_3col[:,0]-1).astype(np.int64), \\\n",
        "                    (Z_3col[:,1]-1).astype(np.int64))\n",
        "\n",
        "# Create an image of Z'\n",
        "imshow(np.array(cvxopt.matrix(cvxopt.spmatrix.trans(Z))), \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fd09d7940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkd2LdwKLWtP",
        "colab_type": "text"
      },
      "source": [
        "### Estimated Random Effects matrix\n",
        "\n",
        "The below reads in the Random effects variance predicted by `R`'s `lmer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqQRAROqdkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in estimated variance\n",
        "RFXVar_REst =pd.read_csv('/Data/BLMM-testdata/estd_rfxvar.csv',header=None).values\n",
        "\n",
        "# The RFX variance was stored in a strange way so we need to reformat slightly\n",
        "RFXVar_REst = spmatrix(RFXVar_REst[RFXVar_REst!=0],[0,0,1,1,2,2,3,3],[0,1,0,1,2,3,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKE_Rr53qeHx",
        "colab_type": "text"
      },
      "source": [
        "### Estimated Theta\n",
        "\n",
        "The below calculates and outputs the `theta` parameter values which `lmer` estimated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeaYoXU0Lnlr",
        "colab_type": "code",
        "outputId": "68f33ff1-625f-4306-e189-7574806b0384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# We now need the Sparse Cholesky decomposition of the RFX variance to obtain \n",
        "# the theta values.\n",
        "f = sparse_chol(RFXVar_REst)\n",
        "\n",
        "# We map the L matrix from the decomposition to theta\n",
        "theta_REst = inv_mapping(f['L'])\n",
        "\n",
        "# This is the desired outcome/theta value of the PLS algorithm. It should match \n",
        "# the R output.\n",
        "print(theta_REst)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.11365482  0.32356815  2.22872418  4.54822071 -0.17500295  0.42370817]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStOLwF_LlTE",
        "colab_type": "text"
      },
      "source": [
        "### Y vector\n",
        "\n",
        "The response vector is read in here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG8eWNdpPQOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=matrix(pd.read_csv('/Data/BLMM-testdata/Y.csv',header=None).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHm6DjdbPTvg",
        "colab_type": "text"
      },
      "source": [
        "### X matrix\n",
        "\n",
        "The fixed effects design matrix is read in here. It consists of an intercept and two random (Gaussian) columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqTKH4n_Po8e",
        "colab_type": "code",
        "outputId": "b7a3c366-7ac1-4755-98ea-3d4925bbf23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X=matrix(pd.read_csv('/Data/BLMM-testdata/X.csv',header=None).values)\n",
        "\n",
        "# Image of the first 20 rows of X\n",
        "imshow(X[1:20,:])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fd051d860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFYAAAD4CAYAAAB2QBFpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niRDrRIh1IsQ6EWKdCLFO/A/Tno1q3pV2hwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_sXGD8qzskp",
        "colab_type": "text"
      },
      "source": [
        "### Number of Levels and Parameters\n",
        "\n",
        "The number of levels is given by a vector with one entry for each grouping factor. e.g. nlevels=[10,2] means there are 10 levels for factor 1 and 2 levels for factor 2. \n",
        "\n",
        "The number of parameters is given by a vector with one entry for each grouping factor. e.g. nparams=[3,4] means there are 3 variables for factor 1 and 4 variables for factor 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e5bUA2DztCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlevels = np.array([20,3])\n",
        "nparams = np.array([2,2])\n",
        "\n",
        "# Number of subjects\n",
        "n = X.size[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0byKXygpCa1P",
        "colab_type": "text"
      },
      "source": [
        "### True b values\n",
        "\n",
        "The true recorded values of the random effects b vector in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzwuuWSdCbCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_True=matrix(pd.read_csv('/Data/BLMM-testdata/true_b.csv',header=None).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvfns6c-CbPd",
        "colab_type": "text"
      },
      "source": [
        "### True beta values\n",
        "\n",
        "The true fixed effects parameters used to generate this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlvolWwvCbbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_True=matrix(pd.read_csv('/Data/BLMM-testdata/true_beta.csv',header=None).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjWoiZtYyuRh",
        "colab_type": "text"
      },
      "source": [
        "### Product Matrices\n",
        "\n",
        "It is useful to calculate all product of matrices before hand as it is both more computationally efficient and also similar to the setting we are interested in. In `cvxopt`, transposing matrices is surprisingly costly in terms of time so even transposes are calculated here to save them having to be recalculated during each iteration of the minimisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMX_8BRYzFhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z tranpose X\n",
        "ZtX=cvxopt.spmatrix.trans(Z)*X\n",
        "\n",
        "# Z tranpose Y\n",
        "ZtY=cvxopt.spmatrix.trans(Z)*Y\n",
        "\n",
        "# X tranpose X\n",
        "XtX=cvxopt.matrix.trans(X)*X\n",
        "\n",
        "# Z tranpose Z\n",
        "ZtZ=cvxopt.spmatrix.trans(Z)*Z\n",
        "\n",
        "# X tranpose Y\n",
        "XtY=cvxopt.matrix.trans(X)*Y\n",
        "\n",
        "# Y tranpose X\n",
        "YtX=cvxopt.matrix.trans(Y)*X\n",
        "\n",
        "# Y transpose Z\n",
        "YtZ=cvxopt.matrix.trans(Y)*Z\n",
        "\n",
        "# X tranpose Z\n",
        "XtZ=cvxopt.matrix.trans(X)*Z\n",
        "\n",
        "# Y tranpose Y\n",
        "YtY=cvxopt.matrix.trans(Y)*Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOHZ6F2DU5e",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the Minimised Log-Likelihood\n",
        "\n",
        "To calculate the minimised log-likelihood the method given by Bates (2015) is used. This involves minimising for a parameter vector theta, a penalized least squares function which is based on the sparse cholesky decomposition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVtC2_vLtsY2",
        "colab_type": "text"
      },
      "source": [
        "### PLS function\n",
        "\n",
        "This function calculates the log likelihood value for parameter vector theta using **P**enalized **L**east **S**quares..\n",
        "\n",
        "---\n",
        "\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **theta**: The parameter estimate.\n",
        " - **ZtX**: Z transpose multiplied by X.\n",
        " - **ZtY**: Z transpose multiplied by Y.\n",
        " - **XtX**: X transpose multiplied by X.\n",
        " - **ZtZ**: Z transpose multiplied by Z.\n",
        " - **XtY**: X transpose multiplied by Y.\n",
        " - **YtX**: Y transpose multiplied by X.\n",
        " - **YtZ**: Y transpose multiplied by Z.\n",
        " - **XtZ**: X transpose multiplied by Z.\n",
        " - **YtY**: Y transpose multiplied by Y.\n",
        " - **P**: The sparse permutation for Lamda'Z'ZLambda+I\n",
        " - **tinds**: A vector specifying how many times each theta parameter should be repeated. For example, if theta=[0.1,0.8,0.3] and theta_inds=[1,1,1,2,3,3], then the values to be mapped into the sparse matrix would be [0.1,0.1,0.1,0.8,0.3,0.3].\n",
        " - **r_inds**: The row indices of the elements mapped into the sparse matrix.\n",
        " - **c_inds**: The column indices of the elements mapped into the sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3bUshSts74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PLS(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds):\n",
        "\n",
        "    # Obtain Lambda\n",
        "    t1 = time.time()\n",
        "    Lambda = mapping(theta, tinds, rinds, cinds)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#3.170967102050781e-05   9\n",
        "    \n",
        "    \n",
        "    # Obtain Lambda'\n",
        "    t1 = time.time()\n",
        "    Lambdat = spmatrix.trans(Lambda)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)# 3.5762786865234375e-06\n",
        "\n",
        "    # Obtain Lambda'Z'Y and Lambda'Z'X\n",
        "    t1 = time.time()\n",
        "    LambdatZtY = Lambdat*ZtY\n",
        "    LambdatZtX = Lambdat*ZtX\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.049041748046875e-05   13\n",
        "    \n",
        "    # Obtain the cholesky decomposition\n",
        "    t1 = time.time()\n",
        "    LambdatZtZLambda = Lambdat*(ZtZ*Lambda)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#3.790855407714844e-05   2\n",
        "    \n",
        "    t1 = time.time()\n",
        "    chol_dict = sparse_chol(LambdatZtZLambda+I, perm=P, retF=True, retP=False, retL=False)\n",
        "    F = chol_dict['F']\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#0.0001342296600341797   1\n",
        "\n",
        "    # Obtain C_u (annoyingly solve writes over the second argument,\n",
        "    # whereas spsolve outputs)\n",
        "    t1 = time.time()\n",
        "    Cu = LambdatZtY[P,:]\n",
        "    cholmod.solve(F,Cu,sys=4)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.5974044799804688e-05   5\n",
        "\n",
        "    # Obtain RZX\n",
        "    t1 = time.time()\n",
        "    RZX = LambdatZtX[P,:]\n",
        "    cholmod.solve(F,RZX,sys=4)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.2159347534179688e-05   7\n",
        "\n",
        "    # Obtain RXtRX\n",
        "    t1 = time.time()\n",
        "    RXtRX = XtX - matrix.trans(RZX)*RZX\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#9.775161743164062e-06  11\n",
        "\n",
        "    # Obtain beta estimates (note: gesv also replaces the second\n",
        "    # argument)\n",
        "    t1 = time.time()\n",
        "    betahat = XtY - matrix.trans(RZX)*Cu\n",
        "    lapack.posv(RXtRX, betahat)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.7404556274414062e-05   6\n",
        "\n",
        "    # Obtain u estimates\n",
        "    t1 = time.time()\n",
        "    uhat = Cu-RZX*betahat\n",
        "    cholmod.solve(F,uhat,sys=5)\n",
        "    cholmod.solve(F,uhat,sys=8)\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.2874603271484375e-05   8\n",
        "    \n",
        "    # Obtain b estimates\n",
        "    t1 = time.time()\n",
        "    bhat = Lambda*uhat\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#2.86102294921875e-06  15\n",
        "    \n",
        "    # Obtain residuals sum of squares\n",
        "    t1 = time.time()\n",
        "    resss = YtY-2*YtX*betahat-2*YtZ*bhat+2*matrix.trans(betahat)*XtZ*bhat+matrix.trans(betahat)*XtX*betahat+matrix.trans(bhat)*ZtZ*bhat\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#3.409385681152344e-05   4\n",
        "    \n",
        "    # Obtain penalised residual sum of squares\n",
        "    t1 = time.time()\n",
        "    pss = resss + matrix.trans(uhat)*uhat\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#2.6226043701171875e-06  16\n",
        "    \n",
        "    # Obtain Log(|L|^2)\n",
        "    t1 = time.time()\n",
        "    logdet = 2*sum(cvxopt.log(cholmod.diag(F)))\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#1.5735626220703125e-05   14\n",
        "    \n",
        "    # Obtain log likelihood\n",
        "    t1 = time.time()\n",
        "    logllh = -logdet/2-n/2*(1+np.log(2*np.pi*pss[0,0])-np.log(n))\n",
        "    t2 = time.time()\n",
        "    #print(t2-t1)#4.506111145019531e-05   3\n",
        "    \n",
        "    return(-logllh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzkEDjxsxHCl",
        "colab_type": "text"
      },
      "source": [
        "## Minimising the Log-Likelihood\n",
        "\n",
        "To minimise the log-likelihood  we use the `scipy optimize` functions on the PLS algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwPiugXwyFpW",
        "colab_type": "code",
        "outputId": "719148db-e616-4341-8c3e-1a5fad21dd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Initial theta value. Bates (2005) suggests using vec(I) where I is the identity matrix\n",
        "theta0=np.array([1,0,1,1,0,1])\n",
        "\n",
        "# Obtain a random Lambda matrix with the correct sparsity for the permutation vector\n",
        "tinds,rinds,cinds=get_mapping(nlevels, nparams)\n",
        "Lam=mapping(np.random.randn(6),tinds,rinds,cinds)\n",
        "\n",
        "# Obtain Lambda'Z'ZLambda\n",
        "LamtZt = spmatrix.trans(Lam)*spmatrix.trans(Z)\n",
        "LamtZtZLam = LamtZt*spmatrix.trans(LamtZt)\n",
        "\n",
        "# Obtaining permutation for PLS\n",
        "P=cvxopt.amd.order(LamtZtZLam)\n",
        "\n",
        "# Identity (Actually quicker to calculate outside of estimation)\n",
        "I = spmatrix(1.0, range(Lam.size[0]), range(Lam.size[0]))\n",
        "\n",
        "# Set cholmod options\n",
        "cholmod.options['supernodal']=2\n",
        "\n",
        "# Obtain estimate using `Nelder-Mead`\n",
        "theta_Est_nm=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='Nelder-Mead', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `Powell`\n",
        "theta_Est_pow=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='Powell', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `CG`\n",
        "theta_Est_cg=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='CG', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `BFGS`\n",
        "theta_Est_bfgs=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='BFGS', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `L-BFGS-B`\n",
        "theta_Est_lbfgsb=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `TNC`\n",
        "theta_Est_tnc=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='TNC', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `COBYLA`\n",
        "theta_Est_cobyla=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='COBYLA', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `SLSQP`\n",
        "theta_Est_slsqp=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='SLSQP', tol=1e-6).x\n",
        "\n",
        "# Obtain estimate using `trust-constr`\n",
        "theta_Est_trcon=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='trust-constr', tol=1e-6).x\n",
        "\n",
        "# Print lmer estimate\n",
        "print('Lmer Estimate')\n",
        "print(theta_REst)\n",
        "\n",
        "# Print estimates\n",
        "print('Nelder-Mead Python Estimate')\n",
        "print(theta_Est_nm)\n",
        "print('Powell Python Estimate')\n",
        "print(theta_Est_pow)\n",
        "print('CG Python Estimate')\n",
        "print(theta_Est_cg)\n",
        "print('BFGS Python Estimate')\n",
        "print(theta_Est_bfgs)\n",
        "print('L-BFGS-B Python Estimate')\n",
        "print(theta_Est_lbfgsb)\n",
        "print('TNC Python Estimate')\n",
        "print(theta_Est_tnc)\n",
        "print('COBYLA Python Estimate')\n",
        "print(theta_Est_cobyla)\n",
        "print('SLSQP Python Estimate')\n",
        "print(theta_Est_slsqp)\n",
        "print('trust-constr Python Estimate')\n",
        "print(theta_Est_trcon)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lmer Estimate\n",
            "[ 1.11365482  0.32356815  2.22872418  4.54822071 -0.17500295  0.42370817]\n",
            "Nelder-Mead Python Estimate\n",
            "[ 1.11126947  0.32242321  2.2240467   4.53967691 -0.17465665  0.42288958]\n",
            "Powell Python Estimate\n",
            "[ 1.11126202  0.32242066  2.22404517  4.53963679 -0.17464939 -0.42289163]\n",
            "CG Python Estimate\n",
            "[ 1.11097483  0.32486049  2.2204823   4.46851015 -0.17170456  0.42445066]\n",
            "BFGS Python Estimate\n",
            "[ 1.1133477   0.32432107  2.23520283  4.73015087 -0.19917473  0.4166644 ]\n",
            "L-BFGS-B Python Estimate\n",
            "[ 1.11069312  0.32626445  2.22179103  4.43127593 -0.17151019  0.42308999]\n",
            "TNC Python Estimate\n",
            "[ 1.317788    0.08469002  2.24681162  3.09562961 -0.04547548  0.38196296]\n",
            "COBYLA Python Estimate\n",
            "[ 1.11129921  0.32238177  2.22400895  4.51698988 -0.17302663  0.42316139]\n",
            "SLSQP Python Estimate\n",
            "[ 1.1119122   0.31467079  2.22144594  4.39343954 -0.16444859  0.42634387]\n",
            "trust-constr Python Estimate\n",
            "[ 1.11011197  0.32224344  2.22245804  4.51683091 -0.1711171   0.42292119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxNYlQkQ_asL",
        "colab_type": "text"
      },
      "source": [
        "### Time efficiency\n",
        "\n",
        "The below runs each method 100 times and works out the average time taken to produce the estimates. In this example, it is clear that `Powell` performs much quicker than `Nelder-Mead`. From now on, in the following sections `Powell` is the default method used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYq_1-3U_nMn",
        "colab_type": "code",
        "outputId": "a8ff8143-9cd6-46ae-cb5c-592ab7816121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Average time\n",
        "time_nm = 0;\n",
        "time_p = 0;\n",
        "time_cg = 0;\n",
        "time_bfgs = 0;\n",
        "time_lbfgsb = 0;\n",
        "time_tnc = 0;\n",
        "time_cobyla = 0;\n",
        "time_slsqp = 0;\n",
        "time_trcon = 0;\n",
        "\n",
        "# Number of iterations\n",
        "n = 10;\n",
        "\n",
        "for i in range(n):\n",
        "  \n",
        "  # Obtain estimate using `Nelder-Mead`\n",
        "  t1 = time.time()\n",
        "  theta_Est_nm=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='Nelder-Mead', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_nm = time_nm + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `Powell`\n",
        "  t1 = time.time()\n",
        "  theta_Est_p=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='Powell', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_p = time_p + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `CG`\n",
        "  t1 = time.time()\n",
        "  theta_Est_cg=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='CG', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_cg = time_cg + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `BFGS`\n",
        "  t1 = time.time()\n",
        "  theta_Est_bfgs=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='BFGS', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_bfgs = time_bfgs + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `L-BFGS-B`\n",
        "  t1 = time.time()\n",
        "  theta_Est_lbfgsb=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_lbfgsb = time_lbfgsb + t2 - t1\n",
        "\n",
        "  # Obtain estimate using `TNC`\n",
        "  t1 = time.time()\n",
        "  theta_Est_tnc=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='TNC', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_tnc = time_tnc + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `COBYLA`\n",
        "  t1 = time.time()\n",
        "  theta_Est_cobyla=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='COBYLA', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_cobyla = time_cobyla + t2 - t1\n",
        "  \n",
        "  # Obtain estimate using `SLSQP`\n",
        "  t1 = time.time()\n",
        "  theta_Est_slsqp=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='SLSQP', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_slsqp = time_slsqp + t2 - t1\n",
        "\n",
        "  # Obtain estimate using `trust-constr`\n",
        "  t1 = time.time()\n",
        "  theta_Est_trcon=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds,rinds, cinds), method='trust-constr', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_trcon = time_trcon + t2 - t1\n",
        "\n",
        "  \n",
        "\n",
        "# Convert to averages\n",
        "time_nm = time_nm/n\n",
        "time_p = time_p/n\n",
        "time_cg = time_cg/n\n",
        "time_bfgs = time_bfgs/n\n",
        "time_lbfgsb = time_lbfgsb/n\n",
        "time_tnc = time_tnc/n\n",
        "time_cobyla = time_cobyla/n\n",
        "time_slsqp = time_slsqp/n\n",
        "time_trcon = time_trcon/n\n",
        "\n",
        "# Print\n",
        "print('Average Nelder-Mead estimation time:')\n",
        "print(time_nm)\n",
        "print('Average Powell estimation time:')\n",
        "print(time_p)\n",
        "print('Average CG estimation time:')\n",
        "print(time_cg)\n",
        "print('Average BFGS estimation time:')\n",
        "print(time_bfgs)\n",
        "print('Average L-BFGS-B estimation time:')\n",
        "print(time_lbfgsb)\n",
        "print('Average TNC estimation time:')\n",
        "print(time_tnc)\n",
        "print('Average COBYLA estimation time:')\n",
        "print(time_cobyla)\n",
        "print('Average SLSQP estimation time:')\n",
        "print(time_slsqp)\n",
        "print('Average trust-contstr estimation time:')\n",
        "print(time_trcon)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Nelder-Mead estimation time:\n",
            "0.25483849048614504\n",
            "Average Powell estimation time:\n",
            "0.047246265411376956\n",
            "Average CG estimation time:\n",
            "0.30346438884735105\n",
            "Average BFGS estimation time:\n",
            "0.17444200515747071\n",
            "Average L-BFGS-B estimation time:\n",
            "0.0746377944946289\n",
            "Average TNC estimation time:\n",
            "0.12482931613922119\n",
            "Average COBYLA estimation time:\n",
            "0.16047990322113037\n",
            "Average SLSQP estimation time:\n",
            "0.05490419864654541\n",
            "Average trust-contstr estimation time:\n",
            "0.3088963747024536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nazpuh-A5vx",
        "colab_type": "text"
      },
      "source": [
        "## Scaling up the computation (Two voxels)\n",
        "\n",
        "This section has several implemented ideas for scaling up the computation to compute several similar models at once. For simplicity it is assumed here that X and Z are the same across voxels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYnjHWXBVmO",
        "colab_type": "text"
      },
      "source": [
        "### Toy data for Neighbouring voxel\n",
        "\n",
        "To assess the potential of the following ideas a toy data example is created below. The idea behind this is that we wish to calculate both the model in the example used in the previous sections and, additionally a similar model from a neighbouring voxel (variables related to the neighbouring voxel will have postfix `_n`). \n",
        "\n",
        "This is not a rigourous test, but just a toy example to see if we can lower the computational time in an example vaguely similar to what we may expect in reality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzUVeNWeDLmy",
        "colab_type": "text"
      },
      "source": [
        "#### Beta vector\n",
        "\n",
        "In a neighbouring voxel, we would expect similar Beta values but not necessarily the same. To simulate this, I have added some normal noise with variance, 1/2, to the original beta values to obtain a new beta value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKzWuueBbeI",
        "colab_type": "code",
        "outputId": "2d61a8bc-0c33-46d7-db77-a94efff3783f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Given a beta vector this function makes a beta \n",
        "# vector for the neighbouring voxel\n",
        "def beta_n(beta):\n",
        "  return(beta + cvxopt.normal(beta.size[0],1)/np.sqrt(2))\n",
        "\n",
        "# Example\n",
        "beta_True_n = beta_n(beta_True)\n",
        "  \n",
        "# print betas for comparison\n",
        "print(\"Beta for voxel 1\")\n",
        "print(beta_True)\n",
        "print(\"Beta for voxel 2\")\n",
        "print(beta_True_n)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beta for voxel 1\n",
            "[ 1]\n",
            "[ 2]\n",
            "[ 3]\n",
            "\n",
            "Beta for voxel 2\n",
            "[ 1.09e+00]\n",
            "[ 1.94e+00]\n",
            "[ 4.18e+00]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTQFQbRLDKmq",
        "colab_type": "text"
      },
      "source": [
        "#### b vector\n",
        "\n",
        "In a neighbouring voxel, we may also expect similar b values. To simulate this, I have added some normal noise with variance, 1/2, to the original b values to obtain a new b value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsyjopBUFNt0",
        "colab_type": "code",
        "outputId": "348e2cfa-5722-485d-9d38-5e1f8f2dad0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Given a b vector this function makes a b\n",
        "# vector for the neighbouring voxel\n",
        "def b_n(b):\n",
        "  return(b + cvxopt.normal(b.size[0],1)/np.sqrt(2))\n",
        "\n",
        "# Example\n",
        "b_True_n = b_n(b_True)\n",
        "  \n",
        "# print bs for comparison\n",
        "print(\"b for voxel 1 (first 5 elements)\")\n",
        "print(b_True[1:5])\n",
        "print(\"b for voxel 2 (first 5 elements)\")\n",
        "print(b_True_n[1:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b for voxel 1 (first 5 elements)\n",
            "[-4.23e+00]\n",
            "[ 1.44e+00]\n",
            "[ 1.41e+00]\n",
            "[ 1.35e+00]\n",
            "\n",
            "b for voxel 2 (first 5 elements)\n",
            "[-4.37e+00]\n",
            "[ 1.13e+00]\n",
            "[ 1.50e+00]\n",
            "[ 1.65e+00]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFb5eO8jBWSf",
        "colab_type": "text"
      },
      "source": [
        " #### Y vector (New response)\n",
        " \n",
        "I now generate a new response vector with the new beta and b values for the neighbouring voxel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V59rDqEGU5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neighbouring voxels response vector\n",
        "Y_n = X*beta_True_n+Z*b_True_n+cvxopt.normal(1000,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fjCdxgH3aV",
        "colab_type": "text"
      },
      "source": [
        "### Product Matrices\n",
        "\n",
        "All products of matrices are calculated beforehand as it is both more computationally efficient and also similar to the setting we are interested in. For the neighbouring voxel only those involving the Y vector (response) need be recalculated as X and Z have not changed between voxel in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnx7aj6OH3tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z tranpose Y_n\n",
        "ZtY_n=cvxopt.spmatrix.trans(Z)*Y_n\n",
        "\n",
        "# X tranpose Y_n\n",
        "XtY_n=cvxopt.matrix.trans(X)*Y_n\n",
        "\n",
        "# Y_n tranpose X\n",
        "YtX_n=cvxopt.matrix.trans(Y_n)*X\n",
        "\n",
        "# Y_n transpose Z\n",
        "YtZ_n=cvxopt.matrix.trans(Y_n)*Z\n",
        "\n",
        "# Y_n tranpose Y_n\n",
        "YtY_n=cvxopt.matrix.trans(Y_n)*Y_n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9CsWWXKGk-I",
        "colab_type": "text"
      },
      "source": [
        "### Idea 1: Initial Estimate\n",
        "\n",
        "The idea behind this is relatively simple. Once we have estimated the model for one voxel, we use the estimated theta vector from that voxel as the initial estimate for it's neighbours.\n",
        "\n",
        "However, it didn't work/no meaningful time improvement was observed in the toy example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5c3WZF5HDm-",
        "colab_type": "code",
        "outputId": "eef5a2ff-a858-43f5-c161-f8c5d852d6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Estimate first voxel\n",
        "theta_Est=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "# Estimate second voxel\n",
        "theta_Est_n=minimize(PLS, theta_Est, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "# Print results\n",
        "print('Estimate for voxel 1')\n",
        "print(theta_Est)\n",
        "\n",
        "# Print results for neighbouring voxel\n",
        "print('Estimate for voxel 2')\n",
        "print(theta_Est_n)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimate for voxel 1\n",
            "[-3.82632372e-07  7.88461899e-09 -8.92650112e-08  1.41769524e-06\n",
            " -4.58399429e-07 -4.63805416e-08]\n",
            "Estimate for voxel 2\n",
            "[-3.79166294e-07 -1.82553801e-08  8.04283532e-08  1.40643049e-06\n",
            " -1.61603437e-07 -1.88357309e-08]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqbOzGU-It3f",
        "colab_type": "text"
      },
      "source": [
        "#### Time efficiency\n",
        "\n",
        "What is really important here is not the estimate values (assuming they are correct), but the time taken to do this for both voxels. In the below, the two voxels are estimated 100 times twice, once reusing the estmate from the first voxel in estimating the second, and once computing the voxels completely seperately.\n",
        "\n",
        "**Conclusion:** This idea didn't really work... the time complexity was not meaningfully reduced (reduction of <0.01s in most runs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OM3CTjNJXp_",
        "colab_type": "code",
        "outputId": "24b13e23-c02b-4bea-e01b-e67892da531c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Average time\n",
        "time_original = 0;\n",
        "time_idea1 = 0;\n",
        "\n",
        "# Number of iterations\n",
        "n = 100;\n",
        "\n",
        "for i in range(n):\n",
        "  \n",
        "  # New neigbouring voxel response\n",
        "  Y_n = X*beta_n(beta_True)+Z*b_n(b_True)+cvxopt.normal(1000,1)\n",
        "  \n",
        "  # Z tranpose Y_n\n",
        "  ZtY_n=cvxopt.spmatrix.trans(Z)*Y_n\n",
        "\n",
        "  # X tranpose Y_n\n",
        "  XtY_n=cvxopt.matrix.trans(X)*Y_n\n",
        "\n",
        "  # Y_n tranpose X\n",
        "  YtX_n=cvxopt.matrix.trans(Y_n)*X\n",
        "\n",
        "  # Y_n transpose Z\n",
        "  YtZ_n=cvxopt.matrix.trans(Y_n)*Z\n",
        "\n",
        "  # Y_n tranpose Y_n\n",
        "  YtY_n=cvxopt.matrix.trans(Y_n)*Y_n\n",
        "  \n",
        "  # Obtain the voxels estimates independently\n",
        "  t1 = time.time()\n",
        "  theta_Est=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  theta_Est_n=minimize(PLS, theta0, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_original = time_original + t2 - t1\n",
        "  \n",
        "  # Obtain the voxels estimates by reusing the estimate from one voxel as the initial estimate for the other\n",
        "  t1 = time.time()\n",
        "  theta_Est=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  theta_Est_n=minimize(PLS, theta_Est, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_idea1 = time_idea1 + t2 - t1\n",
        "\n",
        "# Convert to averages\n",
        "time_original = time_original/n\n",
        "time_idea1 = time_idea1/n\n",
        "\n",
        "# Print\n",
        "print('Average Original estimation time:')\n",
        "print(time_original)\n",
        "print('Average Idea 1 estimation time:')\n",
        "print(time_idea1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Original estimation time:\n",
            "0.06586296558380127\n",
            "Average Idea 1 estimation time:\n",
            "0.05838618516921997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JP8KZC-Mamk",
        "colab_type": "text"
      },
      "source": [
        "### Idea 2: Penalize the difference between beta values in the objective function\n",
        "\n",
        "The PLS algorithm works by penalizing, at every voxel, the objective function:\n",
        "\n",
        "$$||Y-X\\beta+Z\\Lambda u+\\epsilon||^2_2 + ||u||^2_2$$\n",
        "\n",
        "Suppose, now that we wish to estimate the value at one voxel but already have beta values for one of it's neighbours. When the algorithm searches the parameter space, it stands to reason we want it to start by looking at beta values around the neighbouring voxels beta values. To do this we could add an additional term to the objective function:\n",
        "\n",
        "$$||Y-X\\beta+Z\\Lambda u+\\epsilon||^2_2 + ||u||^2_2 + ||\\beta - \\beta_n||^2_2$$\n",
        "\n",
        "Where $\\beta_n$ is the value of beta at the neighbouring voxel. This is the idea tested here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krn-dunmRTZl",
        "colab_type": "text"
      },
      "source": [
        "#### Return Beta from PLS\n",
        "\n",
        "This function returns the beta estimates for a given theta using PLS.\n",
        "\n",
        "---\n",
        "\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **theta**: The parameter estimate.\n",
        " - **ZtX**: Z transpose multiplied by X.\n",
        " - **ZtY**: Z transpose multiplied by Y.\n",
        " - **XtX**: X transpose multiplied by X.\n",
        " - **ZtZ**: Z transpose multiplied by Z.\n",
        " - **XtY**: X transpose multiplied by Y.\n",
        " - **YtX**: Y transpose multiplied by X.\n",
        " - **YtZ**: Y transpose multiplied by Z.\n",
        " - **XtZ**: X transpose multiplied by Z.\n",
        " - **YtY**: Y transpose multiplied by Y.\n",
        " - **P**: The sparse permutation for Lamda'Z'ZLambda+I\n",
        " - **tinds**: A vector specifying how many times each theta parameter should be repeated. For example, if theta=[0.1,0.8,0.3] and theta_inds=[1,1,1,2,3,3], then the values to be mapped into the sparse matrix would be [0.1,0.1,0.1,0.8,0.3,0.3].\n",
        " - **r_inds**: The row indices of the elements mapped into the sparse matrix.\n",
        " - **c_inds**: The column indices of the elements mapped into the sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEUPtjalRQpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PLS_getBeta(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, tinds, rinds, cinds):\n",
        "\n",
        "    # Obtain Lambda\n",
        "    Lambda = mapping(theta, tinds, rinds, cinds)\n",
        "    \n",
        "    # Obtain Lambda'\n",
        "    Lambdat = spmatrix.trans(Lambda)\n",
        "\n",
        "    # Obtain Lambda'Z'Y and Lambda'Z'X\n",
        "    LambdatZtY = Lambdat*ZtY\n",
        "    LambdatZtX = Lambdat*ZtX\n",
        "    \n",
        "    # Set the factorisation to use LL' instead of LDL'\n",
        "    cholmod.options['supernodal']=2\n",
        "\n",
        "    # Obtain the cholesky decomposition\n",
        "    LambdatZtZLambda = Lambdat*ZtZ*Lambda\n",
        "    I = spmatrix(1.0, range(Lambda.size[0]), range(Lambda.size[0]))\n",
        "    chol_dict = sparse_chol(LambdatZtZLambda+I, perm=P, retF=True, retP=False, retL=False)\n",
        "    F = chol_dict['F']\n",
        "\n",
        "    # Obtain C_u (annoyingly solve writes over the second argument,\n",
        "    # whereas spsolve outputs)\n",
        "    Cu = LambdatZtY[P,:]\n",
        "    cholmod.solve(F,Cu,sys=4)\n",
        "\n",
        "    # Obtain RZX\n",
        "    RZX = LambdatZtX[P,:]\n",
        "    cholmod.solve(F,RZX,sys=4)\n",
        "\n",
        "    # Obtain RXtRX\n",
        "    RXtRX = XtX - matrix.trans(RZX)*RZX\n",
        "\n",
        "    # Obtain beta estimates (note: gesv also replaces the second\n",
        "    # argument)\n",
        "    betahat = XtY - matrix.trans(RZX)*Cu\n",
        "    lapack.posv(RXtRX, betahat)\n",
        "\n",
        "    return(betahat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7uYOZzPQ2W",
        "colab_type": "text"
      },
      "source": [
        "#### Neighbour-based PLS objective function\n",
        "\n",
        "The following function calculates the log likelihood based on the above objective function. It is the same as the original PLS algorithm in most respects, except it now also uses as input `beta_n`, the beta value from the run used on a neighbouring voxel. \n",
        "\n",
        "---\n",
        "\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **theta**: The parameter estimate.\n",
        " - **betan**: The beta estimate for a neighbouring voxel.\n",
        " - **ZtX**: Z transpose multiplied by X.\n",
        " - **ZtY**: Z transpose multiplied by Y.\n",
        " - **XtX**: X transpose multiplied by X.\n",
        " - **ZtZ**: Z transpose multiplied by Z.\n",
        " - **XtY**: X transpose multiplied by Y.\n",
        " - **YtX**: Y transpose multiplied by X.\n",
        " - **YtZ**: Y transpose multiplied by Z.\n",
        " - **XtZ**: X transpose multiplied by Z.\n",
        " - **YtY**: Y transpose multiplied by Y.\n",
        " - **P**: The sparse permutation for Lamda'Z'ZLambda+I\n",
        " - **tinds**: A vector specifying how many times each theta parameter should be repeated. For example, if theta=[0.1,0.8,0.3] and theta_inds=[1,1,1,2,3,3], then the values to be mapped into the sparse matrix would be [0.1,0.1,0.1,0.8,0.3,0.3].\n",
        " - **r_inds**: The row indices of the elements mapped into the sparse matrix.\n",
        " - **c_inds**: The column indices of the elements mapped into the sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E1CS6j7P1_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PLSneighbour(theta, betan, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds):\n",
        "\n",
        "    # Neighbour changes, the below is actually all that needs changing to account\n",
        "    # for the new objective function\n",
        "    XtX = XtX+ spmatrix(1.0, range(XtX.size[0]), range(XtX.size[0]))\n",
        "    XtY = XtY + betan\n",
        "    YtX = YtX + matrix.trans(betan)\n",
        "\n",
        "    # Return PLS on the newly adjusted data\n",
        "    return(PLS(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW9A8JM3SRW7",
        "colab_type": "text"
      },
      "source": [
        "#### Correctness\n",
        "\n",
        "To check that we are still estimating the same quantity, here we estimate the neighbour first and then use the beta estimate from the neighbouring voxel to estimate the original toy datasets theta. As can be seen the resultant estimate is still relatively close.\n",
        "\n",
        "Interestingly, the only beta estimate that has changed is the intercept, which `R` had trouble estimating anyway (it took me a while to find a toy dataset were `R` was able to correctly estimate the intercept... it could have just been due to chance/my own p-hacking that it happened in this case). Perhaps this is due to the model I used for this example, in which there is a fixed effects intercept and then an intercept for both grouping factors... this could just be a difficult/impossible model intercept to estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCsbTsTpSRtl",
        "colab_type": "code",
        "outputId": "d35e3666-6caa-406e-ad7a-a4c5b5b91040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Compute theta estimate for neighbouring voxel\n",
        "theta_Est_n=minimize(PLS, theta0, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "# Retrieve beta\n",
        "beta_Est_n = PLS_getBeta(theta_Est_n,ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, tinds, rinds, cinds)\n",
        "\n",
        "# Minimise for the original voxel using the neighbour function\n",
        "theta_Est=minimize(PLSneighbour, theta0, args=(beta_Est_n, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "# Print results\n",
        "print(\"R estimated theta:\")\n",
        "print(theta_REst)\n",
        "print(\"Neighbourhood based estimated theta:\")\n",
        "print(theta_Est)\n",
        "\n",
        "# Print betas\n",
        "print(\"Beta (True)\")\n",
        "print(beta_True)\n",
        "print(\"Beta (R estimated)\")\n",
        "print(PLS_getBeta(theta_REst,ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P,tinds, rinds, cinds))\n",
        "print(\"Beta (Neighbourhood estimated)\")\n",
        "print(PLS_getBeta(theta_Est,ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P,tinds, rinds, cinds))\n",
        "\n",
        "# Double check we get the same as R\n",
        "#print(matrix(pd.read_csv('/Data/BLMM-testdata/estd_beta.csv',header=None).values))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R estimated theta:\n",
            "[ 1.11365482  0.32356815  2.22872418  4.54822071 -0.17500295  0.42370817]\n",
            "Neighbourhood based estimated theta:\n",
            "[ 0.2307727   0.09109081  0.53652211  1.12067893 -0.04111018  0.10321058]\n",
            "Beta (True)\n",
            "[ 1]\n",
            "[ 2]\n",
            "[ 3]\n",
            "\n",
            "Beta (R estimated)\n",
            "[ 1.05e+00]\n",
            "[ 1.98e+00]\n",
            "[ 3.03e+00]\n",
            "\n",
            "Beta (Neighbourhood estimated)\n",
            "[ 1.02e+00]\n",
            "[ 1.98e+00]\n",
            "[ 3.04e+00]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aANxmrO3WIgP",
        "colab_type": "text"
      },
      "source": [
        "To further investigate whether this is a consistent result, I have run the code 100 times with different a neighbouring voxel in each run and recorded the average squared difference between the true value of beta and the estimated value of beta for both the neighbour approach and the original PLS algorithm.\n",
        "\n",
        "**Conclusion**: The previous supposed loss of efficiency was indeed a fluke - after running 100 different neighbouring voxel iterations it has become extremely clear that the added penalty significantly improves accuracy in the toy example. Main points of interest:\n",
        "\n",
        " - The standard PLS algorithm works well for a majority of cases but rarely beats the neighbourhood version. \n",
        " - In some cases the PLS algorithm can massively go wrong estimating the intercept, whereas the neighbourhood method appears more robust to this.\n",
        " - Of course, this is heavily dependent on the simulation and would need more investigation for standard neuroimaging data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3iC0KRtWIqq",
        "colab_type": "code",
        "outputId": "68aac812-70e7-4180-aec0-d3ddab7df634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Average time\n",
        "diff_original = 0;\n",
        "diff_neighbour = 0;\n",
        "\n",
        "# Number of iterations\n",
        "n = 1;\n",
        "\n",
        "for i in range(n):\n",
        "  \n",
        "  # New neigbouring voxel response\n",
        "  beta_True_n = beta_n(beta_True)\n",
        "  Y_n = X*beta_True_n+Z*b_n(b_True)+cvxopt.normal(1000,1)\n",
        "  \n",
        "  #print(beta_True_n)\n",
        "  \n",
        "  # Z tranpose Y_n\n",
        "  ZtY_n=cvxopt.spmatrix.trans(Z)*Y_n\n",
        "\n",
        "  # X tranpose Y_n\n",
        "  XtY_n=cvxopt.matrix.trans(X)*Y_n\n",
        "\n",
        "  # Y_n tranpose X\n",
        "  YtX_n=cvxopt.matrix.trans(Y_n)*X\n",
        "\n",
        "  # Y_n transpose Z\n",
        "  YtZ_n=cvxopt.matrix.trans(Y_n)*Z\n",
        "\n",
        "  # Y_n tranpose Y_n\n",
        "  YtY_n=cvxopt.matrix.trans(Y_n)*Y_n\n",
        "  \n",
        "  # Obtain the voxels estimates independently\n",
        "  theta_Est=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  theta_Est_n=minimize(PLS, theta0, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  \n",
        "  # Get the beta value from seperate calculation\n",
        "  beta_Est_n = PLS_getBeta(theta_Est_n,ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, tinds, rinds, cinds)\n",
        "  \n",
        "  #print(beta_Est_n)\n",
        "  \n",
        "  # Get average difference between estimated and truth\n",
        "  diff_original = np.linalg.norm(np.array(beta_Est_n-beta_True_n))**2 + diff_original\n",
        "  \n",
        "  #print(np.linalg.norm(np.array(beta_Est_n-beta_True_n))**2)\n",
        "  \n",
        "  # Obtain the voxels estimates by using the neighbouring approach\n",
        "  theta_Est= minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  beta_Est = PLS_getBeta(theta_Est,ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P,tinds, rinds, cinds)\n",
        "  theta_Est_n = minimize(PLSneighbour, theta0, args=(beta_Est, ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "  # Get the beta value from seperate calculation\n",
        "  beta_Est_n = PLS_getBeta(theta_Est_n,ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, tinds, rinds, cinds)\n",
        "  \n",
        "  #print(beta_Est_n)\n",
        "  #print(np.linalg.norm(np.array(beta_Est_n-beta_True_n))**2)\n",
        "  \n",
        "  # Get average difference between estimated and truth\n",
        "  diff_neighbour = np.linalg.norm(np.array(beta_Est_n-beta_True_n))**2 + diff_neighbour\n",
        "\n",
        "  #print('')\n",
        "# Convert to averages\n",
        "diff_original = diff_original/n\n",
        "diff_neighbour = diff_neighbour/n\n",
        "\n",
        "# Print\n",
        "print('Average Original squared difference from truth:')\n",
        "print(diff_original)\n",
        "print('Average Idea 2 squared difference from truth:')\n",
        "print(diff_neighbour)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Original squared difference from truth:\n",
            "7.086544577528563\n",
            "Average Idea 2 squared difference from truth:\n",
            "7.086544580078364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAdjGFGxR_3w",
        "colab_type": "text"
      },
      "source": [
        "#### Time efficiency\n",
        "\n",
        "What is important here is the time taken to do this for both voxels. In the below, the two voxels are estimated 100 times twice, once reusing the estmate from the first voxel in estimating the second, and once computing the voxels completely seperately.\n",
        "\n",
        "**Conclusion:** Some significant time improvement was observed when using `Powell` (around 0.07s quicker) but not for `L-BFGS-B`. A more extensive test suite is needed. Also get singular matrices occasionally causing errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8FROJLxR__g",
        "colab_type": "code",
        "outputId": "33a8a2bf-e82c-405b-f2fe-99aa186997ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# Average time\n",
        "time_original = 0;\n",
        "time_idea2 = 0;\n",
        "\n",
        "# Number of iterations\n",
        "n = 100;\n",
        "failureno=0;\n",
        "\n",
        "for i in range(n):\n",
        "  \n",
        "  # New neigbouring voxel response\n",
        "  Y_n = X*beta_n(beta_True)+Z*b_n(b_True)+cvxopt.normal(1000,1)\n",
        "  \n",
        "  # Z tranpose Y_n\n",
        "  ZtY_n=cvxopt.spmatrix.trans(Z)*Y_n\n",
        "\n",
        "  # X tranpose Y_n\n",
        "  XtY_n=cvxopt.matrix.trans(X)*Y_n\n",
        "\n",
        "  # Y_n tranpose X\n",
        "  YtX_n=cvxopt.matrix.trans(Y_n)*X\n",
        "\n",
        "  # Y_n transpose Z\n",
        "  YtZ_n=cvxopt.matrix.trans(Y_n)*Z\n",
        "\n",
        "  # Y_n tranpose Y_n\n",
        "  YtY_n=cvxopt.matrix.trans(Y_n)*Y_n\n",
        "  \n",
        "  # Obtain the voxels estimates independently\n",
        "  t1 = time.time()\n",
        "  theta_Est=minimize(PLS, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n,P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  theta_Est_n=minimize(PLS, theta0, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  t2 = time.time()\n",
        "  time_original = time_original + t2 - t1\n",
        "  \n",
        "  # Obtain the voxels estimates by using the neighbouring approach\n",
        "  t1 = time.time()\n",
        "  theta_Est_n=minimize(PLS, theta0, args=(ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  beta_Est_n = PLS_getBeta(theta_Est_n,ZtX, ZtY_n, XtX, ZtZ, XtY_n, YtX_n, YtZ_n, XtZ, YtY_n, n, P, tinds, rinds, cinds)\n",
        "  try:\n",
        "    theta_Est=minimize(PLSneighbour, theta0, args=(beta_Est_n, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "    t2 = time.time()\n",
        "    time_idea2 = time_idea2 + t2 - t1\n",
        "  except:\n",
        "    print(\"Voxel that failed, number:\")\n",
        "    print(i)\n",
        "    failureno = failureno + 1\n",
        "\n",
        "# Convert to averages\n",
        "time_original = time_original/n\n",
        "time_idea2 = time_idea2/n\n",
        "\n",
        "# Print\n",
        "print('Average Original estimation time:')\n",
        "print(time_original)\n",
        "print('Average Idea 2 estimation time:')\n",
        "print(time_idea2)\n",
        "\n",
        "print('Number of Failures')\n",
        "print(failureno)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Voxel that failed, number:\n",
            "3\n",
            "Voxel that failed, number:\n",
            "30\n",
            "Average Original estimation time:\n",
            "0.06446826219558716\n",
            "Average Idea 2 estimation time:\n",
            "0.06548320293426514\n",
            "Number of Failures\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBr0APoAXKl3",
        "colab_type": "text"
      },
      "source": [
        "## Scaling up the computation (Random field)\n",
        "\n",
        "This section has several implemented ideas for scaling up the computation to compute several similar models at once. For simplicity it is assumed here that X and Z are the same across voxels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5XoW6q2NaJ20"
      },
      "source": [
        "### Toy dataset (for a random field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LTG_EYiZpjM",
        "colab_type": "text"
      },
      "source": [
        "#### Matrix Dimensions\n",
        "\n",
        "Below are the matrix dimensions used for **one voxel** in this example. If the model has form:\n",
        "\n",
        "$$Y=X\\beta+Zb+\\epsilon$$ With $\\epsilon \\sim N(0,\\sigma^2I_n)$ and $b \\sim N(0,\\sigma^2D)$, then the dimensions of each matrix are as follows:\n",
        "\n",
        " - $Y$: $(n \\times 1)$\n",
        " - $X$: $(n \\times p)$\n",
        " - $\\beta$: $(p \\times 1)$\n",
        " - $Z$: $(n \\times q)$\n",
        " - $b$: $(q \\times 1)$\n",
        " - $\\epsilon$: $(n \\times 1)$\n",
        " - $D$: $(p\\times p)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LAfqqiCXO4k",
        "colab_type": "code",
        "outputId": "857eae25-6f71-4f19-d580-67c9d24628dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Number of factors, random integer between 1 and 3\n",
        "r = np.random.randint(2,4)#np.random.randint(1,4)\n",
        "print(\"Number of grouping factors for random effects:\")\n",
        "print(r)\n",
        "\n",
        "# Number of levels, random number between 2 and 8\n",
        "nlevels = np.random.randint(2,8,size=(r))\n",
        "# Let the first number of levels be a little larger (typically like subjects)\n",
        "nlevels[0] = np.random.randint(2,35,size=1)\n",
        "nlevels = np.sort(nlevels)[::-1]\n",
        "print(\"Number of levels for each factor:\")\n",
        "print(nlevels)\n",
        "\n",
        "# Number of parameters, random number between 1 and 5\n",
        "nparams = np.random.randint(1,6,size=(r))\n",
        "print(\"Number of parameters for each factor:\")\n",
        "print(nparams)\n",
        "\n",
        "# Dimension of D\n",
        "print(\"Dimension of D, q:\")\n",
        "q = np.sum(nlevels*nparams)\n",
        "print(q)\n",
        "\n",
        "# Number of fixed effects, random number between 6 and 30\n",
        "p = np.random.randint(6,31)\n",
        "print(\"Number of fixed effects:\")\n",
        "print(p)\n",
        "\n",
        "# Number of subjects, n\n",
        "n = 1000\n",
        "print(\"Number of subjects:\")\n",
        "print(n)\n",
        "\n",
        "# Voxel dimensions\n",
        "dimv = [30,30,30]\n",
        "nv = np.prod(dimv)\n",
        "print(\"Number of voxels:\")\n",
        "print(nv)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of grouping factors for random effects:\n",
            "2\n",
            "Number of levels for each factor:\n",
            "[4 4]\n",
            "Number of parameters for each factor:\n",
            "[5 3]\n",
            "Dimension of D, q:\n",
            "32\n",
            "Number of fixed effects:\n",
            "17\n",
            "Number of subjects:\n",
            "1000\n",
            "Number of voxels:\n",
            "27000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57CJIErlbDS5",
        "colab_type": "text"
      },
      "source": [
        "#### Fixed Effects matrix (X)\n",
        "\n",
        "For simplicity, in this example $X$ is the same for all voxels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wnJHsOxdUne",
        "colab_type": "code",
        "outputId": "cf1bc616-7158-4c05-8a7e-071dbdcb4948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Initialize empty x\n",
        "X = np.zeros((n,p))\n",
        "\n",
        "# First column is intercept\n",
        "X[:,0] = 1\n",
        "\n",
        "# Rest of the columns we will make random noise \n",
        "X[:,1:] = np.random.randn(n*(p-1)).reshape((n,(p-1)))\n",
        "\n",
        "# Image of the last 20 rows of X\n",
        "imshow(X[-20:-1,:])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fcbcc5358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD4CAYAAADrYdqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngBRckQApuCIBUnBFAqTgigTo/wFYSbpBtS1degAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaBzkwl0ekWr",
        "colab_type": "text"
      },
      "source": [
        "#### Random Effects matrix (Z)\n",
        "\n",
        "For simplicity, in this example $Z$ is the same for all voxels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb1S4WdhepI9",
        "colab_type": "code",
        "outputId": "584c1f91-0596-422b-c643-9e9a5576268b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# We need to create a block of Z for each level of each factor\n",
        "for i in np.arange(r):\n",
        "  \n",
        "  Zdata_factor = np.random.randn(n,nparams[i])\n",
        "  \n",
        "  if i==0:\n",
        "    \n",
        "    #The first factor should be block diagonal, so the factor indices are grouped\n",
        "    factorVec = np.repeat(np.arange(nlevels[i]), repeats=np.floor(n/max(nlevels[i],1)))\n",
        "    \n",
        "    if len(factorVec) < n:\n",
        "      \n",
        "      # Quick fix incase rounding leaves empty columns\n",
        "      factorVecTmp = np.zeros(n)\n",
        "      factorVecTmp[0:len(factorVec)] = factorVec\n",
        "      factorVecTmp[len(factorVec):n] = nlevels[i]-1\n",
        "      factorVec = np.int64(factorVecTmp)\n",
        "      \n",
        "    \n",
        "    # Crop the factor vector - otherwise have a few too many\n",
        "    factorVec = factorVec[0:n]\n",
        "    \n",
        "    # Give the data an intercept\n",
        "    Zdata_factor[:,0]=1\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # The factor is randomly arranged across subjects\n",
        "    factorVec = np.random.randint(0,nlevels[i],size=n) \n",
        "  \n",
        "  # Build a matrix showing where the elements of Z should be\n",
        "  indicatorMatrix_factor = np.zeros((n,nlevels[i]))\n",
        "  indicatorMatrix_factor[np.arange(n),factorVec] = 1\n",
        "  \n",
        "  # Need to repeat for each parameter the factor has \n",
        "  indicatorMatrix_factor = np.repeat(indicatorMatrix_factor, nparams[i], axis=1)\n",
        "  \n",
        "  # Enter the Z values\n",
        "  indicatorMatrix_factor[indicatorMatrix_factor==1]=Zdata_factor.reshape(Zdata_factor.shape[0]*Zdata_factor.shape[1])\n",
        "  \n",
        "  # Make sparse\n",
        "  Zfactor = scipy.sparse.csr_matrix(indicatorMatrix_factor)\n",
        "\n",
        "  # Put all the factors together\n",
        "  if i == 0:\n",
        "    Z = Zfactor\n",
        "  else:\n",
        "    Z = scipy.sparse.hstack((Z, Zfactor))\n",
        "\n",
        "\n",
        "Z2 = sparse.COO.from_scipy_sparse(Z)\n",
        "\n",
        "# Create an image of Z\n",
        "imshow(Z.toarray(), \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n",
        "print(nlevels)\n",
        "print(nparams)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 4]\n",
            "[5 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTqsJgFrYP85",
        "colab_type": "text"
      },
      "source": [
        "#### Smooth random beta\n",
        "Smooth random beta image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUeftuE-YQjP",
        "colab_type": "code",
        "outputId": "4e9738d3-3d62-4075-b8a6-3705e9d75b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Random 4D matrix (unsmoothed)\n",
        "beta_us = np.random.randn(nv*p).reshape(dimv[0],dimv[1],dimv[2],p)*20\n",
        "beta_us[10:15,10:15,10:15,3] = beta_us[10:15,10:15,10:15,3] + 100\n",
        "\n",
        "t1 = time.time()\n",
        "# Some random affine, not important for this simulation\n",
        "affine = np.diag([1, 1, 1, 1])\n",
        "beta_us_nii = nib.Nifti1Image(beta_us, affine)\n",
        "\n",
        "# Smoothed beta nifti\n",
        "beta_s_nii = nilearn.image.smooth_img(beta_us_nii, 5)\n",
        "\n",
        "# Final beta\n",
        "beta = beta_s_nii.get_fdata()\n",
        "\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "# Show unsmoothed\n",
        "imshow(beta_us[10,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "\n",
        "plt.colorbar()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.042746543884277344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9fcbbbea58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAD5CAYAAAD/ViQ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOs4ge-_zgIr",
        "colab_type": "code",
        "outputId": "4f11c024-6bfd-4a11-c966-4712df70739c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Show smoothed\n",
        "imshow(beta[10,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9fcbaf3470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD5CAYAAACEcub7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbvUlEQVR4nO3db4xc1XkG8OfZ8a7X2NCADK5rnJgg\n1BaliqlWJBWoJUlJ3SgSIFUIPiAqRTEfghRUPhTxJVRqJVQFKB8iqqVYGIk/QQWKFdEQCyFRpIpg\nXMf8MSkUmWLH2Cwmsg3Y+2eefpjrZmK8c96ZOXv2+vr5oRGzd8/ee+bO+t0z5773PZQEMzMrY2Sx\nO2Bmdjpx0DUzK8hB18ysIAddM7OCHHTNzApy0DUzK2jJMD9McgOAewG0APyLpDt7tR/jUo1j+TCH\nrA4caRJpFGgzkmk/TPx9ixynqSLnL5LaGMl+DO0nUxpl5C2NvPaUkq87U5tIquphHZySdG76gPP7\ni68t14cH55LtXtl57FlJG4Y5VtTAQZdkC8CPAFwJYA+Al0lukfTGfD8zjuX4Cr+R2nH62K1Wus2S\nwEsbHU3vZyzSZix9rPGlPb+twHGwJP26QyL/cObaeY7VSn+Y0ki6DSN9nplN72d6Jr2f2fQ/0pDA\na0fgdzmpHXivAq9JM4Fzc+xYej+Bc6y5dH+2Hn343XSHevvw4Bx+/uznk+1aq99aOeyxooaZXrgU\nwNuS3pE0DeAxAFfl6ZaZ2fAEoB34r6RhphfWAHiv6+s9AL4yXHfMzPIRhBll+uSSyVBzuhEkNwLY\nCADjOGOhD2dm9ltKj2RThgm6ewGs7fr6/Grbb5E0CWASAM7iOS70YGbFCMJczerLDDOn+zKAi0he\nQHIMwHUAtuTplplZHm0o+Shp4JGupFmSNwN4Fp2UsU2SXk/+YCo7IZVaFW0TuSKeI10HyJNGU7O/\nxtkEXlcoMyFyhb5kWlTJ350c+8j1+xXKHAocK5K1cTTQnwQBmCscVFOGmtOV9AyAZzL1xcwsu9Ij\n2ZQFv5BmZrZYBGCmZp8iHXTNrLEENWt6wcys1gTM1SvmOuiaWXN17kirFwddM2swYi5UeagcB10z\na6zOhbTTOegyUCEskIPLSPWmkmUbI3Lk6ZbMH40I5dcG9tMO3BsfyfeNVAdrZ8oJDuSBh46V48Nv\n6Dhpkbx1Rar3Bdow0udD6SYpnTzd0znompkV1j6tR7pmZgV5pGtmVpBAzNVsVTIHXTNrNE8vmJkV\nIhDTyrTMVSb1GnebmWXUuTliJPlIITlO8uckf0HydZJ/V22/gORLJN8m+eOqzG1PhUe6TJZ0C5Vb\njJRtjJSOy1VGMsuKrpkWi4yk05UsgRhJvwoIpRhFjpWrRGSm14U6ffSNlG0MrXydKV0zk0wX0o4B\n+LqkIyRHAbxI8t8B/A2AeyQ9RvKfAXwHwH29duSRrpk1lkTMaST5SO9HknSk+nK0egjA1wH8a7V9\nM4CrU/ty0DWzRmuDyUcEyRbJHQAOANgK4H8A/FrSbNVkDzoL9vbkC2lm1lidC2mhMLeS5Lauryer\n9R1/sy9pDsB6kp8D8BSAPxikTw66ZtZYxy+kBUxJmgjtU/o1yecB/AmAz5FcUo12T7o474k8vWBm\njTYnJh8pJM+tRrgguQzAlQB2AXgewF9VzW4E8HRqXx7pmlljZbwjbTWAzSRb6AxWH5f0E5JvAHiM\n5N8D+C8AD6R2VD7oplJ/WgVTUiLpVZH9RCpONVGk8lck1StXilYkpW4uXYlMkf0EsFWjqnCR39FI\nm8C/GS2JpGuWSxlrB7ITUiTtBHDJSba/A+DSfvblka6ZNVan4E29BkUOumbWWAIxU7PbgB10zayx\nJIRufijJQdfMGix+80MpDrpm1liCR7pmZkU16kIayd0ADgOYAzAbvaNjaKHUlsDkeaSqUmghvgzH\nypWuE0oNSjdhZD+hhSBn021CKWN5Us8Uqp6WpxKZIgtuplKnIlXuAmmNoQ/Ykfc8W5WxMoFQYCOL\nmH9N0lSG/ZiZZdVZgr1eH+jr1Rszs6xYu4Uphx3jC8DPSL5CcmOODpmZ5SJ07khLPUoadqR7uaS9\nJM8DsJXkm5Je6G5QBeONADCOM4Y8nJlZfxo10pW0t/r/AXTqS37mHmRJk5ImJE2McnyYw5mZ9UVi\n7Ua6Ax+N5HKSZx5/DuCbAF7L1TEzs2F1LqS1ko+ShpleWAXgqWqhuiUAHpH00yy9MjPLgs25OaIq\nafbljH3pCK30G8ldrFEOLgLl7kbTfWmPpdtoNJDLGzh/jJRtnEnnoY4cDZy/6Zn0sZAn3zeymm0g\nkzeYN5yhRGSmPF0FftcZWik502rThXQupNVrTtcpY2bWaI26I83MrM6aekeamVltBRemLMZB18wa\nSwJm2g66ZmZFdKYXHHTNzIqp2x1pRYMuSTCVGpWtJGNgP5lWSI2kYKVSwtrj6bdi7oyxZJuZFYHU\ns6WBFKNAalXrWDrFaPTjdKpX68h0ss3IkWPJNkR6P6F0ptBqwHlWDE6nngXKQ0YuFOUqyRhoE0rL\nK7QacK6UMZJrATyEzv0JAjAp6V6SdwD4LoAPqqa3S3qm17480jWzBss2vTAL4FZJ26s7cV8hubX6\n3j2SfhjdkYOumTVajjXSJO0DsK96fpjkLgBrBtlXvWaYzcwy6mQvtJKPfpBcB+ASAC9Vm24muZPk\nJpJnp37eQdfMGuv4zRGpB4CVJLd1PU5aH5zkCgBPALhF0iEA9wG4EMB6dEbCd6X65OkFM2u04PTC\nVGqNR5Kj6ATchyU9CQCS9nd9/34AP0kdyEHXzBorY/YCATwAYJeku7u2r67mewHgGgTK25YNuiQ4\nNtq7TSQdbDSxj+B+Iqvr5kqj0ZLex4qkgx1dmW7z6Tnp1zRzVrq/7cBvRitQQWzpr9M7WjaVbjMe\nSN0bOZRsEqueFqi2FaqjFakylkpPi+wjUokssnpxIFWOzLDCMYKrE2eSKXvhMgA3AHiV5I5q2+0A\nrie5Hp1fid0AbkrtyCNdM2ssiZjNEHQlvYiT/63omZN7Mg66ZtZorjJmZlaIi5ibmRXmoGtmVoiL\nmJuZFZbjNuCciqeMYbR32lNo0cnIgpKR/URkWmQvlTI2c2b6NX1yXvo1HVmb7sv0eemFIEeWpauD\ntT9J93np++n0vrnAgptsL022GQ8slIm5dJvIP1FGUhJDFc169yeSxpVlAczgftQOpINFFrgMrDOa\ngwTMuoi5mVk5nl4wMyvEc7pmZoXJQdfMrJzT+0KamVlBkud0zcwKIuacvWBmVs4pN6dLchOAbwM4\nIOlL1bZzAPwYwDp0ypldK+mj5NEYWKW3ZEnGSB5lpjapFYOnz0y/7k9WBUoyfvGTZJuvfOF/k23W\nLku/ne99mlyZBNvPSicOfzy3PNlm7OP0+GD0cDoneMmxdI5yaDXgXKvZJv49cDZP7rFmA4mxGfKK\ngVjZy8iKwTnUsfZCZNz9IIANJ2y7DcBzki4C8Fz1tZlZvajztyT1KCkZdCW9AODgCZuvArC5er4Z\nwNWZ+2VmlkUbTD5KGnROd1XXEhXvA1g1X8NqgbeNADDeWjHg4czM+qcaXkgbujeShB7TOJImJU1I\nmhgbWTbs4czM+nLKTS/MYz/J1UBnYTYAB/J1ycwsH4nJR0mDBt0tAG6snt8I4Ok83TEzy6czkq1X\n0I2kjD0K4AoAK0nuAfADAHcCeJzkdwC8C+Dahezkgmln+lwRSRlLlHacXZZ+46fPTqcy/eHv7U+2\nue68nyfb/NHY+8k2b86sTLY5OvtnyTY7P1iXbDP9q/T4oD0WSDcMrCqcSu8DAJb63RnJk8YVEnpN\nmVIoC6WMAfVLGUsGXUnXz/Otb2Tui5lZdjnmbEmuBfAQOkkDAjAp6d5B7lmo12U9M7OMBKLdHkk+\nAmYB3CrpYgBfBfA9khdjgHsWHHTNrNEUeCT3Ie2TtL16fhjALgBrMMA9C669YGbNpXDthZUkt3V9\nPSlp8mQNSa4DcAmAl9DHPQvHOeiaWbPF5nSnJE2kGpFcAeAJALdIOtRdQ0KSSCaP5ukFM2u0XClj\nJEfRCbgPS3qy2tz3PQvlR7qpS4mRS40FU1uySaTItAPZTu2l6ZSxc8ePJNt8cXQq2ebC0fQt23P4\nMNlm1bJDyTYKvK52IuUOQGwZ37rJ8O9BoepggcppkQpigWOVqiAWIQDtwArGKey8qAcA7JJ0d9e3\njt+zcCeC9yx4esHMmksA8uTpXgbgBgCvktxRbbsdA9yz4KBrZo2W4wOtpBcx/2epvu5ZcNA1s2Yr\nXNAmxUHXzBqsfG2FFAddM2s2j3TNzAoRoAzZCzmVDboClEhdKXp62oE0mkBVqlDFqUSbVmC9xNan\n6b7s++SsZJs3p5M3zWAU+5JtfjmT3s++T38n2YZH0/lyrelkk+D7kH7PGUmvypVumDpWpIJYpI3S\nr0mh/QRS2NJ7ybewZ8jpHHTNzErz9IKZWUEOumZmheS7OSIbB10za7TSC0+mOOiaWbOd1tkLZmaF\npYstluWga2bNFV0aoqDCeboCZmcTTQIl/ApO0jBUNi+d3zhytPfrHjuSzqNcOpXOZ31r73nJNo+0\nvpps8/nlB5NtfhXIwd2193eTbZZ+mH7PRz8O5NdOR8oXZsrBjewnIpE3rEguea5yqJEc3FwrDxdD\nX0gzMyvqtB7pmpmVlulDSS4OumbWXM7TNTMry9kLZmYl1SzoejVgM7OCkiNdkpsAfBvAAUlfqrbd\nAeC7AD6omt0u6ZnQEVMl5iIZKZEUmUyl48RAacfpdF3GkY+P9vz++IdjyX2s2DuebKPWsmSbnYfW\nJdv84ozzk21wLJ3CtvRAus0Z76ffz7FDw6flAYiV88yWVpahVGJo5euaqVmf6za9EBnpPghgw0m2\n3yNpffWIBVwzs5KEzm3AqUcAyU0kD5B8rWvbHST3ktxRPb6V2k8y6Ep6AUA6U97MrI4UeMQ8iAwD\n0GHmdG8mubOK/mcPsR8zswVDpR8RuQaggwbd+wBcCGA9gH0A7pqvIcmNJLeR3DatTwc8nJnZgPKN\ndOfT1wB0oKArab+kOUltAPcDuLRH20lJE5Imxpi+yGNmllUs6K48PjisHhuDew8PQI8bKE+X5GpJ\nx1cuvAbAa73am5kthj6mD6YkTfS7f0n7//9Y5P0AfpL6mUjK2KMArkDnL8EeAD8AcAXJ9ej8jdgN\n4KZwLwMpWFnkqrwUuHFb7XRqED/u/bpHp9J//84cSV9lbU2nU8+OBqp6zY0vTbZhIENr9Ej6HC/7\nKH3+Rg+n0/I4E3gfMlXbiqSDhSqEpfoTWMU3JPC7g1Y6vS9ynV+RvM+SaWULWMR8kAFo8l+6pOtP\nsvmBPvtmZrYocuXp5hqA+jZgM2u2TEE31wDUQdfMmquPlLBSHHTNrNkcdM3MymHNipi7ypiZWUEe\n6ZpZs53W0wsksCRxyEheYq4c3EiuZa6VhxP9YaAUZToDFxgJrIi79KP0294ei6zKHOjPTLo/Sz5O\nJ/y2Pg3k6UZKKWZaXTeUg5tj5dxcv3+ZcnBDJVMjbSKvazrdJH0cX0gzMyvLQdfMrCAHXTOzMoj6\nZS846JpZc3lO18ysMAddM7OCTuugS4Ct3qlIUiDdJJSKE0j7ybWiayB9KJlilDgvQPrcAcCSwGsa\n+WQ02Uajee6biXy0C5VkDLTBTKDWZGSl38h7nmOlXyBPicNI2caIQFoZAk0Y6U/B0o6eXjAzK8lB\n18ysEDl7wcysLI90zczK8ZyumVlJDrpmZoX8Zon12igfdBMViGKrjZ6CUulDkVSm6UClrZF0qtdI\n5FiB9LRs1aQibWYDaWWBNqH0vsj5KZUOFhE5TiSNK/J+RkRSzwp95me5Q4V5pGtmjVa3oOuVI8ys\n2RR4BJDcRPIAyde6tp1DcivJt6r/n53aj4OumTVbpqAL4EEAG07YdhuA5yRdBOC56uueHHTNrLmq\nKmOpR2hX0gsADp6w+SoAm6vnmwFcndqP53TNrNliQXUlyW1dX09Kmgz83CpJ+6rn7wNYlfoBB10z\na7TgbcBTkiaGOY4kkelxczLoklwL4CF0IrjQ+QtwL8lzAPwYwDoAuwFcK+mjQM9SHU/uIpfIYpDK\nlUaTElkkM5I2Fai0FUrLK5gyxkjKU2QhyEjKWKg6WKab9XNV/yqFuWYbA+ev4MTmAmcv7Ce5WtI+\nkqsBHEj9QOSlzwK4VdLFAL4K4HskL8YAE8hmZkVFLqINF5S3ALixen4jgKdTP5AMupL2SdpePT8M\nYBeANRhgAtnMrLh8KWOPAvhPAL9Pcg/J7wC4E8CVJN8C8OfV1z31NadLch2ASwC8hAEmkM3MSsp5\nR5qk6+f51jf62U846JJcAeAJALdIOtQ9H9prApnkRgAbAWC8taKfvpmZDS10zaCg0HQ2yVF0Au7D\nkp6sNu+vJo7RawJZ0qSkCUkTYyPLcvTZzCxm4ed0+5YMuuwMaR8AsEvS3V3f6nsC2cystFw3R+QS\nmV64DMANAF4luaPadjs6E8aPV5PJ7wK4dmG6aGY2hHrNLqSDrqQXMX9qZ18TyJCg2cCKrYH9JEVy\nJCMrDyswA5Mht1iB/FHOTKf3E3jdkexRKlCeL5dIKcVInm6kbGPkvQrlqwb6kyPvNZIznCu3PXKs\nXLm8pfLfUb8qY74jzcyazUHXzKwQrwZsZlaOV44wMyutYD2XCAddM2s0j3TNzEo57VcDFoAcKWOR\ntJVIylhg1dJsqxOnUsIipR0Dh8nVX4bS8jKl04VW1i2YOhUqyZgnpS5VXlSBSpSh9LVc70OpVLmM\nfCHNzKwgB10zs1IEX0gzMyvJF9LMzEpy0DUzK8M3R5iZlSTVroh54ZQxQZGKUgkMZetkqpIVSSsL\nvKmpFqHqVznS7QAw8JqyVYEqWE0qcqyi6/PmWC05kr4WSSuLBJ5cqxfXbRXkesVcj3TNrNk8vWBm\nVooQG+UHkNwN4DA6ny1mJU0Msh8HXTNrtrwj3a9JmhpmBw66ZtZodZteqNdN0mZmmbGt5CNIAH5G\n8hWSGwftj0e6ZtZc8SpjK0lu6/p6UtLkCW0ul7SX5HkAtpJ8U9IL/XapfNBNVdOKpNlE2kQyxnKl\nM0VSsAJVxJIif5FDFbsyfd7K9V7lahORq6JZLonXFaoaF6q6l+s9z/PhmJEKdTmOg2DFPGAqdWFM\n0t7q/wdIPgXgUgB9B11PL5hZs7UDjwSSy0meefw5gG8CeG2Q7nh6wcwaLTjSTVkF4Kmq/vESAI9I\n+ukgO3LQNbPmyrRyhKR3AHx5+D056JpZo53utRfMzEpzEXMzs0JUv+V6ktkLJNeSfJ7kGyRfJ/n9\navsdJPeS3FE9vrXw3TUz65OUfhQUGenOArhV0vYqZeIVklur790j6Yd9HTGVbxnJ34uUjgvlfmbK\nmAvkQCbLKUbe+Mif7MjrzlV6L5QvXTArsWSOcimBnGEGznG2Vx343SmVgxtWs7c8GXQl7QOwr3p+\nmOQuAGsWumNmZjmw5M0uAX39SSK5DsAlAF6qNt1McifJTSTPztw3M7PhCFlujsgpHHRJrgDwBIBb\nJB0CcB+ACwGsR2ckfNc8P7eR5DaS26Z1NEOXzcxiCIFKP0oKBV2So+gE3IclPQkAkvZLmpPUBnA/\nOvchf4akSUkTkibGOJ6r32ZmMTW7kBbJXiCABwDsknR31/bVXc2uwYD3IZuZLaiaBd1I9sJlAG4A\n8CrJHdW22wFcT3I9OrMmuwHctCA9NDMb1PE53RqJZC+8iJNXmHum76OR4NhY7zaRdKaRQCnFoiuS\nBvoz2vvbjPQ314qukfMXKVeZK3WvqEhqXo1WMI6kXwVGamSG0qKnqLplL/iONDNrsPLTBykOumbW\nXIKDrplZUfWaXXDQNbNmK52Hm+Kga2bN5qBrZlaIBMzVa36hbNAdITi+NNEmkCITSekpueor08dS\nKr0qksalSJWx9PmLVKUquvpurvezZiOaLBXfcp2biLqtlJxLzX4vPNI1s2Zz0DUzK0SoXQ3lmlUb\nNjPLSZ1pudQjgOQGkr8k+TbJ2wbtkUe6ZtZcQpYLaSRbAH4E4EoAewC8THKLpDf63ZdHumbWbHmq\njF0K4G1J70iaBvAYgKsG6Y6Drpk1W56guwbAe11f78GAy5YVThkbgZYv69mEuSa9I6kts4HKS5lS\nnpItSqbr1G7hwEzpYJGPkbmuZOdaADS1n5IpY5Hfr8CxVKtsgXBQXUlyW9fXk5ImF6JHntM1s+YS\nooOVKUkTPb6/F8Darq/Pr7b1rWZDHjOzzPJML7wM4CKSF5AcA3AdgC2DdMcjXTNrsDy3AUuaJXkz\ngGfRWbVgk6TXB9mXg66ZNZcABfNwk7uSnsEgK+acwEHXzJqtZnekOeiaWbPVKpvCQdfMmkyqXWW0\nskGXBEZ7HzL0NykwMc7ZwH5akdzYTH8lc6xO3M6zMmxIydKOEZH3IVeuc8k85tqtltxbKAe3Zh/n\nPdI1MytG0Fy9lp930DWz5qphaUcHXTNrtkwpY7k46JpZYwmAPNI1MytE8kjXzKykul1IY8kybCQ/\nAPBu16aVAKaKdSAP93nhnWr9BdznhfAFSecOswOSP0XndaZMSdowzLGiigbdzxyc3JYop1Y77vPC\nO9X6C7jPFufSjmZmBTnompkVtNhBd0GWw1hg7vPCO9X6C7jPFrSoc7pmZqebxR7pmpmdVhYt6JLc\nQPKXJN8medti9aMfJHeTfJXkjhNWDq0NkptIHiD5Wte2c0huJflW9f+zF7OP3ebp7x0k91bneQfJ\nby1mH7uRXEvyeZJvkHyd5Per7XU+x/P1ubbnuckWZXqBZAvAfwO4Ep31418GcL2kN4p3pg8kdwOY\nkFTb3EaSfwrgCICHJH2p2vaPAA5KurP6A3e2pL9dzH4eN09/7wBwRNIPF7NvJ0NyNYDVkraTPBPA\nKwCuBvDXqO85nq/P16Km57nJFmukeymAtyW9I2kawGMArlqkvjSKpBcAHDxh81UANlfPN6PzD64W\n5ulvbUnaJ2l79fwwgF0A1qDe53i+PtsiWKyguwbAe11f78Gp8UsgAD8j+QrJjYvdmT6skrSvev4+\ngFWL2Zmgm0nurKYfavNRvRvJdQAuAfASTpFzfEKfgVPgPDeNL6T153JJfwzgLwF8r/pofEpRZz6p\n7ikr9wG4EMB6APsA3LW43fkskisAPAHgFkmHur9X13N8kj7X/jw30WIF3b0A1nZ9fX61rdYk7a3+\nfwDAU+hMk5wK9lfzesfn9w4scn96krRf0pw6a2ffj5qdZ5Kj6ASvhyU9WW2u9Tk+WZ/rfp6barGC\n7ssALiJ5AckxANcB2LJIfQkhuby6CAGSywF8E8BrvX+qNrYAuLF6fiOApxexL0nHg1flGtToPJMk\ngAcA7JJ0d9e3anuO5+tznc9zky3azRFVeso/AWgB2CTpHxalI0Ekv4jO6BbolMR8pI59JvkogCvQ\nqay0H8APAPwbgMcBfB6dKm/XSqrFxat5+nsFOh95BWA3gJu65ksXFcnLAfwHgFcBHC/Uejs6c6R1\nPcfz9fl61PQ8N5nvSDMzK8gX0szMCnLQNTMryEHXzKwgB10zs4IcdM3MCnLQNTMryEHXzKwgB10z\ns4L+D6o/G8nBneGnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vabjCMt0eMq",
        "colab_type": "text"
      },
      "source": [
        "#### Smooth random b\n",
        "Smooth random b image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bSmo7Af0ecp",
        "colab_type": "code",
        "outputId": "ef0ec041-e752-4c4d-bb22-4784dd532788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Random 4D matrix (unsmoothed)\n",
        "b_us = np.random.randn(nv*q).reshape(dimv[0],dimv[1],dimv[2],q)*20\n",
        "\n",
        "# Some random affine, not important for this simulation\n",
        "affine = np.diag([1, 1, 1, 1])\n",
        "b_us_nii = nib.Nifti1Image(b_us, affine)\n",
        "\n",
        "# Smoothed beta nifti\n",
        "b_s_nii = nilearn.image.smooth_img(b_us_nii, 5)\n",
        "\n",
        "# Final beta\n",
        "b = b_s_nii.get_fdata()\n",
        "\n",
        "# Show unsmoothed\n",
        "imshow(b_us[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fcbae6358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXEPETmY0w4z",
        "colab_type": "code",
        "outputId": "425d8d6a-e4b3-4661-f964-cd6ccbb21588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Show smoothed\n",
        "imshow(b[3,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fcba3c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQKFo4ABQqP8DdunjNwM0/yQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzdoPEEm6eUC",
        "colab_type": "text"
      },
      "source": [
        " #### Y vector (New response)\n",
        " \n",
        "Generate response for the whole field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQokPoYh6eoY",
        "colab_type": "code",
        "outputId": "c9486b6b-ac09-4c0e-86ad-0fdecf5a4689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "# Reshape X\n",
        "X = X.reshape(1, X.shape[0], X.shape[1])\n",
        "\n",
        "# Reshape beta\n",
        "beta = beta.reshape(beta.shape[0]*beta.shape[1]*beta.shape[2],beta.shape[3],1)\n",
        "\n",
        "# Reshape Z (note: This step is slow because of the sparse to dense conversion;\n",
        "# it could probably be made quicker but this is only for one simulation at current)\n",
        "Ztmp = Z.toarray().reshape(1, Z.shape[0], Z.shape[1])\n",
        "\n",
        "# Reshape b\n",
        "b = b.reshape(b.shape[0]*b.shape[1]*b.shape[2],b.shape[3],1)\n",
        "\n",
        "print(X.shape)\n",
        "print(Ztmp.shape)\n",
        "print(beta.shape)\n",
        "print(b.shape)\n",
        "\n",
        "# Generate Y\n",
        "Y = np.matmul(X,beta)+np.matmul(Ztmp,b) + np.random.randn(n,1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1000, 17)\n",
            "(1, 1000, 32)\n",
            "(27000, 17, 1)\n",
            "(27000, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Laa68OGOvyw",
        "colab_type": "text"
      },
      "source": [
        "Check Y looks reasonable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lTEeBqSOz1B",
        "colab_type": "code",
        "outputId": "55760e8b-c8e6-4080-ef7f-11b82fb98ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print(Y.shape)\n",
        "\n",
        "Y_imageformat = Y.reshape((dimv[0],dimv[1],dimv[2],n))\n",
        "\n",
        "imshow(Y_imageformat[10,:,:,1].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27000, 1000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9fcba17eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABSKAg4AhaKAA0ChKOAAUCgKOAAU6v8AA3wMv/F+6uIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MhOA6XP-op",
        "colab_type": "text"
      },
      "source": [
        "#### Transpose products\n",
        "\n",
        "Calculate X'Y, X'Z, X'Y, Y'Y, Y'Z, Y'X Z'Z, Z'X and Z'Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCFYLn3sQVU2",
        "colab_type": "code",
        "outputId": "7dabd339-fca6-45d9-cf37-56fac5eeaadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# X'Z\\Z'X\n",
        "XtZ = np.matmul(X.transpose(0,2,1),Ztmp)\n",
        "ZtX = XtZ.transpose(0,2,1)\n",
        "\n",
        "# Z'Y\\Y'Z\n",
        "YtZ = np.matmul(Y.transpose(0,2,1),Ztmp)\n",
        "ZtY = YtZ.transpose(0,2,1)\n",
        "\n",
        "# Y'X/X'Y\n",
        "YtX = np.matmul(Y.transpose(0,2,1),X)\n",
        "XtY = YtX.transpose(0,2,1)\n",
        "\n",
        "# YtY\n",
        "YtY = np.matmul(Y.transpose(0,2,1),Y)\n",
        "\n",
        "# ZtZ\n",
        "ZtZ = np.matmul(Ztmp.transpose(0,2,1),Ztmp)\n",
        "\n",
        "# X'X\n",
        "XtX = np.matmul(X.transpose(0,2,1),X)\n",
        "\n",
        "\n",
        "print(XtZ.shape)\n",
        "print(ZtX.shape)\n",
        "\n",
        "print(XtY.shape)\n",
        "print(YtX.shape)\n",
        "\n",
        "print(YtZ.shape)\n",
        "print(ZtY.shape)\n",
        "\n",
        "print(XtX.shape)\n",
        "\n",
        "print(YtY.shape)\n",
        "\n",
        "print(ZtZ.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 17, 32)\n",
            "(1, 32, 17)\n",
            "(27000, 17, 1)\n",
            "(27000, 1, 17)\n",
            "(27000, 1, 32)\n",
            "(27000, 32, 1)\n",
            "(1, 17, 17)\n",
            "(27000, 1, 1)\n",
            "(1, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYxYXW3AUu3H",
        "colab_type": "text"
      },
      "source": [
        "### Demonstration: Time taken just looping\n",
        "\n",
        "This is a demonstration showing how long PLS takes when doing each voxel seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgah7SUnUt5k",
        "colab_type": "code",
        "outputId": "565dd8af-321f-49d4-a0f9-816b047e6ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Initialize empty estimates\n",
        "beta_est = np.zeros(beta.shape)\n",
        "\n",
        "# Initialize temporary X'X, X'Z, Z'X and Z'Z\n",
        "XtZtmp = matrix(XtZ[0,:,:])\n",
        "ZtXtmp = matrix(ZtX[0,:,:])\n",
        "ZtZtmp = cvxopt.sparse(matrix(ZtZ[0,:,:]))\n",
        "XtXtmp = matrix(XtX[0,:,:])\n",
        "\n",
        "# Initial theta value. Bates (2005) suggests using [vech(I_q1),...,vech(I_qr)] where I is the identity matrix\n",
        "theta0 = np.array([])\n",
        "for i in np.arange(r):\n",
        "  theta0 = np.hstack((theta0, mat2vech(np.eye(nparams[i])).reshape(np.int64(nparams[i]*(nparams[i]+1)/2))))\n",
        "  \n",
        "# Obtain a random Lambda matrix with the correct sparsity for the permutation vector\n",
        "tinds,rinds,cinds=get_mapping(nlevels, nparams)\n",
        "Lam=mapping(np.random.randn(theta0.shape[0]),tinds,rinds,cinds)\n",
        "\n",
        "# Obtain Lambda'Z'ZLambda\n",
        "LamtZtZLam = spmatrix.trans(Lam)*cvxopt.sparse(matrix(ZtZtmp))*Lam\n",
        "\n",
        "\n",
        "# Identity (Actually quicker to calculate outside of estimation)\n",
        "I = spmatrix(1.0, range(Lam.size[0]), range(Lam.size[0]))\n",
        "\n",
        "# Obtaining permutation for PLS\n",
        "P=cvxopt.amd.order(LamtZtZLam)\n",
        "\n",
        "demo = False\n",
        "\n",
        "if demo:\n",
        "  \n",
        "  nv_tmp = beta.shape[0]\n",
        "  \n",
        "else:\n",
        "  \n",
        "  nv_tmp = 5\n",
        "\n",
        "t1 = time.time()\n",
        "for i in np.arange(nv_tmp):\n",
        "  \n",
        "  print(i)\n",
        "  \n",
        "  XtYtmp = matrix(XtY[i,:,:]) \n",
        "  ZtYtmp = matrix(ZtY[i,:,:]) \n",
        "  YtYtmp = matrix(YtY[i,:,:]) \n",
        "  YtZtmp = matrix(YtZ[i,:,:])\n",
        "  YtXtmp = matrix(YtX[i,:,:])\n",
        "  \n",
        "  theta_est = minimize(PLS, theta0, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6)\n",
        "  nit = theta_est.nit\n",
        "  theta_est = theta_est.x\n",
        "  print(nit)\n",
        "  \n",
        "  # Get current beta\n",
        "  beta_current = PLS_getBeta(theta_est, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P,tinds, rinds, cinds)\n",
        "  \n",
        "  beta_est[i,:,:] = beta_current[:]\n",
        "  \n",
        "t2 = time.time()\n",
        "print(\"Time taken in seconds for this example:\")\n",
        "print(t2-t1)\n",
        "print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "print(100*100*100*(t2-t1)/(nv_tmp*60*60))\n",
        "\n",
        "print(\"True beta (3)\")\n",
        "\n",
        "if demo:\n",
        "  beta_map=beta.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "  beta_est_map=beta_est.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "  # Show true beta, 3rd x-slice, 3rd parameter\n",
        "  imshow(beta_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "77\n",
            "1\n",
            "79\n",
            "2\n",
            "101\n",
            "3\n",
            "159\n",
            "4\n",
            "90\n",
            "Time taken in seconds for this example:\n",
            "2.8321022987365723\n",
            "Estimated time taken for this example on a nifti of size (100x100x100), in hours:\n",
            "157.33901659647623\n",
            "True beta (3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQyp_7qj56-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if demo:\n",
        "  print(\"Estimated beta (3)\")\n",
        "\n",
        "  # Show estimated beta, 3rd x-slice, 3rd parameter\n",
        "  imshow(beta_est_map[3,:,:,3].reshape(10,10), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "  plt.colorbar()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzs1yhAt6WTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if demo:\n",
        "  # Sanity check, lets look at the differences\n",
        "  imshow((beta_est_map[3,:,:,3]-beta_map[3,:,:,3]).reshape(10,10), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "  plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jr5TiVBqzbD",
        "colab_type": "text"
      },
      "source": [
        "Now lets try the same but with Dask delayed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBHSWUbNqwvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "f60cef2e-61a6-4a33-fede-eb78d5a764b2"
      },
      "source": [
        "import dask\n",
        "\n",
        "@dask.delayed\n",
        "def minPLS(theta0, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds):\n",
        "  \n",
        "  theta_est = minimize(PLS, theta0, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6)\n",
        "  nit = theta_est.nit\n",
        "  print(nit)\n",
        "  theta_est = theta_est.x\n",
        "  \n",
        "  return(theta_est)\n",
        "\n",
        "@dask.delayed\n",
        "def getBeta(theta_est, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P,tinds, rinds, cinds, beta_est, i):\n",
        "\n",
        "  beta_est = copy(beta_est)\n",
        "  beta_current = PLS_getBeta(theta_est, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P,tinds, rinds, cinds)\n",
        "  beta_est[i,:,:] = beta_current[:]\n",
        "  \n",
        "  return(beta_est)\n",
        "  \n",
        "# Initialize empty estimates\n",
        "beta_est = np.zeros(beta.shape)\n",
        "t1 = time.time()\n",
        "for i in np.arange(beta.shape[0]):\n",
        "  \n",
        "  theta_est = minPLS(theta0, ZtXtmp, matrix(ZtY[i,:,:]), XtXtmp, ZtZtmp, matrix(XtY[i,:,:]), matrix(YtX[i,:,:]), matrix(YtZ[i,:,:]), XtZtmp, matrix(YtY[i,:,:]), n, P, I, tinds, rinds, cinds)\n",
        "  \n",
        "  # Get current beta\n",
        "  beta_est = getBeta(theta_est, ZtXtmp, matrix(ZtY[i,:,:]), XtXtmp, ZtZtmp, matrix(XtY[i,:,:]), matrix(YtX[i,:,:]), matrix(YtZ[i,:,:]), XtZtmp, matrix(YtY[i,:,:]), n, P,tinds, rinds, cinds, beta_est, i)\n",
        "  \n",
        "beta_est.compute()\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"Time taken in seconds for this example:\")\n",
        "print(t2-t1)\n",
        "print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "print(100*100*100*(t2-t1)/(nv*60*60))\n",
        "\n",
        "print(\"True beta (3)\")\n",
        "beta_map=beta.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "beta_est_map=beta_est.reshape(dimv[0],dimv[1],dimv[2],beta.shape[1])\n",
        "\n",
        "\n",
        "# Show true beta, 3rd x-slice, 3rd parameter\n",
        "imshow(beta_map[3,:,:,3].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-292b25eb9816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m# Get current beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mbeta_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetBeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZtXtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZtY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtXtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZtZtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtZtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mbeta_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/delayed.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         return call_function(self._obj, self._key, args, kwargs,\n\u001b[0;32m--> 598\u001b[0;31m                              pure=self._pure, nout=self._nout)\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/delayed.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(func, func_token, args, kwargs, pure, nout)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     graph = HighLevelGraph.from_collections(name, {name: task},\n\u001b[0;32m--> 577\u001b[0;31m                                             dependencies=collections)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0mnout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36mfrom_collections\u001b[0;34m(cls, name, layer, dependencies)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, dependencies)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHighLevelGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Inline the cache checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDkUiAca6p5G",
        "colab_type": "text"
      },
      "source": [
        "Now, let's try the neighbour method, see how the results change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFyOOob6qtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "for i in np.arange(beta.shape[0]):\n",
        "  \n",
        "  XtYtmp = matrix(XtY[i,:,:]) \n",
        "  ZtYtmp = matrix(ZtY[i,:,:]) \n",
        "  YtYtmp = matrix(YtY[i,:,:]) \n",
        "  YtZtmp = matrix(YtZ[i,:,:])\n",
        "  YtXtmp = matrix(YtX[i,:,:])\n",
        "  \n",
        "  if i==0:\n",
        "    theta_est = minimize(PLS, theta0, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  else:\n",
        "    theta_est = minimize(PLSneighbour, theta0, args=(beta_current, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "\n",
        "  # Get current beta\n",
        "  beta_current = PLS_getBeta(theta_est, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P,tinds, rinds, cinds)\n",
        "  beta_est[i,:,:] = beta_current[:]\n",
        "  \n",
        "t2 = time.time()\n",
        "print(\"Time taken in seconds for this example:\")\n",
        "print(t2-t1)\n",
        "print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "print(1000*(t2-t1)/(60*60))\n",
        "\n",
        "# Lets look at the differences\n",
        "beta_map=beta.reshape(10,10,10,beta.shape[1])\n",
        "beta_est_map=beta_est.reshape(10,10,10,beta.shape[1])\n",
        "imshow((beta_est_map[3,:,:,3]-beta_map[3,:,:,3]).reshape(10,10), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfeS68Db9J1v",
        "colab_type": "text"
      },
      "source": [
        "Lets try checking the re-used starting point method.\n",
        "\n",
        "**Conclusion:** The added penalty had neglible effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8nM3SJC9KAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "for i in np.arange(beta.shape[0]):\n",
        "  XtYtmp = matrix(XtY[i,:,:]) \n",
        "  ZtYtmp = matrix(ZtY[i,:,:]) \n",
        "  YtYtmp = matrix(YtY[i,:,:]) \n",
        "  YtZtmp = matrix(YtZ[i,:,:])\n",
        "  YtXtmp = matrix(YtX[i,:,:])\n",
        "  \n",
        "  if i==0:\n",
        "    theta_est = minimize(PLS, theta0, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "  else:\n",
        "    theta_est = minimize(PLS, theta_est, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=1e-6).x\n",
        "    \n",
        "  # Get current beta\n",
        "  beta_current = PLS_getBeta(theta_est, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P,tinds, rinds, cinds)\n",
        "  beta_est[i,:,:] = beta_current[:]\n",
        "  \n",
        "t2 = time.time()\n",
        "print(\"Time taken in seconds for this example:\")\n",
        "print(t2-t1)\n",
        "print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "print(1000*(t2-t1)/(60*60))\n",
        "\n",
        "# Lets look at the differences\n",
        "beta_map=beta.reshape(10,10,10,beta.shape[1])\n",
        "beta_est_map=beta_est.reshape(10,10,10,beta.shape[1])\n",
        "imshow((beta_est_map[3,:,:,3]-beta_map[3,:,:,3]).reshape(10,10), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x78FGBZoIYEI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Conclusion:** Often marked improvement in terms of time efficiency!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KowcFHBSSAIa",
        "colab_type": "text"
      },
      "source": [
        "### Idea 3: Broadcast everything we can\n",
        "\n",
        "The title for this idea speaks for itself. The only operations that cannot be broadcast are those that must be done in `cvxopt`, the only for which it is absolutely must use `cvxopt` is the sparse cholesky decomposition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkCJOA2DkdNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try dask formatting first\n",
        "import dask.array as da\n",
        "\n",
        "XtX_da = da.from_array(XtX, chunks=(1, 4000, 4000))\n",
        "XtY_da = da.from_array(XtY, chunks=(100, 400, 400))\n",
        "XtZ_da = da.from_array(XtZ, chunks=(1, 4000, 4000))\n",
        "YtX_da = da.from_array(YtX, chunks=(100, 4000, 4000))\n",
        "YtY_da = da.from_array(YtY, chunks=(100, 1, 1))\n",
        "YtZ_da = da.from_array(YtZ, chunks=(100, 400, 400))\n",
        "ZtX_da = da.from_array(ZtX, chunks=(1, 4000, 4000))\n",
        "ZtY_da = da.from_array(ZtY, chunks=(1, 4000, 4000))\n",
        "ZtZ_da = da.from_array(ZtZ, chunks=(1, 4000, 4000)).map_blocks(sparse.COO).rechunk('auto')\n",
        "\n",
        "nv = np.prod(dimv) # Number of voxels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsNtMTsfZEzm",
        "colab_type": "text"
      },
      "source": [
        "#### Helper functions for idea 3\n",
        "\n",
        "Idea 3 needs broadcasted equivalents of the previous functions; these are given below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJFifADzZNvL",
        "colab_type": "text"
      },
      "source": [
        "#### Get the 3D mapping\n",
        "\n",
        "This function returns a 3D mapping equivalent to the previous mapping from a vector of parameters, theta, to indices which maps the parameters the to lower triangular block diagonal matrix, lambda; but for every voxel.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **nlevels**: a vector of the number of levels for each grouping factor. e.g. nlevels=[10,2] means there are 10 levels for factor 1 and 2 levels for factor 2.\n",
        " - **nparams**: a vector of the number of variables for each grouping factor. e.g. nparams=[3,4] means there are 3 variables for factor 1 and 4 variables for factor 2.\n",
        " - **nv**: The number of voxels the mapping is required for.\n",
        "\n",
        "All arrays must be np arrays.\n",
        "\n",
        "Note: It is assumed that all voxels have the same mapping here, i.e. they all have the same number of parameters and levels. This could be removed if needed but I suggest removing this assumption would have little practical use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w_peMYTZE6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e18aa37-c6fb-42a5-f3ae-6417dbee6580"
      },
      "source": [
        "def get_3D_mapping(nlevels, nparams, nv, P=None):\n",
        "\n",
        "    # Work out the 2D mapping for one voxel\n",
        "    theta_repeated_inds, row_indices, col_indices = get_mapping(nlevels, nparams)\n",
        "    \n",
        "    print('1')\n",
        "    \n",
        "    # Repeat the row and column indices for each voxel\n",
        "    row_indices_3D = np.tile(row_indices, nv)\n",
        "    col_indices_3D = np.tile(col_indices, nv)\n",
        "    \n",
        "    print('2')\n",
        "    \n",
        "    if not (P is None):\n",
        "      # Work out the inverse permutation\n",
        "      P = np.array(P[:]).reshape(P.size[0])\n",
        "      invP = np.arange(len(P))[np.argsort(P)]\n",
        "      \n",
        "      # Permute the columns using the inverse permutation\n",
        "      print('invP')\n",
        "      print(type(invP))\n",
        "      print(invP)\n",
        "      \n",
        "      col_indices_P = invP[col_indices.astype(np.int64)]\n",
        "      \n",
        "      # Tile across voxels\n",
        "      col_indices_P_3D = np.tile(col_indices_P, nv)\n",
        "    else:\n",
        "      col_indices_P_3D = col_indices_3D\n",
        "    \n",
        "    print('3')\n",
        "    \n",
        "    # Make an array for the coordinate representing which voxel we are looking \n",
        "    # at.\n",
        "    vox_indices_3D = np.repeat(np.arange(nv), len(col_indices))\n",
        "    \n",
        "    print('4')\n",
        "    \n",
        "    # Make 3D theta indices\n",
        "    theta_indices_3D = np.tile(theta_repeated_inds, nv)#+vox_indices_3D*len(col_indices)#Not correct \n",
        "    \n",
        "    print('5')\n",
        "    \n",
        "    # We need unique theta elements for each voxel so we change the 3D theta indices \n",
        "    theta_indices_3D = theta_indices_3D + vox_indices_3D*(np.max(theta_repeated_inds)+1)\n",
        "    \n",
        "    print('6')\n",
        "    \n",
        "    # Return \n",
        "    return(theta_indices_3D.astype(np.int64), row_indices_3D.astype(np.int16), col_indices_3D.astype(np.int16), col_indices_P_3D.astype(np.int16), vox_indices_3D.astype(np.int16))\n",
        "\n",
        "print(nparams)\n",
        "print(nlevels)\n",
        "theta_indices_3D, row_indices_3D, col_indices_3D, col_indices_P_3D, vox_indices_3D = get_3D_mapping(nlevels, nparams, nv)\n",
        "\n",
        "print(len(P))\n",
        "x = np.random.randn(len(P),len(P))\n",
        "\n",
        "import sys\n",
        "print(x.shape)\n",
        "print(x[:,P].reshape(x.shape[0], x.shape[1]).shape)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "print(x)\n",
        "print(x[:,P].reshape(x.shape[0], x.shape[1]))\n",
        "\n",
        "print(P)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 3]\n",
            "[4 4]\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "32\n",
            "(32, 32)\n",
            "(32, 32)\n",
            "[[-1.62026387e+00  4.44291228e-01 -2.00372497e-01 -3.00636367e-01\n",
            "   8.83318323e-01  6.71257051e-01 -1.54714357e+00  6.67322451e-01\n",
            "   4.03457888e-01 -3.45117596e-01 -2.95202438e-01  1.15282247e+00\n",
            "   6.82829795e-01 -5.62378101e-01 -5.61275867e-01  1.73243966e-02\n",
            "  -6.29821094e-01 -1.11124083e-02  7.63411644e-01  4.02437430e-01\n",
            "  -2.94792643e-01 -3.83234083e-02  5.04378244e-01  5.68071989e-01\n",
            "   4.04214513e-01 -6.46069975e-02  7.93241841e-01 -2.42731103e+00\n",
            "  -4.59018221e-01 -3.45411769e-01 -1.81518706e-01  3.58506703e-02]\n",
            " [-1.60985515e+00 -1.67482946e+00  2.42042762e-01 -1.70530900e+00\n",
            "  -6.46406848e-01  6.31883944e-01  1.13238855e+00  2.51774376e-01\n",
            "  -7.51247656e-02  2.02972349e+00 -3.77886241e-01  1.40078935e+00\n",
            "  -2.13070348e+00 -8.06235967e-01 -2.01666221e-01 -3.16336049e-01\n",
            "   1.29429933e+00  5.96937537e-01  1.02091625e+00 -2.31680649e-01\n",
            "   1.58372594e-01 -8.53160057e-02 -1.63478325e-01  2.09661184e+00\n",
            "   1.05753112e+00 -3.30223481e-01  3.59485487e-01  1.97967366e+00\n",
            "   6.27576799e-01  4.02800299e-01 -6.40102624e-01 -5.75763461e-01]\n",
            " [ 9.87251219e-01 -4.07472067e-01 -9.35244876e-01  2.42439739e-01\n",
            "   2.20538266e-01  9.65831198e-01 -3.49689723e-01 -1.40936030e+00\n",
            "  -4.72558170e-01 -5.33388261e-01  1.71119345e-01  4.78655869e-01\n",
            "  -2.70521738e-01 -1.10952280e+00  2.92008414e-01  6.45474180e-01\n",
            "  -1.11591699e+00 -8.89854411e-02 -1.16551592e+00  1.71370706e+00\n",
            "  -8.66360022e-01  4.38842235e-01 -5.58065261e-01  9.38300893e-01\n",
            "   7.70826434e-01 -4.61440493e-01 -1.48577120e+00  1.40558749e+00\n",
            "  -9.82897703e-01 -3.41649683e-01 -4.90243644e-01  3.78811408e-01]\n",
            " [ 1.05868158e-01  7.88251085e-01 -9.24660141e-01  6.91592568e-01\n",
            "  -8.13728632e-01  8.30109724e-01 -2.85932375e-01  1.43216028e-01\n",
            "   1.18942878e+00  1.23850381e-01  1.03973367e+00  8.24750638e-01\n",
            "   8.43304722e-01 -1.18948289e+00  7.71258457e-01 -1.48186357e-01\n",
            "  -1.82806984e+00 -5.73636986e-01  1.21891345e+00 -1.15388383e+00\n",
            "  -8.05239525e-02 -2.77288171e-02 -9.85675210e-01 -3.23321345e-01\n",
            "   1.02806180e-01 -1.32851421e-01  4.63483690e-01 -1.28286772e+00\n",
            "  -8.18836550e-01  4.00283156e-01  4.95272023e-01 -3.82819467e-01]\n",
            " [ 1.62233583e+00  1.80539319e+00  1.95963839e+00 -6.67539393e-01\n",
            "  -3.97780792e-01  1.57833908e+00  4.12585231e-01  1.69474259e+00\n",
            "  -6.01199519e-01  1.50465269e+00 -1.08386054e-01 -9.82679392e-01\n",
            "  -4.58998304e-01  3.24052666e-01  1.97410611e+00  5.22269517e-01\n",
            "   1.14341757e-01  6.24042011e-01  2.87093898e+00 -7.20633113e-01\n",
            "   4.50968941e-01  2.11804723e+00 -5.12549785e-01  4.92727148e-01\n",
            "  -1.06673659e+00 -1.08931141e+00  4.33402699e-01 -1.31185460e+00\n",
            "  -6.17007775e-02  9.34133807e-01  5.91108193e-01  5.07168639e-01]\n",
            " [ 3.96639427e-01 -7.41988569e-01 -1.33549713e+00 -7.15571019e-01\n",
            "  -4.97750320e-01  3.92659394e-01 -3.23297567e-01 -1.28263660e+00\n",
            "  -2.65653582e-01 -1.54826548e+00 -1.23793878e+00 -1.01746815e+00\n",
            "   2.11827219e-01  6.11993709e-01  6.41363313e-01  1.44996844e+00\n",
            "  -2.33962721e+00 -5.08249489e-01 -2.38874818e-01 -3.09344594e-01\n",
            "   3.65702457e-01 -3.93506279e-01  5.56450314e-01 -8.53840440e-01\n",
            "  -1.92867382e+00  1.04612093e-01  1.12827604e+00 -4.45040024e-01\n",
            "   1.43293447e+00  8.65785068e-01  3.84055789e-01  1.30384409e+00]\n",
            " [-2.44954594e+00 -5.22847239e-02 -1.45919039e+00  1.01898528e+00\n",
            "  -5.94268262e-02  1.67937183e-01  1.02411502e+00  3.85758500e-01\n",
            "  -6.01764490e-01 -6.28346989e-01  8.82211896e-01 -8.54407203e-01\n",
            "   3.89517844e-01  1.41728925e+00 -4.42971828e-01  6.48385751e-01\n",
            "  -1.85232847e+00  2.98977079e-01  1.29772030e-01 -1.29134776e+00\n",
            "   7.82991085e-01  7.05669651e-01 -1.32004761e-01  4.82811878e-01\n",
            "   5.58021724e-02  4.87188391e-02 -1.50633640e+00 -5.31856583e-01\n",
            "  -2.86015808e-01 -1.09949196e+00 -2.39837830e+00 -3.60662458e-01]\n",
            " [-1.51796295e+00  2.34045378e+00  7.37183064e-01  7.20238121e-01\n",
            "  -8.87485485e-01  9.71329510e-01  1.58259857e-01  1.51332493e+00\n",
            "  -1.55580697e+00  1.02562452e+00  2.52086227e-01  1.01998997e+00\n",
            "   6.55760639e-01  8.67949586e-01  8.61349903e-01  6.39993084e-01\n",
            "  -1.81536654e-01  7.67790679e-01  1.13062407e+00 -1.32763319e+00\n",
            "   4.76423998e-01 -1.06302228e+00 -9.44852992e-01 -1.08784049e+00\n",
            "  -1.71767267e+00  9.53064907e-02  1.88039176e-01  1.28019620e+00\n",
            "   1.36586055e+00  1.29421337e+00 -4.95987354e-01 -1.22009309e-01]\n",
            " [-1.01131699e+00 -1.61905249e+00 -7.13595619e-02 -6.14958716e-01\n",
            "  -2.02465743e+00  5.79832138e-01 -1.07272396e+00  7.16862400e-01\n",
            "  -1.79247177e-01  8.11410870e-01 -5.66585475e-01 -2.41330735e-03\n",
            "   3.94972253e-01  6.40184914e-01  7.93222254e-01  1.08930465e+00\n",
            "   1.32181798e+00  1.12181312e+00 -1.71997011e-01  1.97315380e+00\n",
            "   3.49261093e-02 -6.10859382e-01  9.57343460e-01 -6.16961723e-01\n",
            "  -9.73670401e-02 -9.05352876e-01 -3.91634761e-01  1.41820239e+00\n",
            "   1.08676289e+00  1.12985473e-02 -9.23820685e-01  5.14070401e-01]\n",
            " [ 9.35598414e-01 -7.88407180e-01  4.77582685e-01  7.80884393e-01\n",
            "  -5.05714530e-01  1.75641161e-01  4.69422903e-01 -1.53195445e+00\n",
            "  -8.75209104e-01  3.59406884e-01 -9.74028522e-01  1.69032711e+00\n",
            "   8.55393523e-01 -1.14587394e+00 -7.01491766e-01  2.05348066e-01\n",
            "   1.92968088e-01 -1.17100418e+00 -5.47082150e-01 -1.00524014e-01\n",
            "  -1.21722058e+00  5.46899643e-01 -6.22493014e-02 -6.18367459e-01\n",
            "  -1.71783817e+00  2.87738762e-01  1.19450132e-02  1.38004437e+00\n",
            "  -1.96876679e+00 -3.04780820e-02  7.68177625e-01 -2.81509914e+00]\n",
            " [-7.58018878e-01  6.31131357e-02  1.97433372e+00 -1.30238804e+00\n",
            "  -8.92941240e-01 -5.62967475e-01 -3.85502150e-01 -8.37644509e-01\n",
            "  -7.49670071e-01  7.63841046e-01 -1.67656062e+00  1.07163163e-01\n",
            "   1.08534819e-01  8.79601625e-01  3.43439207e-01 -8.00058732e-01\n",
            "   1.09408211e+00  8.85671739e-01 -6.04584400e-01  4.65416993e-01\n",
            "  -1.58029182e+00  9.24163493e-01 -2.71088839e-01 -7.90801562e-01\n",
            "   9.01838624e-02 -1.37075510e-01 -2.00320769e-01 -2.37473056e-01\n",
            "  -2.25776942e-01 -1.37545059e+00 -1.31248860e+00 -1.22191636e-01]\n",
            " [ 2.64425229e+00 -5.96188638e-01 -1.38090159e+00 -1.18847073e+00\n",
            "  -1.24921341e-01  1.67894016e+00 -1.73729388e-01 -1.41245647e+00\n",
            "   5.35822693e-01  1.03167562e+00 -3.16496684e-01 -3.87981739e-01\n",
            "  -8.20987071e-01  7.09371485e-01 -1.38410862e+00  8.37470491e-03\n",
            "   1.48780670e+00  1.15756842e-01  1.13902174e+00 -7.98278626e-01\n",
            "  -7.36328576e-01  9.59854431e-01  4.28048551e-01  3.53935792e-01\n",
            "   1.21398976e+00  1.30067356e+00 -7.39138874e-01 -2.25288829e-01\n",
            "   1.34808556e+00  8.58052626e-01  7.98081422e-01  1.59431598e+00]\n",
            " [-2.28471289e-01  4.91541230e-01 -1.04686498e-01 -6.03742271e-01\n",
            "   5.23927500e-01 -3.89784488e-01 -7.73468880e-01 -1.76432162e-01\n",
            "   8.32552730e-01  2.82104116e-01 -2.05635604e+00  6.78992858e-01\n",
            "  -1.15696704e+00  2.66722246e-01  6.30658886e-01 -4.08873883e-01\n",
            "  -1.01728687e-01 -2.00532137e+00 -8.78599667e-01 -7.58328614e-01\n",
            "   1.25713347e-01  1.15667756e-01  4.11097796e-01  4.07252134e-02\n",
            "  -1.58554265e+00  8.83835118e-01  1.49316771e+00  9.74904922e-01\n",
            "   6.52888072e-01  6.61732929e-02 -9.08161832e-01 -1.90217090e-01]\n",
            " [-4.83173953e-01  6.15421027e-01  2.06950644e+00 -1.40194243e-01\n",
            "   4.74400076e-01  3.33597246e-01  1.83773113e+00  1.23040117e+00\n",
            "  -8.40748710e-01 -5.38455317e-01 -3.58290992e-01  8.74035194e-01\n",
            "  -5.72670240e-01 -3.53328690e-01 -8.99206945e-01  1.01038271e+00\n",
            "   2.61741348e-01 -7.43320322e-01  7.82492769e-02  8.96398310e-01\n",
            "   1.71259191e-01 -1.81403573e+00  1.52920629e+00 -1.20152177e+00\n",
            "   1.04587842e+00 -5.59307969e-01  6.76745295e-01  9.28818186e-01\n",
            "  -8.75880326e-03  2.41005704e-01 -4.04117228e-01  4.30561177e-01]\n",
            " [ 1.23160897e-01 -1.78145350e+00 -1.03566365e-01  8.73440088e-01\n",
            "  -2.73818788e-01 -3.07147347e-01  2.14055228e+00 -1.28511727e+00\n",
            "   1.25024847e+00  1.63082317e+00  1.61352367e+00 -6.80063668e-01\n",
            "   6.60237613e-01  1.38559263e+00 -1.14040304e+00 -4.39998169e-02\n",
            "  -2.08578831e-01  1.18561694e+00 -9.79607729e-01 -7.07824763e-01\n",
            "  -3.27218480e-01 -3.92249054e-01 -1.39658754e+00 -1.19223965e+00\n",
            "   5.72574777e-01  1.80954892e+00  1.38347761e+00  2.94820203e-01\n",
            "  -4.05568392e-01  8.52202146e-01 -1.27105823e+00  2.94157053e-01]\n",
            " [ 7.59546767e-01  6.15781999e-01  1.14367569e+00  7.63170482e-01\n",
            "   1.08083837e+00 -5.36581834e-01 -1.24618252e+00 -9.35735306e-01\n",
            "  -6.08599292e-01 -6.06058258e-01 -4.66347274e-01 -3.95683998e-01\n",
            "  -1.85508608e-01  4.77989221e-01  1.09318322e-01 -1.92114683e-01\n",
            "   5.55531470e-01  5.60434264e-01 -2.23285797e-01 -4.88896598e-01\n",
            "   1.83712564e-01 -3.60128097e-01  1.23954341e+00 -2.28073405e-01\n",
            "   2.01560128e-02  7.24526545e-01  1.60822362e+00 -1.65609233e-01\n",
            "  -6.78130700e-01  1.27989696e-01 -1.50708582e+00 -1.85668991e+00]\n",
            " [ 1.30575415e-01 -1.91589596e-01 -2.91592065e-02  2.74004421e+00\n",
            "  -7.93070542e-02  7.19685109e-01 -3.84400764e-01  1.22378705e+00\n",
            "   7.74627471e-01 -3.92690342e-01  1.13095557e+00 -7.32194067e-01\n",
            "  -2.62034214e-01  4.05001834e-01  1.53434639e+00 -6.82278197e-01\n",
            "  -3.93778406e-01 -2.19884776e+00 -1.20123760e-01  1.00849134e+00\n",
            "   1.30675192e-01  3.99472310e-01  1.17030307e-01 -4.68225805e-01\n",
            "   1.46691127e+00  5.61407248e-01 -7.82565856e-01  6.15757303e-01\n",
            "  -1.70284852e+00 -3.20699417e-01  1.58624455e+00 -1.51224917e+00]\n",
            " [-2.07194386e-01 -5.63704231e-01 -2.10315025e-01  6.92212948e-02\n",
            "   1.33646322e+00 -3.78057953e-01 -5.42159697e-01 -3.23897317e-01\n",
            "   8.21199724e-01 -1.70151847e+00  9.09132414e-01 -1.59992904e+00\n",
            "  -6.19491307e-01 -5.57388580e-01  5.02382115e-01 -1.44051907e+00\n",
            "  -5.79966399e-02  4.29046806e-01  1.53167888e+00  2.72191978e-01\n",
            "   5.15559232e-01  1.28466815e-01 -3.33609870e-01  7.99153279e-02\n",
            "  -1.66083796e+00  1.22090311e+00 -1.34273501e+00 -1.78753484e-01\n",
            "   1.82729850e-01 -1.39154862e-02 -1.59339662e+00  3.16921429e-01]\n",
            " [ 9.21504009e-01  1.54358245e-01 -2.27855689e-03  3.12725196e-01\n",
            "   9.65289520e-01 -5.95892169e-01 -9.09591683e-01  8.44490341e-01\n",
            "  -6.37245494e-01 -4.61756907e-01 -1.38998458e+00 -9.23998661e-02\n",
            "  -1.86862577e+00 -2.08263384e-01 -5.27740134e-01  7.37761008e-01\n",
            "  -9.46961281e-01 -1.47024539e+00  9.46775197e-01  2.33166170e-02\n",
            "   5.66111996e-02  8.22140218e-01  4.63936202e-01 -1.01509963e-01\n",
            "   9.34357698e-03  9.32540576e-01 -3.48067251e-01 -1.88566119e+00\n",
            "   9.07525985e-01 -1.00740035e+00 -3.35249590e-01 -1.09442895e+00]\n",
            " [-1.13159298e+00  2.27050834e-01  8.36568864e-01 -7.86243621e-01\n",
            "  -1.47564696e+00  2.44272148e-01 -3.25818986e-01  1.52752584e+00\n",
            "   6.51703473e-01 -6.91517563e-01  1.06666092e-01 -1.13948636e+00\n",
            "   1.16173273e+00 -1.39152253e+00  6.11452617e-01  1.59218677e+00\n",
            "   1.11292596e+00  1.40546524e-01  1.36698449e+00  1.12021967e-01\n",
            "   7.90419984e-01  8.98064595e-01 -1.37822344e-01  2.82254603e-01\n",
            "  -9.35200221e-01 -7.50655653e-01 -2.38857785e+00  8.25553309e-01\n",
            "  -1.01818380e+00  2.73065282e+00  3.63186467e-01  6.24530224e-01]\n",
            " [-1.39380868e+00  2.84338780e-01 -8.09297465e-01 -1.95498640e-01\n",
            "   1.35862335e+00 -5.40610585e-01 -1.13822174e+00 -9.72738296e-01\n",
            "   1.13230526e+00  9.73326396e-01 -8.24481212e-01  1.79196898e+00\n",
            "  -3.04789052e-02 -1.59596969e+00  6.00269689e-01 -8.09631351e-02\n",
            "  -1.24903781e+00 -1.16545184e+00  1.84023274e-01 -2.22183847e-01\n",
            "  -1.74375834e+00  4.48590180e-01 -1.79705261e+00  5.12058925e-01\n",
            "  -1.25266605e+00  2.56226578e-01  2.70550344e+00  6.01127069e-01\n",
            "  -1.85269765e+00 -6.30585090e-01 -2.77994493e+00 -8.33659864e-01]\n",
            " [ 6.25342366e-01 -1.28202075e+00 -1.08659338e+00 -6.96750453e-01\n",
            "  -9.46057607e-01 -4.53976105e-01  5.07088592e-01  1.60669808e+00\n",
            "  -1.49599399e+00 -1.19486588e+00  6.22598246e-01 -1.59105794e+00\n",
            "  -3.37343195e-02  8.01862174e-01 -1.39399717e+00 -1.07829954e+00\n",
            "  -5.08392246e-01 -3.49652679e-01 -5.89874314e-02  8.64868699e-02\n",
            "  -4.67466457e-01 -2.91758514e-01  2.06581109e-01  5.64035238e-01\n",
            "   2.68214687e-01 -1.22387593e+00  1.90412767e-01  3.63093104e-01\n",
            "   4.17923605e-01 -5.68641074e-01 -2.38983154e-01 -4.53840020e-01]\n",
            " [-1.43518863e+00 -1.64544022e-01 -8.19173301e-01  1.04118975e+00\n",
            "  -9.55708485e-01 -3.24021896e-01  1.00905956e+00  2.83271228e-01\n",
            "  -9.82787319e-01 -2.02011010e-01  1.06030162e+00  1.14962708e+00\n",
            "   9.99317981e-01 -1.34810414e-01  3.35323977e-01 -2.68374208e-01\n",
            "  -4.58903462e-01 -6.01552639e-01  1.41884523e+00 -3.09758387e-01\n",
            "   1.50845529e+00  1.20545204e+00 -3.49613223e-01 -6.13279791e-01\n",
            "  -1.21891341e+00 -2.55989774e-01  1.34865070e+00  1.30515558e+00\n",
            "   5.40928591e-01  1.30188856e-01  5.99198311e-01 -3.76416005e-01]\n",
            " [-3.85030192e-01  5.05478768e-01  1.29687471e-01 -6.29134101e-01\n",
            "  -1.27333688e+00 -1.11303997e+00 -1.79825487e+00  1.00979203e+00\n",
            "   7.07428764e-01 -2.32113792e-01 -4.73994239e-01 -3.95981065e-01\n",
            "  -1.02376175e-01 -7.67031362e-01  1.49962524e+00  1.09888468e+00\n",
            "   4.53007304e-01 -1.75492787e+00 -4.55853825e-01  1.38052914e+00\n",
            "  -6.40417728e-02  2.67209028e-01  1.60998663e+00 -4.92765391e-01\n",
            "  -8.55923940e-01 -3.63313759e-01  1.67490822e+00 -5.13394497e-01\n",
            "   4.51757872e-01 -9.99614658e-01 -2.34684910e-01  1.06217175e+00]\n",
            " [-1.52108990e+00  3.36250725e-01  1.41592354e+00  1.25618635e+00\n",
            "  -5.43668301e-01  7.57326293e-02 -3.12837465e-01 -1.07475859e-01\n",
            "  -7.71777271e-01  4.26608295e-01  7.18501228e-01 -2.02291131e-01\n",
            "   1.33903378e+00 -8.78660736e-01  1.31399629e+00  3.53431252e-01\n",
            "   1.48090986e+00 -2.59318522e-01 -8.15974840e-01  5.47548579e-01\n",
            "  -2.61276692e-01 -1.03202494e+00 -8.37743734e-01 -5.36047772e-01\n",
            "  -9.97887228e-01 -8.02789015e-01 -1.43422093e-01  7.16390691e-01\n",
            "   2.40329779e+00 -6.36957584e-01 -1.83317398e-01 -1.54449834e+00]\n",
            " [ 5.78523682e-01 -1.73758850e-01 -2.26910927e-02  3.63405912e-01\n",
            "  -6.37987093e-01  3.97738895e-01 -9.08112902e-01 -5.58666603e-01\n",
            "   3.28333379e-01 -1.50070592e-01 -1.61316804e-01 -1.55620363e+00\n",
            "  -1.41695355e+00 -5.03429543e-01  2.81248113e-01  6.52164928e-01\n",
            "  -2.36347100e-02  1.61296118e+00  2.86244332e+00  2.26184271e-01\n",
            "   6.29434981e-01  7.01984132e-02  7.68925717e-01 -7.11826093e-01\n",
            "  -1.75072420e-01  5.69137703e-01 -3.13712176e-01 -2.60065316e-01\n",
            "   4.09443288e-01  2.10935301e+00 -4.10789080e-02 -9.39438153e-01]\n",
            " [ 1.61796236e+00  1.83888763e+00  8.38364227e-02 -3.81950273e-01\n",
            "   2.51187762e-01 -1.60772513e+00  1.45391016e+00 -8.54129189e-02\n",
            "   9.63559607e-01 -6.06228374e-01 -1.48825093e+00 -1.24306146e+00\n",
            "   9.60771033e-01 -1.68702556e-01 -1.14461188e-01 -7.45276775e-01\n",
            "  -1.29485184e+00  1.88991373e-01 -1.20359191e+00 -7.40866132e-01\n",
            "   1.01777871e+00  7.05229999e-01 -6.22599960e-01 -8.74035435e-01\n",
            "   2.71553302e-01 -8.13735767e-02  1.25762848e+00 -1.13024192e+00\n",
            "  -1.10640029e-01 -1.44491015e+00  2.38632775e-01 -4.67949365e-01]\n",
            " [ 2.91363237e-01 -5.53561794e-01 -4.57458480e-01 -2.73759796e-01\n",
            "  -7.47286259e-01 -1.08882181e-01  1.00704741e+00 -9.72216234e-01\n",
            "  -9.84708004e-01  8.75350638e-01  3.81656111e-01  1.59315726e+00\n",
            "   2.07180738e-01 -8.62427231e-01 -1.30086976e+00 -6.30314114e-01\n",
            "   3.88344187e-02 -2.46778950e-01  8.65802181e-01  8.32315473e-01\n",
            "  -4.06913373e-01 -1.59623795e+00 -4.59875014e-01 -7.79162072e-02\n",
            "  -1.29417670e+00 -1.67139285e+00  3.80930456e-01  5.79262284e-01\n",
            "   7.59428564e-01  9.61292686e-01 -5.54182638e-01 -5.93218335e-01]\n",
            " [ 2.41208329e-01 -1.06845189e-01  3.74701246e-01 -2.35798000e-02\n",
            "  -1.35139875e-01  1.30817115e+00  2.33340020e-01  7.93897844e-01\n",
            "  -7.28599404e-01  2.25622463e+00  9.21638085e-01  1.04257460e+00\n",
            "  -3.95332238e-01 -2.07881616e+00  1.22754615e+00 -1.59186793e+00\n",
            "   1.32661364e+00 -1.42440488e-01  7.57068268e-03  1.44854743e+00\n",
            "  -1.19196520e-01  4.78114496e-01 -1.37991035e+00 -5.52641769e-01\n",
            "  -3.28789315e-01 -8.00339714e-01 -1.84572289e-01  1.13407090e-01\n",
            "  -5.66882766e-01  9.81281195e-01  1.14188099e-01 -1.57353247e-01]\n",
            " [-1.99870533e+00  3.46893855e-02 -1.78318311e+00 -1.62018595e-02\n",
            "   7.20446571e-01  1.20628544e+00 -6.28113005e-01  3.44692884e-01\n",
            "   1.18251498e+00  5.43810339e-01 -1.44754902e-02  1.05669898e+00\n",
            "   8.69082254e-01 -1.22661626e+00 -2.10095732e-01  9.77585620e-01\n",
            "  -3.12797963e-01 -2.53188842e-01 -1.43253806e+00  4.25560811e-01\n",
            "  -4.55448320e-01 -7.40290051e-01  1.02495334e+00 -8.59823453e-01\n",
            "  -1.04016033e+00 -9.90147965e-01  8.79438830e-01  6.03769603e-01\n",
            "   7.56149700e-01  7.38310939e-01 -7.91836277e-02 -2.55520243e-01]\n",
            " [-7.14728902e-01  1.26190253e+00 -5.48831604e-03  5.36498443e-01\n",
            "  -1.16906711e+00 -1.27693765e+00 -8.55370045e-01  9.19094886e-01\n",
            "   1.49139248e+00 -3.25550497e-01  1.82579654e+00 -6.60477043e-01\n",
            "   1.15965628e+00  4.54618631e-01 -6.10442215e-02  6.76117955e-01\n",
            "   1.01661794e+00 -9.43491378e-01 -2.06736445e-01 -9.57076389e-01\n",
            "   4.35726200e-01  1.81346705e-01 -4.88118274e-01  1.34226244e+00\n",
            "  -6.40959007e-01  3.65159296e-01  5.24054711e-01  5.36578549e-01\n",
            "   4.38507984e-03  6.11563385e-01  2.42613468e+00  1.03734349e-01]\n",
            " [ 1.47585595e+00 -4.63038256e-01 -1.32667867e+00  2.16505063e-02\n",
            "   4.04425770e-02  9.09407929e-01 -2.14241051e-01 -9.87558423e-01\n",
            "  -1.58773616e+00  1.51592153e+00 -4.04885902e-01 -6.75283670e-01\n",
            "   5.85956688e-01 -6.40547163e-01 -1.81095462e-01  7.92480668e-01\n",
            "   3.61338899e-01 -4.38556746e-01  1.78541358e+00 -9.87072359e-01\n",
            "  -1.38738758e+00 -1.11434841e+00  1.97004559e-01  1.70259667e+00\n",
            "  -8.40833617e-01 -1.33900378e+00  7.03490095e-01 -7.40392797e-01\n",
            "  -5.43307784e-01  6.83954924e-01  5.14209241e-01 -2.22331062e+00]]\n",
            "[[ 1.73243966e-02 -6.29821094e-01 -1.11124083e-02  7.63411644e-01\n",
            "   4.02437430e-01 -1.62026387e+00  4.44291228e-01 -2.00372497e-01\n",
            "  -3.00636367e-01  8.83318323e-01  6.71257051e-01 -1.54714357e+00\n",
            "   6.67322451e-01  4.03457888e-01 -3.45117596e-01 -2.95202438e-01\n",
            "   1.15282247e+00  6.82829795e-01 -5.62378101e-01 -5.61275867e-01\n",
            "  -2.94792643e-01 -3.83234083e-02  5.04378244e-01  5.68071989e-01\n",
            "   4.04214513e-01 -6.46069975e-02  7.93241841e-01 -2.42731103e+00\n",
            "  -4.59018221e-01 -3.45411769e-01 -1.81518706e-01  3.58506703e-02]\n",
            " [-3.16336049e-01  1.29429933e+00  5.96937537e-01  1.02091625e+00\n",
            "  -2.31680649e-01 -1.60985515e+00 -1.67482946e+00  2.42042762e-01\n",
            "  -1.70530900e+00 -6.46406848e-01  6.31883944e-01  1.13238855e+00\n",
            "   2.51774376e-01 -7.51247656e-02  2.02972349e+00 -3.77886241e-01\n",
            "   1.40078935e+00 -2.13070348e+00 -8.06235967e-01 -2.01666221e-01\n",
            "   1.58372594e-01 -8.53160057e-02 -1.63478325e-01  2.09661184e+00\n",
            "   1.05753112e+00 -3.30223481e-01  3.59485487e-01  1.97967366e+00\n",
            "   6.27576799e-01  4.02800299e-01 -6.40102624e-01 -5.75763461e-01]\n",
            " [ 6.45474180e-01 -1.11591699e+00 -8.89854411e-02 -1.16551592e+00\n",
            "   1.71370706e+00  9.87251219e-01 -4.07472067e-01 -9.35244876e-01\n",
            "   2.42439739e-01  2.20538266e-01  9.65831198e-01 -3.49689723e-01\n",
            "  -1.40936030e+00 -4.72558170e-01 -5.33388261e-01  1.71119345e-01\n",
            "   4.78655869e-01 -2.70521738e-01 -1.10952280e+00  2.92008414e-01\n",
            "  -8.66360022e-01  4.38842235e-01 -5.58065261e-01  9.38300893e-01\n",
            "   7.70826434e-01 -4.61440493e-01 -1.48577120e+00  1.40558749e+00\n",
            "  -9.82897703e-01 -3.41649683e-01 -4.90243644e-01  3.78811408e-01]\n",
            " [-1.48186357e-01 -1.82806984e+00 -5.73636986e-01  1.21891345e+00\n",
            "  -1.15388383e+00  1.05868158e-01  7.88251085e-01 -9.24660141e-01\n",
            "   6.91592568e-01 -8.13728632e-01  8.30109724e-01 -2.85932375e-01\n",
            "   1.43216028e-01  1.18942878e+00  1.23850381e-01  1.03973367e+00\n",
            "   8.24750638e-01  8.43304722e-01 -1.18948289e+00  7.71258457e-01\n",
            "  -8.05239525e-02 -2.77288171e-02 -9.85675210e-01 -3.23321345e-01\n",
            "   1.02806180e-01 -1.32851421e-01  4.63483690e-01 -1.28286772e+00\n",
            "  -8.18836550e-01  4.00283156e-01  4.95272023e-01 -3.82819467e-01]\n",
            " [ 5.22269517e-01  1.14341757e-01  6.24042011e-01  2.87093898e+00\n",
            "  -7.20633113e-01  1.62233583e+00  1.80539319e+00  1.95963839e+00\n",
            "  -6.67539393e-01 -3.97780792e-01  1.57833908e+00  4.12585231e-01\n",
            "   1.69474259e+00 -6.01199519e-01  1.50465269e+00 -1.08386054e-01\n",
            "  -9.82679392e-01 -4.58998304e-01  3.24052666e-01  1.97410611e+00\n",
            "   4.50968941e-01  2.11804723e+00 -5.12549785e-01  4.92727148e-01\n",
            "  -1.06673659e+00 -1.08931141e+00  4.33402699e-01 -1.31185460e+00\n",
            "  -6.17007775e-02  9.34133807e-01  5.91108193e-01  5.07168639e-01]\n",
            " [ 1.44996844e+00 -2.33962721e+00 -5.08249489e-01 -2.38874818e-01\n",
            "  -3.09344594e-01  3.96639427e-01 -7.41988569e-01 -1.33549713e+00\n",
            "  -7.15571019e-01 -4.97750320e-01  3.92659394e-01 -3.23297567e-01\n",
            "  -1.28263660e+00 -2.65653582e-01 -1.54826548e+00 -1.23793878e+00\n",
            "  -1.01746815e+00  2.11827219e-01  6.11993709e-01  6.41363313e-01\n",
            "   3.65702457e-01 -3.93506279e-01  5.56450314e-01 -8.53840440e-01\n",
            "  -1.92867382e+00  1.04612093e-01  1.12827604e+00 -4.45040024e-01\n",
            "   1.43293447e+00  8.65785068e-01  3.84055789e-01  1.30384409e+00]\n",
            " [ 6.48385751e-01 -1.85232847e+00  2.98977079e-01  1.29772030e-01\n",
            "  -1.29134776e+00 -2.44954594e+00 -5.22847239e-02 -1.45919039e+00\n",
            "   1.01898528e+00 -5.94268262e-02  1.67937183e-01  1.02411502e+00\n",
            "   3.85758500e-01 -6.01764490e-01 -6.28346989e-01  8.82211896e-01\n",
            "  -8.54407203e-01  3.89517844e-01  1.41728925e+00 -4.42971828e-01\n",
            "   7.82991085e-01  7.05669651e-01 -1.32004761e-01  4.82811878e-01\n",
            "   5.58021724e-02  4.87188391e-02 -1.50633640e+00 -5.31856583e-01\n",
            "  -2.86015808e-01 -1.09949196e+00 -2.39837830e+00 -3.60662458e-01]\n",
            " [ 6.39993084e-01 -1.81536654e-01  7.67790679e-01  1.13062407e+00\n",
            "  -1.32763319e+00 -1.51796295e+00  2.34045378e+00  7.37183064e-01\n",
            "   7.20238121e-01 -8.87485485e-01  9.71329510e-01  1.58259857e-01\n",
            "   1.51332493e+00 -1.55580697e+00  1.02562452e+00  2.52086227e-01\n",
            "   1.01998997e+00  6.55760639e-01  8.67949586e-01  8.61349903e-01\n",
            "   4.76423998e-01 -1.06302228e+00 -9.44852992e-01 -1.08784049e+00\n",
            "  -1.71767267e+00  9.53064907e-02  1.88039176e-01  1.28019620e+00\n",
            "   1.36586055e+00  1.29421337e+00 -4.95987354e-01 -1.22009309e-01]\n",
            " [ 1.08930465e+00  1.32181798e+00  1.12181312e+00 -1.71997011e-01\n",
            "   1.97315380e+00 -1.01131699e+00 -1.61905249e+00 -7.13595619e-02\n",
            "  -6.14958716e-01 -2.02465743e+00  5.79832138e-01 -1.07272396e+00\n",
            "   7.16862400e-01 -1.79247177e-01  8.11410870e-01 -5.66585475e-01\n",
            "  -2.41330735e-03  3.94972253e-01  6.40184914e-01  7.93222254e-01\n",
            "   3.49261093e-02 -6.10859382e-01  9.57343460e-01 -6.16961723e-01\n",
            "  -9.73670401e-02 -9.05352876e-01 -3.91634761e-01  1.41820239e+00\n",
            "   1.08676289e+00  1.12985473e-02 -9.23820685e-01  5.14070401e-01]\n",
            " [ 2.05348066e-01  1.92968088e-01 -1.17100418e+00 -5.47082150e-01\n",
            "  -1.00524014e-01  9.35598414e-01 -7.88407180e-01  4.77582685e-01\n",
            "   7.80884393e-01 -5.05714530e-01  1.75641161e-01  4.69422903e-01\n",
            "  -1.53195445e+00 -8.75209104e-01  3.59406884e-01 -9.74028522e-01\n",
            "   1.69032711e+00  8.55393523e-01 -1.14587394e+00 -7.01491766e-01\n",
            "  -1.21722058e+00  5.46899643e-01 -6.22493014e-02 -6.18367459e-01\n",
            "  -1.71783817e+00  2.87738762e-01  1.19450132e-02  1.38004437e+00\n",
            "  -1.96876679e+00 -3.04780820e-02  7.68177625e-01 -2.81509914e+00]\n",
            " [-8.00058732e-01  1.09408211e+00  8.85671739e-01 -6.04584400e-01\n",
            "   4.65416993e-01 -7.58018878e-01  6.31131357e-02  1.97433372e+00\n",
            "  -1.30238804e+00 -8.92941240e-01 -5.62967475e-01 -3.85502150e-01\n",
            "  -8.37644509e-01 -7.49670071e-01  7.63841046e-01 -1.67656062e+00\n",
            "   1.07163163e-01  1.08534819e-01  8.79601625e-01  3.43439207e-01\n",
            "  -1.58029182e+00  9.24163493e-01 -2.71088839e-01 -7.90801562e-01\n",
            "   9.01838624e-02 -1.37075510e-01 -2.00320769e-01 -2.37473056e-01\n",
            "  -2.25776942e-01 -1.37545059e+00 -1.31248860e+00 -1.22191636e-01]\n",
            " [ 8.37470491e-03  1.48780670e+00  1.15756842e-01  1.13902174e+00\n",
            "  -7.98278626e-01  2.64425229e+00 -5.96188638e-01 -1.38090159e+00\n",
            "  -1.18847073e+00 -1.24921341e-01  1.67894016e+00 -1.73729388e-01\n",
            "  -1.41245647e+00  5.35822693e-01  1.03167562e+00 -3.16496684e-01\n",
            "  -3.87981739e-01 -8.20987071e-01  7.09371485e-01 -1.38410862e+00\n",
            "  -7.36328576e-01  9.59854431e-01  4.28048551e-01  3.53935792e-01\n",
            "   1.21398976e+00  1.30067356e+00 -7.39138874e-01 -2.25288829e-01\n",
            "   1.34808556e+00  8.58052626e-01  7.98081422e-01  1.59431598e+00]\n",
            " [-4.08873883e-01 -1.01728687e-01 -2.00532137e+00 -8.78599667e-01\n",
            "  -7.58328614e-01 -2.28471289e-01  4.91541230e-01 -1.04686498e-01\n",
            "  -6.03742271e-01  5.23927500e-01 -3.89784488e-01 -7.73468880e-01\n",
            "  -1.76432162e-01  8.32552730e-01  2.82104116e-01 -2.05635604e+00\n",
            "   6.78992858e-01 -1.15696704e+00  2.66722246e-01  6.30658886e-01\n",
            "   1.25713347e-01  1.15667756e-01  4.11097796e-01  4.07252134e-02\n",
            "  -1.58554265e+00  8.83835118e-01  1.49316771e+00  9.74904922e-01\n",
            "   6.52888072e-01  6.61732929e-02 -9.08161832e-01 -1.90217090e-01]\n",
            " [ 1.01038271e+00  2.61741348e-01 -7.43320322e-01  7.82492769e-02\n",
            "   8.96398310e-01 -4.83173953e-01  6.15421027e-01  2.06950644e+00\n",
            "  -1.40194243e-01  4.74400076e-01  3.33597246e-01  1.83773113e+00\n",
            "   1.23040117e+00 -8.40748710e-01 -5.38455317e-01 -3.58290992e-01\n",
            "   8.74035194e-01 -5.72670240e-01 -3.53328690e-01 -8.99206945e-01\n",
            "   1.71259191e-01 -1.81403573e+00  1.52920629e+00 -1.20152177e+00\n",
            "   1.04587842e+00 -5.59307969e-01  6.76745295e-01  9.28818186e-01\n",
            "  -8.75880326e-03  2.41005704e-01 -4.04117228e-01  4.30561177e-01]\n",
            " [-4.39998169e-02 -2.08578831e-01  1.18561694e+00 -9.79607729e-01\n",
            "  -7.07824763e-01  1.23160897e-01 -1.78145350e+00 -1.03566365e-01\n",
            "   8.73440088e-01 -2.73818788e-01 -3.07147347e-01  2.14055228e+00\n",
            "  -1.28511727e+00  1.25024847e+00  1.63082317e+00  1.61352367e+00\n",
            "  -6.80063668e-01  6.60237613e-01  1.38559263e+00 -1.14040304e+00\n",
            "  -3.27218480e-01 -3.92249054e-01 -1.39658754e+00 -1.19223965e+00\n",
            "   5.72574777e-01  1.80954892e+00  1.38347761e+00  2.94820203e-01\n",
            "  -4.05568392e-01  8.52202146e-01 -1.27105823e+00  2.94157053e-01]\n",
            " [-1.92114683e-01  5.55531470e-01  5.60434264e-01 -2.23285797e-01\n",
            "  -4.88896598e-01  7.59546767e-01  6.15781999e-01  1.14367569e+00\n",
            "   7.63170482e-01  1.08083837e+00 -5.36581834e-01 -1.24618252e+00\n",
            "  -9.35735306e-01 -6.08599292e-01 -6.06058258e-01 -4.66347274e-01\n",
            "  -3.95683998e-01 -1.85508608e-01  4.77989221e-01  1.09318322e-01\n",
            "   1.83712564e-01 -3.60128097e-01  1.23954341e+00 -2.28073405e-01\n",
            "   2.01560128e-02  7.24526545e-01  1.60822362e+00 -1.65609233e-01\n",
            "  -6.78130700e-01  1.27989696e-01 -1.50708582e+00 -1.85668991e+00]\n",
            " [-6.82278197e-01 -3.93778406e-01 -2.19884776e+00 -1.20123760e-01\n",
            "   1.00849134e+00  1.30575415e-01 -1.91589596e-01 -2.91592065e-02\n",
            "   2.74004421e+00 -7.93070542e-02  7.19685109e-01 -3.84400764e-01\n",
            "   1.22378705e+00  7.74627471e-01 -3.92690342e-01  1.13095557e+00\n",
            "  -7.32194067e-01 -2.62034214e-01  4.05001834e-01  1.53434639e+00\n",
            "   1.30675192e-01  3.99472310e-01  1.17030307e-01 -4.68225805e-01\n",
            "   1.46691127e+00  5.61407248e-01 -7.82565856e-01  6.15757303e-01\n",
            "  -1.70284852e+00 -3.20699417e-01  1.58624455e+00 -1.51224917e+00]\n",
            " [-1.44051907e+00 -5.79966399e-02  4.29046806e-01  1.53167888e+00\n",
            "   2.72191978e-01 -2.07194386e-01 -5.63704231e-01 -2.10315025e-01\n",
            "   6.92212948e-02  1.33646322e+00 -3.78057953e-01 -5.42159697e-01\n",
            "  -3.23897317e-01  8.21199724e-01 -1.70151847e+00  9.09132414e-01\n",
            "  -1.59992904e+00 -6.19491307e-01 -5.57388580e-01  5.02382115e-01\n",
            "   5.15559232e-01  1.28466815e-01 -3.33609870e-01  7.99153279e-02\n",
            "  -1.66083796e+00  1.22090311e+00 -1.34273501e+00 -1.78753484e-01\n",
            "   1.82729850e-01 -1.39154862e-02 -1.59339662e+00  3.16921429e-01]\n",
            " [ 7.37761008e-01 -9.46961281e-01 -1.47024539e+00  9.46775197e-01\n",
            "   2.33166170e-02  9.21504009e-01  1.54358245e-01 -2.27855689e-03\n",
            "   3.12725196e-01  9.65289520e-01 -5.95892169e-01 -9.09591683e-01\n",
            "   8.44490341e-01 -6.37245494e-01 -4.61756907e-01 -1.38998458e+00\n",
            "  -9.23998661e-02 -1.86862577e+00 -2.08263384e-01 -5.27740134e-01\n",
            "   5.66111996e-02  8.22140218e-01  4.63936202e-01 -1.01509963e-01\n",
            "   9.34357698e-03  9.32540576e-01 -3.48067251e-01 -1.88566119e+00\n",
            "   9.07525985e-01 -1.00740035e+00 -3.35249590e-01 -1.09442895e+00]\n",
            " [ 1.59218677e+00  1.11292596e+00  1.40546524e-01  1.36698449e+00\n",
            "   1.12021967e-01 -1.13159298e+00  2.27050834e-01  8.36568864e-01\n",
            "  -7.86243621e-01 -1.47564696e+00  2.44272148e-01 -3.25818986e-01\n",
            "   1.52752584e+00  6.51703473e-01 -6.91517563e-01  1.06666092e-01\n",
            "  -1.13948636e+00  1.16173273e+00 -1.39152253e+00  6.11452617e-01\n",
            "   7.90419984e-01  8.98064595e-01 -1.37822344e-01  2.82254603e-01\n",
            "  -9.35200221e-01 -7.50655653e-01 -2.38857785e+00  8.25553309e-01\n",
            "  -1.01818380e+00  2.73065282e+00  3.63186467e-01  6.24530224e-01]\n",
            " [-8.09631351e-02 -1.24903781e+00 -1.16545184e+00  1.84023274e-01\n",
            "  -2.22183847e-01 -1.39380868e+00  2.84338780e-01 -8.09297465e-01\n",
            "  -1.95498640e-01  1.35862335e+00 -5.40610585e-01 -1.13822174e+00\n",
            "  -9.72738296e-01  1.13230526e+00  9.73326396e-01 -8.24481212e-01\n",
            "   1.79196898e+00 -3.04789052e-02 -1.59596969e+00  6.00269689e-01\n",
            "  -1.74375834e+00  4.48590180e-01 -1.79705261e+00  5.12058925e-01\n",
            "  -1.25266605e+00  2.56226578e-01  2.70550344e+00  6.01127069e-01\n",
            "  -1.85269765e+00 -6.30585090e-01 -2.77994493e+00 -8.33659864e-01]\n",
            " [-1.07829954e+00 -5.08392246e-01 -3.49652679e-01 -5.89874314e-02\n",
            "   8.64868699e-02  6.25342366e-01 -1.28202075e+00 -1.08659338e+00\n",
            "  -6.96750453e-01 -9.46057607e-01 -4.53976105e-01  5.07088592e-01\n",
            "   1.60669808e+00 -1.49599399e+00 -1.19486588e+00  6.22598246e-01\n",
            "  -1.59105794e+00 -3.37343195e-02  8.01862174e-01 -1.39399717e+00\n",
            "  -4.67466457e-01 -2.91758514e-01  2.06581109e-01  5.64035238e-01\n",
            "   2.68214687e-01 -1.22387593e+00  1.90412767e-01  3.63093104e-01\n",
            "   4.17923605e-01 -5.68641074e-01 -2.38983154e-01 -4.53840020e-01]\n",
            " [-2.68374208e-01 -4.58903462e-01 -6.01552639e-01  1.41884523e+00\n",
            "  -3.09758387e-01 -1.43518863e+00 -1.64544022e-01 -8.19173301e-01\n",
            "   1.04118975e+00 -9.55708485e-01 -3.24021896e-01  1.00905956e+00\n",
            "   2.83271228e-01 -9.82787319e-01 -2.02011010e-01  1.06030162e+00\n",
            "   1.14962708e+00  9.99317981e-01 -1.34810414e-01  3.35323977e-01\n",
            "   1.50845529e+00  1.20545204e+00 -3.49613223e-01 -6.13279791e-01\n",
            "  -1.21891341e+00 -2.55989774e-01  1.34865070e+00  1.30515558e+00\n",
            "   5.40928591e-01  1.30188856e-01  5.99198311e-01 -3.76416005e-01]\n",
            " [ 1.09888468e+00  4.53007304e-01 -1.75492787e+00 -4.55853825e-01\n",
            "   1.38052914e+00 -3.85030192e-01  5.05478768e-01  1.29687471e-01\n",
            "  -6.29134101e-01 -1.27333688e+00 -1.11303997e+00 -1.79825487e+00\n",
            "   1.00979203e+00  7.07428764e-01 -2.32113792e-01 -4.73994239e-01\n",
            "  -3.95981065e-01 -1.02376175e-01 -7.67031362e-01  1.49962524e+00\n",
            "  -6.40417728e-02  2.67209028e-01  1.60998663e+00 -4.92765391e-01\n",
            "  -8.55923940e-01 -3.63313759e-01  1.67490822e+00 -5.13394497e-01\n",
            "   4.51757872e-01 -9.99614658e-01 -2.34684910e-01  1.06217175e+00]\n",
            " [ 3.53431252e-01  1.48090986e+00 -2.59318522e-01 -8.15974840e-01\n",
            "   5.47548579e-01 -1.52108990e+00  3.36250725e-01  1.41592354e+00\n",
            "   1.25618635e+00 -5.43668301e-01  7.57326293e-02 -3.12837465e-01\n",
            "  -1.07475859e-01 -7.71777271e-01  4.26608295e-01  7.18501228e-01\n",
            "  -2.02291131e-01  1.33903378e+00 -8.78660736e-01  1.31399629e+00\n",
            "  -2.61276692e-01 -1.03202494e+00 -8.37743734e-01 -5.36047772e-01\n",
            "  -9.97887228e-01 -8.02789015e-01 -1.43422093e-01  7.16390691e-01\n",
            "   2.40329779e+00 -6.36957584e-01 -1.83317398e-01 -1.54449834e+00]\n",
            " [ 6.52164928e-01 -2.36347100e-02  1.61296118e+00  2.86244332e+00\n",
            "   2.26184271e-01  5.78523682e-01 -1.73758850e-01 -2.26910927e-02\n",
            "   3.63405912e-01 -6.37987093e-01  3.97738895e-01 -9.08112902e-01\n",
            "  -5.58666603e-01  3.28333379e-01 -1.50070592e-01 -1.61316804e-01\n",
            "  -1.55620363e+00 -1.41695355e+00 -5.03429543e-01  2.81248113e-01\n",
            "   6.29434981e-01  7.01984132e-02  7.68925717e-01 -7.11826093e-01\n",
            "  -1.75072420e-01  5.69137703e-01 -3.13712176e-01 -2.60065316e-01\n",
            "   4.09443288e-01  2.10935301e+00 -4.10789080e-02 -9.39438153e-01]\n",
            " [-7.45276775e-01 -1.29485184e+00  1.88991373e-01 -1.20359191e+00\n",
            "  -7.40866132e-01  1.61796236e+00  1.83888763e+00  8.38364227e-02\n",
            "  -3.81950273e-01  2.51187762e-01 -1.60772513e+00  1.45391016e+00\n",
            "  -8.54129189e-02  9.63559607e-01 -6.06228374e-01 -1.48825093e+00\n",
            "  -1.24306146e+00  9.60771033e-01 -1.68702556e-01 -1.14461188e-01\n",
            "   1.01777871e+00  7.05229999e-01 -6.22599960e-01 -8.74035435e-01\n",
            "   2.71553302e-01 -8.13735767e-02  1.25762848e+00 -1.13024192e+00\n",
            "  -1.10640029e-01 -1.44491015e+00  2.38632775e-01 -4.67949365e-01]\n",
            " [-6.30314114e-01  3.88344187e-02 -2.46778950e-01  8.65802181e-01\n",
            "   8.32315473e-01  2.91363237e-01 -5.53561794e-01 -4.57458480e-01\n",
            "  -2.73759796e-01 -7.47286259e-01 -1.08882181e-01  1.00704741e+00\n",
            "  -9.72216234e-01 -9.84708004e-01  8.75350638e-01  3.81656111e-01\n",
            "   1.59315726e+00  2.07180738e-01 -8.62427231e-01 -1.30086976e+00\n",
            "  -4.06913373e-01 -1.59623795e+00 -4.59875014e-01 -7.79162072e-02\n",
            "  -1.29417670e+00 -1.67139285e+00  3.80930456e-01  5.79262284e-01\n",
            "   7.59428564e-01  9.61292686e-01 -5.54182638e-01 -5.93218335e-01]\n",
            " [-1.59186793e+00  1.32661364e+00 -1.42440488e-01  7.57068268e-03\n",
            "   1.44854743e+00  2.41208329e-01 -1.06845189e-01  3.74701246e-01\n",
            "  -2.35798000e-02 -1.35139875e-01  1.30817115e+00  2.33340020e-01\n",
            "   7.93897844e-01 -7.28599404e-01  2.25622463e+00  9.21638085e-01\n",
            "   1.04257460e+00 -3.95332238e-01 -2.07881616e+00  1.22754615e+00\n",
            "  -1.19196520e-01  4.78114496e-01 -1.37991035e+00 -5.52641769e-01\n",
            "  -3.28789315e-01 -8.00339714e-01 -1.84572289e-01  1.13407090e-01\n",
            "  -5.66882766e-01  9.81281195e-01  1.14188099e-01 -1.57353247e-01]\n",
            " [ 9.77585620e-01 -3.12797963e-01 -2.53188842e-01 -1.43253806e+00\n",
            "   4.25560811e-01 -1.99870533e+00  3.46893855e-02 -1.78318311e+00\n",
            "  -1.62018595e-02  7.20446571e-01  1.20628544e+00 -6.28113005e-01\n",
            "   3.44692884e-01  1.18251498e+00  5.43810339e-01 -1.44754902e-02\n",
            "   1.05669898e+00  8.69082254e-01 -1.22661626e+00 -2.10095732e-01\n",
            "  -4.55448320e-01 -7.40290051e-01  1.02495334e+00 -8.59823453e-01\n",
            "  -1.04016033e+00 -9.90147965e-01  8.79438830e-01  6.03769603e-01\n",
            "   7.56149700e-01  7.38310939e-01 -7.91836277e-02 -2.55520243e-01]\n",
            " [ 6.76117955e-01  1.01661794e+00 -9.43491378e-01 -2.06736445e-01\n",
            "  -9.57076389e-01 -7.14728902e-01  1.26190253e+00 -5.48831604e-03\n",
            "   5.36498443e-01 -1.16906711e+00 -1.27693765e+00 -8.55370045e-01\n",
            "   9.19094886e-01  1.49139248e+00 -3.25550497e-01  1.82579654e+00\n",
            "  -6.60477043e-01  1.15965628e+00  4.54618631e-01 -6.10442215e-02\n",
            "   4.35726200e-01  1.81346705e-01 -4.88118274e-01  1.34226244e+00\n",
            "  -6.40959007e-01  3.65159296e-01  5.24054711e-01  5.36578549e-01\n",
            "   4.38507984e-03  6.11563385e-01  2.42613468e+00  1.03734349e-01]\n",
            " [ 7.92480668e-01  3.61338899e-01 -4.38556746e-01  1.78541358e+00\n",
            "  -9.87072359e-01  1.47585595e+00 -4.63038256e-01 -1.32667867e+00\n",
            "   2.16505063e-02  4.04425770e-02  9.09407929e-01 -2.14241051e-01\n",
            "  -9.87558423e-01 -1.58773616e+00  1.51592153e+00 -4.04885902e-01\n",
            "  -6.75283670e-01  5.85956688e-01 -6.40547163e-01 -1.81095462e-01\n",
            "  -1.38738758e+00 -1.11434841e+00  1.97004559e-01  1.70259667e+00\n",
            "  -8.40833617e-01 -1.33900378e+00  7.03490095e-01 -7.40392797e-01\n",
            "  -5.43307784e-01  6.83954924e-01  5.14209241e-01 -2.22331062e+00]]\n",
            "[ 15]\n",
            "[ 16]\n",
            "[ 17]\n",
            "[ 18]\n",
            "[ 19]\n",
            "[  0]\n",
            "[  1]\n",
            "[  2]\n",
            "[  3]\n",
            "[  4]\n",
            "[  5]\n",
            "[  6]\n",
            "[  7]\n",
            "[  8]\n",
            "[  9]\n",
            "[ 10]\n",
            "[ 11]\n",
            "[ 12]\n",
            "[ 13]\n",
            "[ 14]\n",
            "[ 20]\n",
            "[ 21]\n",
            "[ 22]\n",
            "[ 23]\n",
            "[ 24]\n",
            "[ 25]\n",
            "[ 26]\n",
            "[ 27]\n",
            "[ 28]\n",
            "[ 29]\n",
            "[ 30]\n",
            "[ 31]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKqSBrIPz32K",
        "colab_type": "text"
      },
      "source": [
        "#### Permute Lambda\n",
        "\n",
        "The below function takes in Lambda and an `approximate minimum degree` permutation vector and applies the permutation to Lambda. (This function is mainly just applied to make it clearer where we are applying the permutation).\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        " - Lambda: The \n",
        " - nparams: The number of parameters vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is9Rmt0fz4BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def permuteLambda(Lambda, P):\n",
        "  \n",
        "  return(Lambda[:,P])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZhUF3lKvWXw",
        "colab_type": "text"
      },
      "source": [
        "### Apply 3D mapping function\n",
        "\n",
        "The below function applies a mapping to a vector of parameters for a list of voxels.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **theta**: the vector of theta parameters for all voxels (i.e. if one voxel has 6 parameters and there are 10 voxels, then theta is 60 by 1 and laid out as [$p_1$,$p_2$,...,$p_{10}$] where $p_n$ is the parameter vector for voxel n.\n",
        " - **v_inds**: A vector specifying which voxel each entry in the theta vector belongs to. E.g. v_inds[i]=j means the $i^{th}$ parameter entry belongs to voxel $j$.\n",
        " - **t_inds**: A vector specifying how many times each theta parameter should be repeated. For example, if theta=[0.1,0.8,0.3] and theta_inds=[0,0,0,1,2,2], then the values to be mapped into the sparse matrix would be [0.1,0.1,0.1,0.8,0.3,0.3].\n",
        " - **r_inds**: The row indices of the elements mapped into the sparse matrix.\n",
        " - **c_inds**: The column indices of the elements mapped into the sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcdMAE1syUfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "ca9c9a0a-4884-46b5-de5a-922240eecced"
      },
      "source": [
        "def mapping_3D(theta, v_inds, t_inds, r_inds, c_inds):\n",
        "  \n",
        "  # Create the coordinate matrix\n",
        "  coords = np.array([v_inds, r_inds, c_inds])\n",
        "\n",
        "  # Create Lambda\n",
        "  lam = sparse.COO(coords, theta[t_inds.astype(np.int64)].tolist(), shape=(np.max(v_inds)+1,np.max(r_inds)+1,np.max(c_inds)+1))\n",
        "\n",
        "  return(lam)\n",
        "\n",
        "# Random theta to test with\n",
        "print(len(vox_indices_3D))\n",
        "print(len(theta_indices_3D))\n",
        "print(len(row_indices_3D))\n",
        "print(len(col_indices_3D))\n",
        "print(np.max(theta_indices_3D))\n",
        "print(nv)\n",
        "print((np.sum((nparams*(nparams+1)/2)))*nv)\n",
        "print(np.int16((np.sum((nparams*(nparams+1)/2)))*nv))\n",
        "theta = np.random.randn(np.int64((np.sum((nparams*(nparams+1)/2)))*nv))\n",
        "\n",
        "print(theta.shape)\n",
        "\n",
        "# Get lambda\n",
        "lam = mapping_3D(theta, vox_indices_3D, theta_indices_3D, row_indices_3D, col_indices_3D)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2268000\n",
            "2268000\n",
            "2268000\n",
            "2268000\n",
            "566999\n",
            "27000\n",
            "567000.0\n",
            "-22824\n",
            "(567000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kg_SG7m8vsI",
        "colab_type": "text"
      },
      "source": [
        "#### Initial Theta function\n",
        "\n",
        "The below function calculates the initial theta vector for the whole brain.\n",
        "\n",
        "---\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        " - nv: The number of voxels.\n",
        " - nparams: The number of parameters vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTBeQKxE8v2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_theta(nv, nparams):\n",
        "  \n",
        "  # Get the initial parameter values for a single voxel\n",
        "  # These are given by the lower triangle of an identity\n",
        "  # for each factor of size #params by #params\n",
        "  init_theta_tmp = np.array([])\n",
        "  for nump in nparams:\n",
        "    \n",
        "    I = np.eye(nump)\n",
        "    lower = I[np.tril_indices(nump)]\n",
        "    init_theta_tmp = np.hstack((init_theta_tmp, np.array(lower[:])))\n",
        "    \n",
        "  # Repeat for all voxels and return.\n",
        "  return(np.tile(init_theta_tmp, reps=nv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbsGqStlYAas",
        "colab_type": "text"
      },
      "source": [
        "#### Broadcasted PLS function\n",
        "\n",
        "Commented lines still need doing... documentation also coming soon..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkkDPCSRYG-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "386c09b8-9bd1-4ba9-d715-2536b2c30e94"
      },
      "source": [
        "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
        "import dask\n",
        "\n",
        "def PLS_broadcasted(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds):\n",
        "    \n",
        "    t1 = time.time()\n",
        "    # Obtain Lambda and Lambda*P\n",
        "    Lambda = mapping_3D(theta[:], vinds, tinds, rinds, cinds_permuted)\n",
        "    #LambdaP = mapping_3D(theta[:], vinds, tinds, rinds, cinds)\n",
        "    \n",
        "    print('1')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'\n",
        "    Lambdat = Lambda.transpose((0,2,1))\n",
        "\n",
        "    print('2')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'Z'Y and Lambda'Z'X\n",
        "    LambdatZtY = da.matmul(Lambdat,ZtY).rechunk((16000, 10, 1)) #### SLOW: PRESUMABLY COS LAM NOT DASK ARRAY\n",
        "    LambdatZtX = da.matmul(Lambdat,ZtX).rechunk((100, 400, 400))\n",
        "\n",
        "    print('3')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain the cholesky decomposition \n",
        "    LambdatZtZLambda = da.matmul(da.matmul(Lambdat,ZtZ),Lambda)\n",
        "    I = da.eye(Lambda.shape[1], chunks=4000).map_blocks(sparse.COO).rechunk('auto') #fast - could be removed though\n",
        "    \n",
        "    print('4')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    print((LambdatZtZLambda+I).shape)\n",
        "    \n",
        "    # Get P in numpy format\n",
        "    P_np = np.array(P[:]).reshape(P.size[0])\n",
        "    \n",
        "    # Permute lambda'Z'X and lambda'Z'Y\n",
        "    print(LambdatZtX.chunks)\n",
        "    #LambdatZtXP = LambdatZtX[:,P_np,:].compute() #NB - about half a second\n",
        "    \n",
        "    LambdatZtXP, LambdatZtYP = dask.compute(LambdatZtX[:,P_np,:], LambdatZtY[:,P_np,:])\n",
        "    print('5')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    print(LambdatZtY.shape)\n",
        "    print(LambdatZtY.chunks)\n",
        "    #LambdatZtYP = LambdatZtY[:,P_np,:].compute() # 86 seconds? Weird\n",
        "    \n",
        "    \n",
        "    print('6')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Add identity to Lambda'Z'ZLambda\n",
        "    LambdatZtZLambdaplusI = LambdatZtZLambda + I\n",
        "    LambdatZtZLambdaplusI = LambdatZtZLambdaplusI.compute() # 27 seconds - Probably chunking problems\n",
        "    \n",
        "    print('7')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Initialize empty arrays to store RZX and Cu\n",
        "    RZX = np.zeros((Lambda.shape[0], ZtZ.shape[1], XtX.shape[1]))\n",
        "    Cu = np.zeros((Lambda.shape[0], ZtZ.shape[1], 1))\n",
        "    L = np.zeros((Lambda.shape[0], ZtZ.shape[1], ZtZ.shape[1])) # All fast - 0.4s-ish\n",
        "    \n",
        "    print('8')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    for i in np.arange(Lambda.shape[0]):\n",
        "      print(i)\n",
        "      \n",
        "      # Perform sparse cholesky on lambda'Z'Zlambda + I\n",
        "      data = LambdatZtZLambdaplusI[i,:,:].data\n",
        "      coords = LambdatZtZLambdaplusI[i,:,:].coords\n",
        "      chol_dict = sparse_chol(spmatrix(data, coords[0,:],coords[1,:],size=(Lambda.shape[1],Lambda.shape[1])), perm=P, retF=True, retP=False, retL=False)\n",
        "      F = chol_dict['F']\n",
        "      \n",
        "      # Obtain Cu\n",
        "      Cu_tmp = matrix(LambdatZtYP[i,:,:])\n",
        "      cholmod.solve(F,Cu_tmp,sys=4)\n",
        "      \n",
        "      # Save Cu\n",
        "      Cu[i,:,:] = np.array(Cu_tmp)\n",
        "      \n",
        "      # Obtain RZX\n",
        "      RZXtmp = matrix(LambdatZtXP[i,:,:])\n",
        "      cholmod.solve(F,RZXtmp,sys=4)\n",
        "      \n",
        "      # Save RZX\n",
        "      RZX[i,:,:] = np.array(RZXtmp)\n",
        "    \n",
        "      # Obtain L (for later - note: has to be done last as this changes F)\n",
        "      Ltmp=cholmod.getfactor(F)\n",
        "      L[i,:,:] = np.array(matrix(Ltmp))\n",
        "      \n",
        "    \n",
        "    print('9')# Shockingly fast - 23.156267166137695\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "      \n",
        "    # Obtain RXtRX\n",
        "    RZX = da.from_array(RZX, chunks=(100, 400, 400))\n",
        "    RXtRX = XtX - da.matmul(RZX.transpose(0,2,1),RZX)\n",
        "    \n",
        "\n",
        "    # Obtain beta estimates \n",
        "    Cu = da.from_array(Cu, chunks=(400, 400, 1))\n",
        "    XtYminusRZXtCu = XtY - da.matmul(RZX.transpose(0,2,1),Cu)\n",
        "    \n",
        "    #Get betahat\n",
        "    RXtRX, XtYminusRZXtCu = dask.compute(RXtRX, XtYminusRZXtCu)\n",
        "    betahat = da.from_array(np.linalg.solve(RXtRX, XtYminusRZXtCu), chunks=(100, 400, 400))\n",
        "    print(time.time()-t1)\n",
        "    betahat = da.apply_gufunc(np.linalg.solve,  \"(i,j),(i,k)->(j,k)\", RXtRX, XtYminusRZXtCu, vectorize=True,output_dtypes=RXtRX.dtype).rechunk('auto') # suspected time kill\n",
        "    \n",
        "    \n",
        "    \n",
        "    print('10') #5s\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain L\n",
        "    # Obtain RXtRX\n",
        "    L = da.from_array(L, chunks=(100, 400, 400))\n",
        "    \n",
        "    \n",
        "    print('11')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain u estimates\n",
        "    CuminusRZXbetahat = Cu - da.matmul(RZX, betahat)\n",
        "    \n",
        "    #Get betahat\n",
        "    uhat = da.apply_gufunc(np.linalg.solve,  \"(i,j),(i,k)->(j,k)\", L.transpose(0,2,1), CuminusRZXbetahat, vectorize=True,output_dtypes=RXtRX.dtype).rechunk('auto')\n",
        "    \n",
        "    print('12')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    print(L.shape)\n",
        "    print(CuminusRZXbetahat.shape)\n",
        "    print(uhat.shape)\n",
        "    \n",
        "    # Permute U from the left to make the correct uhat\n",
        "    uhat = uhat[:,P_np,:]\n",
        "\n",
        "    # Obtain b estimates\n",
        "    print(Lambda.shape)\n",
        "    print(uhat.shape)\n",
        "    bhat = da.matmul(Lambda,uhat)\n",
        "\n",
        "    # Obtain residuals sum of squares\n",
        "    resss = YtY-2*da.matmul(YtX,betahat)-2*da.matmul(YtZ,bhat)+2*da.matmul(da.matmul(betahat.transpose(0,2,1),XtZ),bhat)+da.matmul(betahat.transpose(0,2,1),da.matmul(XtX,betahat))+da.matmul(bhat.transpose(0,2,1),da.matmul(ZtZ,bhat))\n",
        "\n",
        "    # Obtain penalised residual sum of squares\n",
        "    pss = (resss + da.matmul(uhat.transpose(0,2,1),uhat)).compute()\n",
        "\n",
        "    print('13')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain Log(|L|^2)\n",
        "    #logdet = 2*da.trace(da.log(L))\n",
        "    logdet = 2*np.sum(np.log(np.diagonal(L.compute(),axis1=1,axis2=2)))\n",
        "\n",
        "    print('14')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    # Obtain log likelihood\n",
        "    logllh = -logdet/2-n/2*(1+da.log(2*np.pi*pss)-np.log(n))\n",
        "\n",
        "    print('15')\n",
        "    print(time.time()-t1)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    return(-logllh)\n",
        "\n",
        "# Make the initial theta estimate\n",
        "theta0 = init_theta(nv,nparams)\n",
        "\n",
        "# Obtain the mapping indices\n",
        "tinds, rinds, cinds, cinds_permuted, vinds = get_3D_mapping(nlevels, nparams, nv, P)\n",
        "\n",
        "t1 = time.time()\n",
        "llhmap = PLS_broadcasted(theta0, ZtX_da, ZtY_da, XtX_da, ZtZ_da, XtY_da, YtX_da, YtZ_da, XtZ_da, YtY_da, P, n, tinds, rinds, cinds, cinds_permuted, vinds)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print((t2-t1)*1000*100/(60*60))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "invP\n",
            "<class 'numpy.ndarray'>\n",
            "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31]\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-31ee7af84707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0mllhmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLS_broadcasted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZtX_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZtY_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtX_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZtZ_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtY_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtX_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtZ_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtZ_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtY_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcinds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcinds_permuted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvinds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ZtX_da' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb75nTHT6R6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cvxopt2Scipy(M):\n",
        "  \n",
        "  Vdim = M.V.size[0]*M.V.size[1]\n",
        "  Idim = M.I.size[0]*M.I.size[1]\n",
        "  Jdim = M.J.size[0]*M.J.size[1]\n",
        "  V = np.array(M.V).reshape(Vdim)\n",
        "  I = np.array(M.I).reshape(Idim)\n",
        "  J = np.array(M.J).reshape(Jdim)\n",
        "  \n",
        "  return(scipy.sparse.coo_matrix((V,(I,J))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9-EHSWWr9NP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "eae54196-724e-44c3-b2b6-b11e7d8e397f"
      },
      "source": [
        "def PLS_broadcasted2(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds):\n",
        "    print('running_it')\n",
        "    #ZtX_ov = cvxopt.matrix(ZtX[0,:,:]) \n",
        "    #ZtY_ov = cvxopt.matrix(ZtY[10,:,:])\n",
        "    #XtX_ov = cvxopt.matrix(XtX[0,:,:])\n",
        "    #ZtZ_ov = cvxopt.sparse(cvxopt.matrix(ZtZ[0,:,:]))\n",
        "    #XtY_ov = cvxopt.matrix(XtY[10,:,:])\n",
        "    #YtX_ov = cvxopt.matrix(YtX[10,:,:])\n",
        "    #YtZ_ov = cvxopt.matrix(YtZ[10,:,:])\n",
        "    #XtZ_ov = cvxopt.matrix(XtZ[0,:,:])\n",
        "    #YtY_ov = cvxopt.matrix(YtY[10,:,:])\n",
        "    \n",
        "    #t1 = time.time()\n",
        "    # Obtain Lambda and Lambda*P\n",
        "    Lambda = mapping_3D(theta[:], vinds, tinds, rinds, cinds)\n",
        "    #LambdaP = mapping_3D(theta[:], vinds, tinds, rinds, cinds)\n",
        "    \n",
        "    #theta_ov = theta[0:(len(theta)//ZtY.shape[0])]\n",
        "    #tinds_ov,rinds_ov,cinds_ov=get_mapping(nlevels, nparams)\n",
        "    #Lambda_ov = mapping(theta_ov, tinds_ov, rinds_ov, cinds_ov)\n",
        "    #print('lambda check')\n",
        "    #print(type(cvxopt2Scipy(Lambda_ov)))\n",
        "    #print(type(Lambda[10,:,:]))\n",
        "    #print((cvxopt2Scipy(Lambda_ov) - Lambda[10,:,:].to_scipy_sparse()).toarray())\n",
        "    \n",
        "    \n",
        "    #print('1')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'\n",
        "    Lambdat = sparse.COO(Lambda.transpose((0,2,1)))\n",
        "    #Lambdat_ov = spmatrix.trans(Lambda_ov)\n",
        "    #print('lambda transpose check')\n",
        "    #print((cvxopt2Scipy(Lambdat_ov) - Lambdat[10,:,:].to_scipy_sparse()).toarray())\n",
        "    \n",
        "    #print('2')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'Z'Y and Lambda'Z'X\n",
        "    LambdatZtY = np.matmul(Lambdat,ZtY)\n",
        "    LambdatZtX = np.matmul(Lambdat,ZtX)\n",
        "    \n",
        "    #LambdatZtY_ov = Lambdat_ov*ZtY_ov\n",
        "    #LambdatZtX_ov = Lambdat_ov*ZtX_ov\n",
        "    #print('Lambda ZtY check')\n",
        "    #print(type(LambdatZtY[10,:,:]))\n",
        "    #print(type(LambdatZtY_ov))\n",
        "    #print(np.array(LambdatZtY_ov)-np.array(LambdatZtY[10,:,:]))\n",
        "    #print('Lambda ZtX check')\n",
        "    #print(type(LambdatZtX[10,:,:]))\n",
        "    #print(type(LambdatZtX_ov))\n",
        "    #print(np.array(LambdatZtX_ov)-np.array(LambdatZtX[10,:,:]))\n",
        "    \n",
        "\n",
        "    #print('3')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    ZtZLambda = np.matmul(ZtZ,Lambda)\n",
        "    #ZtZLambda_ov = ZtZ_ov*Lambda_ov\n",
        "    #print(np.array(ZtZLambda[10,:,:])-np.array(cvxopt.matrix(ZtZLambda_ov)))\n",
        "    #print(type(ZtZLambda))\n",
        "    #print(type(ZtZLambda_ov))\n",
        "    # Obtain the cholesky decomposition \n",
        "    LambdatZtZLambda = np.matmul(np.matmul(Lambdat,ZtZ),Lambda)\n",
        "    #LambdatZtZLambda_ov = Lambdat_ov*(ZtZ_ov*Lambda_ov)\n",
        "    I = np.eye(Lambda.shape[1])\n",
        "    \n",
        "    \n",
        "    #print('Lambdat ZtZ Lambda check')\n",
        "    #print(np.array(LambdatZtZLambda[10,:,:])-np.array(cvxopt.matrix(LambdatZtZLambda_ov)))\n",
        "    \n",
        "    #print('4')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #print((LambdatZtZLambda+I).shape)\n",
        "    \n",
        "    # Get P in numpy format\n",
        "    P_np = np.array(P[:]).reshape(P.size[0])\n",
        "    \n",
        "    LambdatZtXP = LambdatZtX[:,P_np,:]\n",
        "    LambdatZtYP = LambdatZtY[:,P_np,:]\n",
        "    \n",
        "    #LambdatZtXP_ov = LambdatZtX_ov[P,:]\n",
        "    #LambdatZtYP_ov = LambdatZtY_ov[P,:]\n",
        "    \n",
        "    #print('permuted ZtX check')\n",
        "    #print(np.array(LambdatZtXP[10,:,:])-np.array(LambdatZtXP_ov))\n",
        "    #print('permuted ZtY check')\n",
        "    #print(np.array(LambdatZtYP[10,:,:])-np.array(LambdatZtYP_ov))\n",
        "    \n",
        "    #print('5')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    #LambdatZtYP = LambdatZtY[:,P_np,:].compute() # 86 seconds? Weird\n",
        "    \n",
        "    \n",
        "    #print('6')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Add identity to Lambda'Z'ZLambda\n",
        "    LambdatZtZLambdaplusI = LambdatZtZLambda + I\n",
        "    \n",
        "    #print('7')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Initialize empty arrays to store RZX and Cu\n",
        "    RZX = np.zeros((Lambda.shape[0], ZtZ.shape[1], XtX.shape[1]))\n",
        "    Cu = np.zeros((Lambda.shape[0], ZtZ.shape[1], 1))\n",
        "    L = np.zeros((Lambda.shape[0], ZtZ.shape[1], ZtZ.shape[1])) # All fast - 0.4s-ish\n",
        "    \n",
        "    #print('8')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    for i in np.arange(Lambda.shape[0]):\n",
        "      #print(i)\n",
        "      \n",
        "      # Perform sparse cholesky on lambda'Z'Zlambda + I\n",
        "      #print(type(LambdatZtZLambdaplusI[i,:,:]))\n",
        "      chol_dict = sparse_chol(cvxopt.sparse(matrix(LambdatZtZLambdaplusI[i,:,:])), perm=P, retF=True, retP=False, retL=False)\n",
        "      F = chol_dict['F']\n",
        "      \n",
        "      # Obtain Cu\n",
        "      Cu_tmp = matrix(LambdatZtYP[i,:,:])\n",
        "      cholmod.solve(F,Cu_tmp,sys=4)\n",
        "      \n",
        "      # Save Cu\n",
        "      Cu[i,:,:] = np.array(Cu_tmp)\n",
        "      \n",
        "      # Obtain RZX\n",
        "      RZXtmp = matrix(LambdatZtXP[i,:,:])\n",
        "      cholmod.solve(F,RZXtmp,sys=4)\n",
        "      \n",
        "      # Save RZX\n",
        "      RZX[i,:,:] = np.array(RZXtmp)\n",
        "    \n",
        "      # Obtain L (for later - note: has to be done last as this changes F)\n",
        "      Ltmp=cholmod.getfactor(F)\n",
        "      L[i,:,:] = np.array(matrix(Ltmp))\n",
        "      \n",
        "      \n",
        "      \n",
        "      #if i == 10:\n",
        "        \n",
        "      #  print(ZtZ.shape)\n",
        "      #  print(ZtZ_ov.size)\n",
        "      #  I_ov = spmatrix(1.0, range(ZtZ_ov.size[1]), range(ZtZ_ov.size[1]))\n",
        "\n",
        "      #  print(type(LambdatZtZLambda_ov+I_ov))\n",
        "      #  print((LambdatZtZLambda_ov+I_ov).size)\n",
        "      #  chol_dict_ov = sparse_chol(LambdatZtZLambda_ov+I_ov, perm=P, retF=True, retP=False, retL=False)\n",
        "      #  F_ov = chol_dict_ov['F']\n",
        "        \n",
        "      #  Cu_ov = LambdatZtY_ov[P,:]\n",
        "      #  cholmod.solve(F_ov,Cu_ov,sys=4)\n",
        "        \n",
        "      #  print('Cu check')\n",
        "      #  print(Cu[10,:,:]-Cu_ov)\n",
        "        \n",
        "      #  RZX_ov = LambdatZtX_ov[P,:]\n",
        "      #  cholmod.solve(F_ov,RZX_ov,sys=4)\n",
        "        \n",
        "      #  print('RZX check')\n",
        "      #  print(RZX[10,:,:]-RZX_ov)\n",
        "        \n",
        "    \n",
        "    #print('9')# Shockingly fast - 23.156267166137695\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "      \n",
        "    # Obtain RXtRX\n",
        "    RXtRX = XtX - np.matmul(RZX.transpose(0,2,1),RZX)\n",
        "    \n",
        "    \n",
        "    #RXtRX_ov = XtX_ov - matrix.trans(RZX_ov)*RZX_ov\n",
        "\n",
        "    #print('RXtRX check')\n",
        "    #print(RXtRX_ov-RXtRX[10,:,:])\n",
        "    \n",
        "    # Obtain beta estimates \n",
        "    XtYminusRZXtCu = XtY - np.matmul(RZX.transpose(0,2,1),Cu)\n",
        "    \n",
        "    #XtYminusRZXtCu_ov = XtY_ov - matrix.trans(RZX_ov)*Cu_ov\n",
        "    \n",
        "    #print('XtY - RZXtCu check')\n",
        "    #print(XtYminusRZXtCu_ov - XtYminusRZXtCu[10,:,:])\n",
        "    \n",
        "    #Get betahat\n",
        "    betahat = np.linalg.solve(RXtRX, XtYminusRZXtCu)\n",
        "    \n",
        "    \n",
        "    #betahat_ov = XtY_ov - matrix.trans(RZX_ov)*Cu_ov\n",
        "    #lapack.posv(RXtRX_ov, betahat_ov)\n",
        "    \n",
        "    #print('betahat check')\n",
        "    #print(betahat_ov-betahat[10,:,:])\n",
        "    \n",
        "    #print('10') #5s\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain L\n",
        "    # Obtain RXtRX\n",
        "    \n",
        "    \n",
        "    #print('11')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain u estimates\n",
        "    CuminusRZXbetahat = Cu - np.matmul(RZX, betahat)\n",
        "    \n",
        "    #Get betahat\n",
        "    uhat = np.linalg.solve(L.transpose(0,2,1), CuminusRZXbetahat)\n",
        "    \n",
        "    \n",
        "    #uhat_ov = Cu_ov-RZX_ov*betahat_ov\n",
        "    #cholmod.solve(F_ov,uhat_ov,sys=5)\n",
        "    #cholmod.solve(F_ov,uhat_ov,sys=8)\n",
        "    \n",
        "    #print('12')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #print(L.shape)\n",
        "    #print(CuminusRZXbetahat.shape)\n",
        "    #print(uhat.shape)\n",
        "    \n",
        "    # Permute U from the left to make the correct uhat\n",
        "    invP_np = np.arange(len(P_np))[np.argsort(P_np)]\n",
        "    uhat = uhat[:,invP_np,:]\n",
        "\n",
        "    #print('uhat check')\n",
        "    #print(uhat_ov - uhat[10,:,:])\n",
        "    \n",
        "    # Obtain b estimates\n",
        "    #print(Lambda.shape)\n",
        "    #print(uhat.shape)\n",
        "    bhat = np.matmul(Lambda,uhat)\n",
        "\n",
        "    #bhat_ov = Lambda_ov*uhat_ov\n",
        "    #print('bhat check')\n",
        "    #print(bhat_ov-bhat[10,:,:])\n",
        "    \n",
        "    # Obtain residuals sum of squares\n",
        "    resss = YtY-2*np.matmul(YtX,betahat)-2*np.matmul(YtZ,bhat)+2*np.matmul(np.matmul(betahat.transpose(0,2,1),XtZ),bhat)+np.matmul(betahat.transpose(0,2,1),np.matmul(XtX,betahat))+np.matmul(bhat.transpose(0,2,1),np.matmul(ZtZ,bhat))\n",
        "\n",
        "    #resss_ov = YtY_ov-2*YtX_ov*betahat_ov-2*YtZ_ov*bhat_ov+2*matrix.trans(betahat_ov)*XtZ_ov*bhat_ov+matrix.trans(betahat_ov)*XtX_ov*betahat_ov+matrix.trans(bhat_ov)*ZtZ_ov*bhat_ov\n",
        "   \n",
        "    #print('resss check')\n",
        "    #print(resss[10,:,:]-resss_ov)\n",
        "    \n",
        "    # Obtain penalised residual sum of squares\n",
        "    pss = resss + np.matmul(uhat.transpose(0,2,1),uhat)\n",
        "    #pss_ov = resss_ov + matrix.trans(uhat_ov)*uhat_ov\n",
        "\n",
        "    #print('pss check')\n",
        "    #print(pss[10,:,:]-pss_ov)\n",
        "    \n",
        "    #print('13')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Log(|L|^2)\n",
        "    #logdet = 2*da.trace(da.log(L))\n",
        "    #tmp = np.log(np.diagonal(L,axis1=1,axis2=2))\n",
        "    #print(tmp.shape)\n",
        "    #print(np.sum(tmp).shape)\n",
        "    #print(np.sum(tmp, axis=0).shape)\n",
        "    #print(np.sum(tmp, axis=1).shape)\n",
        "    #print(2*np.sum(np.log(np.diagonal(L,axis1=1,axis2=2)),axis=1).shape)\n",
        "    logdet = 2*np.sum(np.log(np.diagonal(L,axis1=1,axis2=2)),axis=1).reshape((nv,1,1))\n",
        "    #logdet_ov = 2*sum(cvxopt.log(cholmod.diag(F_ov)))\n",
        "    #print(logdet)\n",
        "    #print(logdet.shape)\n",
        "    #print('logdet check')\n",
        "    #print(logdet[10]-logdet_ov)\n",
        "    \n",
        "    #print('14')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain log likelihood\n",
        "    logllh = -logdet/2-n/2*(1+np.log(2*np.pi*pss)-np.log(n))\n",
        "\n",
        "    #print('15')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    return(np.amax(-logllh))\n",
        "\n",
        "    #return(-logllh)\n",
        "  \n",
        "# Make the initial theta estimate\n",
        "theta0 = init_theta(nv,nparams)\n",
        "\n",
        "# Obtain the mapping indices\n",
        "tinds, rinds, cinds, cinds_permuted, vinds = get_3D_mapping(nlevels, nparams, nv, P)\n",
        "\n",
        "t1 = time.time()\n",
        "llhmap = PLS_broadcasted2(theta0, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print((t2-t1)*100*100*100/(nv*60*60))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "invP\n",
            "<class 'numpy.ndarray'>\n",
            "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31]\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "running_it\n",
            "41.056034326553345\n",
            "0.42238718442956114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQC-daPsD8wz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "718f15e3-fd78-44e6-89f3-754cb373a8d3"
      },
      "source": [
        "print(llhmap.shape)\n",
        "llhmap_imageformat = llhmap.reshape((dimv[0],dimv[1],dimv[2]))\n",
        "\n",
        "imshow(llhmap_imageformat[1,:,:].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "\n",
        "plt.colorbar()\n",
        "\n",
        "print((t2-t1)*10/3*10/3*10/3*100/(60*60))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27000, 1, 1)\n",
            "48.44159255793064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD5CAYAAADlasS5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9krmSRHV47jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "adf92c66-3c45-49cb-b81d-1f258596fd28"
      },
      "source": [
        "print(type(theta0))\n",
        "print(len(theta0)/nv)\n",
        "\n",
        "theta0tmp = theta0[0:(len(theta0)//nv)]\n",
        "\n",
        "# Obtain a random Lambda matrix with the correct sparsity for the permutation vector\n",
        "tindstmp,rindstmp,cindstmp=get_mapping(nlevels, nparams)\n",
        "\n",
        "t1 = time.time()\n",
        "llh2map = np.zeros(nv)\n",
        "\n",
        "for i in np.arange(nv):\n",
        "  #print(i)\n",
        "  XtYtmp = matrix(XtY[i,:,:]) \n",
        "  ZtYtmp = matrix(ZtY[i,:,:]) \n",
        "  YtYtmp = matrix(YtY[i,:,:]) \n",
        "  YtZtmp = matrix(YtZ[i,:,:])\n",
        "  YtXtmp = matrix(YtX[i,:,:])\n",
        "  \n",
        "  llh2map[i] = PLS(theta0tmp, ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tindstmp, rindstmp, cindstmp)\n",
        "\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print((t2-t1)*10/3*10/3*10/3*100/(60*60))\n",
        "  \n",
        "print(llh2map.shape)\n",
        "llh2map_imageformat = llh2map.reshape((dimv[0],dimv[1],dimv[2]))\n",
        "\n",
        "imshow(llh2map_imageformat[1,:,:].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "plt.colorbar()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "21.0\n",
            "5.4115846157073975\n",
            "5.567473884472631\n",
            "(27000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9fc5e764e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD5CAYAAADlasS5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHjWoarZI7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6d66775d-aba1-40d6-df81-261dcd275e73"
      },
      "source": [
        "t1 = time.time()\n",
        "minimize(PLS_broadcasted3, theta0, args=(ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds), method='L-BFGS-B', tol=1e-6)\n",
        "print((time.time()-t1)*100*100*100/(nv*60*60))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running_it\n",
            "<class 'numpy.ndarray'>\n",
            "(27000, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6lhX5mjgLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7d7bbca4-1176-4877-e3ca-669f31ba4002"
      },
      "source": [
        "def PLS_broadcasted3(theta, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds):\n",
        "    print('running_it')\n",
        "    #ZtX_ov = cvxopt.matrix(ZtX[0,:,:]) \n",
        "    #ZtY_ov = cvxopt.matrix(ZtY[10,:,:])\n",
        "    #XtX_ov = cvxopt.matrix(XtX[0,:,:])\n",
        "    #ZtZ_ov = cvxopt.sparse(cvxopt.matrix(ZtZ[0,:,:]))\n",
        "    #XtY_ov = cvxopt.matrix(XtY[10,:,:])\n",
        "    #YtX_ov = cvxopt.matrix(YtX[10,:,:])\n",
        "    #YtZ_ov = cvxopt.matrix(YtZ[10,:,:])\n",
        "    #XtZ_ov = cvxopt.matrix(XtZ[0,:,:])\n",
        "    #YtY_ov = cvxopt.matrix(YtY[10,:,:])\n",
        "    \n",
        "    #t1 = time.time()\n",
        "    # Obtain Lambda and Lambda*P\n",
        "    Lambda = mapping_3D(theta[:], vinds, tinds, rinds, cinds)\n",
        "    #LambdaP = mapping_3D(theta[:], vinds, tinds, rinds, cinds)\n",
        "    \n",
        "    #theta_ov = theta[0:(len(theta)//ZtY.shape[0])]\n",
        "    #tinds_ov,rinds_ov,cinds_ov=get_mapping(nlevels, nparams)\n",
        "    #Lambda_ov = mapping(theta_ov, tinds_ov, rinds_ov, cinds_ov)\n",
        "    #print('lambda check')\n",
        "    #print(type(cvxopt2Scipy(Lambda_ov)))\n",
        "    #print(type(Lambda[10,:,:]))\n",
        "    #print((cvxopt2Scipy(Lambda_ov) - Lambda[10,:,:].to_scipy_sparse()).toarray())\n",
        "    \n",
        "    \n",
        "    #print('1')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'\n",
        "    Lambdat = sparse.COO(Lambda.transpose((0,2,1)))\n",
        "    #Lambdat_ov = spmatrix.trans(Lambda_ov)\n",
        "    #print('lambda transpose check')\n",
        "    #print((cvxopt2Scipy(Lambdat_ov) - Lambdat[10,:,:].to_scipy_sparse()).toarray())\n",
        "    \n",
        "    #print('2')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Lambda'Z'Y and Lambda'Z'X\n",
        "    LambdatZtY = np.matmul(Lambdat,ZtY)\n",
        "    LambdatZtX = np.matmul(Lambdat,ZtX)\n",
        "    \n",
        "    #LambdatZtY_ov = Lambdat_ov*ZtY_ov\n",
        "    #LambdatZtX_ov = Lambdat_ov*ZtX_ov\n",
        "    #print('Lambda ZtY check')\n",
        "    #print(type(LambdatZtY[10,:,:]))\n",
        "    #print(type(LambdatZtY_ov))\n",
        "    #print(np.array(LambdatZtY_ov)-np.array(LambdatZtY[10,:,:]))\n",
        "    #print('Lambda ZtX check')\n",
        "    #print(type(LambdatZtX[10,:,:]))\n",
        "    #print(type(LambdatZtX_ov))\n",
        "    #print(np.array(LambdatZtX_ov)-np.array(LambdatZtX[10,:,:]))\n",
        "    \n",
        "\n",
        "    #print('3')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    ZtZLambda = np.matmul(ZtZ,Lambda)\n",
        "    #ZtZLambda_ov = ZtZ_ov*Lambda_ov\n",
        "    #print(np.array(ZtZLambda[10,:,:])-np.array(cvxopt.matrix(ZtZLambda_ov)))\n",
        "    #print(type(ZtZLambda))\n",
        "    #print(type(ZtZLambda_ov))\n",
        "    # Obtain the cholesky decomposition \n",
        "    LambdatZtZLambda = np.matmul(np.matmul(Lambdat,ZtZ),Lambda)\n",
        "    #LambdatZtZLambda_ov = Lambdat_ov*(ZtZ_ov*Lambda_ov)\n",
        "    I = np.eye(Lambda.shape[1])\n",
        "    \n",
        "    \n",
        "    #print('Lambdat ZtZ Lambda check')\n",
        "    #print(np.array(LambdatZtZLambda[10,:,:])-np.array(cvxopt.matrix(LambdatZtZLambda_ov)))\n",
        "    \n",
        "    #print('4')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #print((LambdatZtZLambda+I).shape)\n",
        "    \n",
        "    # Get P in numpy format\n",
        "    P_np = np.array(P[:]).reshape(P.size[0])\n",
        "    \n",
        "    LambdatZtXP = LambdatZtX[:,P_np,:]\n",
        "    LambdatZtYP = LambdatZtY[:,P_np,:]\n",
        "    \n",
        "    #LambdatZtXP_ov = LambdatZtX_ov[P,:]\n",
        "    #LambdatZtYP_ov = LambdatZtY_ov[P,:]\n",
        "    \n",
        "    #print('permuted ZtX check')\n",
        "    #print(np.array(LambdatZtXP[10,:,:])-np.array(LambdatZtXP_ov))\n",
        "    #print('permuted ZtY check')\n",
        "    #print(np.array(LambdatZtYP[10,:,:])-np.array(LambdatZtYP_ov))\n",
        "    \n",
        "    #print('5')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    #LambdatZtYP = LambdatZtY[:,P_np,:].compute() # 86 seconds? Weird\n",
        "    \n",
        "    \n",
        "    #print('6')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Add identity to Lambda'Z'ZLambda\n",
        "    LambdatZtZLambdaplusI = LambdatZtZLambda + I\n",
        "    \n",
        "    #print('7')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #print('8')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    print(type(LambdatZtZLambdaplusI[:,P_np,:][:,:,P_np]))\n",
        "    print(LambdatZtZLambdaplusI[:,P_np,:][:,:,P_np].shape)\n",
        "    L = np.linalg.cholesky(LambdatZtZLambdaplusI[:,P_np,:][:,:,P_np])\n",
        "    Cu = np.linalg.solve(L,LambdatZtYP)\n",
        "    RZX = np.linalg.solve(L,LambdatZtXP)\n",
        "    \n",
        "    #for i in np.arange(Lambda.shape[0]):\n",
        "      #print(i)\n",
        "      \n",
        "      # Perform sparse cholesky on lambda'Z'Zlambda + I\n",
        "      #print(type(LambdatZtZLambdaplusI[i,:,:]))\n",
        "      #chol_dict = sparse_chol(cvxopt.sparse(matrix(LambdatZtZLambdaplusI[i,:,:])), perm=P, retF=True, retP=False, retL=False)\n",
        "      #F = chol_dict['F']\n",
        "      \n",
        "      # Obtain Cu\n",
        "      #Cu_tmp = matrix(LambdatZtYP[i,:,:])\n",
        "      #cholmod.solve(F,Cu_tmp,sys=4)\n",
        "      \n",
        "      # Save Cu\n",
        "      #Cu[i,:,:] = np.array(Cu_tmp)\n",
        "      \n",
        "      # Obtain RZX\n",
        "      #RZXtmp = matrix(LambdatZtXP[i,:,:])\n",
        "      #cholmod.solve(F,RZXtmp,sys=4)\n",
        "      \n",
        "      # Save RZX\n",
        "      #RZX[i,:,:] = np.array(RZXtmp)\n",
        "    \n",
        "      # Obtain L (for later - note: has to be done last as this changes F)\n",
        "      #Ltmp=cholmod.getfactor(F)\n",
        "      #L[i,:,:] = np.array(matrix(Ltmp))\n",
        "      \n",
        "      \n",
        "      \n",
        "      #if i == 10:\n",
        "        \n",
        "      #  print(ZtZ.shape)\n",
        "      #  print(ZtZ_ov.size)\n",
        "      #  I_ov = spmatrix(1.0, range(ZtZ_ov.size[1]), range(ZtZ_ov.size[1]))\n",
        "\n",
        "      #  print(type(LambdatZtZLambda_ov+I_ov))\n",
        "      #  print((LambdatZtZLambda_ov+I_ov).size)\n",
        "      #  chol_dict_ov = sparse_chol(LambdatZtZLambda_ov+I_ov, perm=P, retF=True, retP=False, retL=False)\n",
        "      #  F_ov = chol_dict_ov['F']\n",
        "        \n",
        "      #  Cu_ov = LambdatZtY_ov[P,:]\n",
        "      #  cholmod.solve(F_ov,Cu_ov,sys=4)\n",
        "        \n",
        "      #  print('Cu check')\n",
        "      #  print(Cu[10,:,:]-Cu_ov)\n",
        "        \n",
        "      #  RZX_ov = LambdatZtX_ov[P,:]\n",
        "      #  cholmod.solve(F_ov,RZX_ov,sys=4)\n",
        "        \n",
        "      #  print('RZX check')\n",
        "      #  print(RZX[10,:,:]-RZX_ov)\n",
        "        \n",
        "    \n",
        "    #print('9')# Shockingly fast - 23.156267166137695\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "      \n",
        "    # Obtain RXtRX\n",
        "    RXtRX = XtX - np.matmul(RZX.transpose(0,2,1),RZX)\n",
        "    \n",
        "    \n",
        "    #RXtRX_ov = XtX_ov - matrix.trans(RZX_ov)*RZX_ov\n",
        "\n",
        "    #print('RXtRX check')\n",
        "    #print(RXtRX_ov-RXtRX[10,:,:])\n",
        "    \n",
        "    # Obtain beta estimates \n",
        "    XtYminusRZXtCu = XtY - np.matmul(RZX.transpose(0,2,1),Cu)\n",
        "    \n",
        "    #XtYminusRZXtCu_ov = XtY_ov - matrix.trans(RZX_ov)*Cu_ov\n",
        "    \n",
        "    #print('XtY - RZXtCu check')\n",
        "    #print(XtYminusRZXtCu_ov - XtYminusRZXtCu[10,:,:])\n",
        "    \n",
        "    #Get betahat\n",
        "    betahat = np.linalg.solve(RXtRX, XtYminusRZXtCu)\n",
        "    \n",
        "    \n",
        "    #betahat_ov = XtY_ov - matrix.trans(RZX_ov)*Cu_ov\n",
        "    #lapack.posv(RXtRX_ov, betahat_ov)\n",
        "    \n",
        "    #print('betahat check')\n",
        "    #print(betahat_ov-betahat[10,:,:])\n",
        "    \n",
        "    #print('10') #5s\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain L\n",
        "    # Obtain RXtRX\n",
        "    \n",
        "    \n",
        "    #print('11')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain u estimates\n",
        "    CuminusRZXbetahat = Cu - np.matmul(RZX, betahat)\n",
        "    \n",
        "    #Get betahat\n",
        "    uhat = np.linalg.solve(L.transpose(0,2,1), CuminusRZXbetahat)\n",
        "    \n",
        "    \n",
        "    #uhat_ov = Cu_ov-RZX_ov*betahat_ov\n",
        "    #cholmod.solve(F_ov,uhat_ov,sys=5)\n",
        "    #cholmod.solve(F_ov,uhat_ov,sys=8)\n",
        "    \n",
        "    #print('12')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #print(L.shape)\n",
        "    #print(CuminusRZXbetahat.shape)\n",
        "    #print(uhat.shape)\n",
        "    \n",
        "    # Permute U from the left to make the correct uhat\n",
        "    invP_np = np.arange(len(P_np))[np.argsort(P_np)]\n",
        "    uhat = uhat[:,invP_np,:]\n",
        "\n",
        "    #print('uhat check')\n",
        "    #print(uhat_ov - uhat[10,:,:])\n",
        "    \n",
        "    # Obtain b estimates\n",
        "    #print(Lambda.shape)\n",
        "    #print(uhat.shape)\n",
        "    bhat = np.matmul(Lambda,uhat)\n",
        "\n",
        "    #bhat_ov = Lambda_ov*uhat_ov\n",
        "    #print('bhat check')\n",
        "    #print(bhat_ov-bhat[10,:,:])\n",
        "    \n",
        "    # Obtain residuals sum of squares\n",
        "    resss = YtY-2*np.matmul(YtX,betahat)-2*np.matmul(YtZ,bhat)+2*np.matmul(np.matmul(betahat.transpose(0,2,1),XtZ),bhat)+np.matmul(betahat.transpose(0,2,1),np.matmul(XtX,betahat))+np.matmul(bhat.transpose(0,2,1),np.matmul(ZtZ,bhat))\n",
        "\n",
        "    #resss_ov = YtY_ov-2*YtX_ov*betahat_ov-2*YtZ_ov*bhat_ov+2*matrix.trans(betahat_ov)*XtZ_ov*bhat_ov+matrix.trans(betahat_ov)*XtX_ov*betahat_ov+matrix.trans(bhat_ov)*ZtZ_ov*bhat_ov\n",
        "   \n",
        "    #print('resss check')\n",
        "    #print(resss[10,:,:]-resss_ov)\n",
        "    \n",
        "    # Obtain penalised residual sum of squares\n",
        "    pss = resss + np.matmul(uhat.transpose(0,2,1),uhat)\n",
        "    #pss_ov = resss_ov + matrix.trans(uhat_ov)*uhat_ov\n",
        "\n",
        "    #print('pss check')\n",
        "    #print(pss[10,:,:]-pss_ov)\n",
        "    \n",
        "    #print('13')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain Log(|L|^2)\n",
        "    #logdet = 2*da.trace(da.log(L))\n",
        "    #tmp = np.log(np.diagonal(L,axis1=1,axis2=2))\n",
        "    #print(tmp.shape)\n",
        "    #print(np.sum(tmp).shape)\n",
        "    #print(np.sum(tmp, axis=0).shape)\n",
        "    #print(np.sum(tmp, axis=1).shape)\n",
        "    #print(2*np.sum(np.log(np.diagonal(L,axis1=1,axis2=2)),axis=1).shape)\n",
        "    logdet = 2*np.sum(np.log(np.diagonal(L,axis1=1,axis2=2)),axis=1).reshape((nv,1,1))\n",
        "    #logdet_ov = 2*sum(cvxopt.log(cholmod.diag(F_ov)))\n",
        "    #print(logdet)\n",
        "    #print(logdet.shape)\n",
        "    #print('logdet check')\n",
        "    #print(logdet[10]-logdet_ov)\n",
        "    \n",
        "    #print('14')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    # Obtain log likelihood\n",
        "    logllh = -logdet/2-n/2*(1+np.log(2*np.pi*pss)-np.log(n))\n",
        "\n",
        "    #print('15')\n",
        "    #print(time.time()-t1)\n",
        "    #t1 = time.time()\n",
        "    \n",
        "    #return(np.amax(-logllh))\n",
        "\n",
        "    return(-logllh)\n",
        "  \n",
        "# Make the initial theta estimate\n",
        "theta0 = init_theta(nv,nparams)\n",
        "\n",
        "# Obtain the mapping indices\n",
        "tinds, rinds, cinds, cinds_permuted, vinds = get_3D_mapping(nlevels, nparams, nv, P)\n",
        "\n",
        "t1 = time.time()\n",
        "llhmap = PLS_broadcasted3(theta0, ZtX, ZtY, XtX, ZtZ, XtY, YtX, YtZ, XtZ, YtY, P, n, tinds, rinds, cinds, cinds_permuted, vinds)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print((t2-t1)*100*100*100/(nv*60*60))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "invP\n",
            "<class 'numpy.ndarray'>\n",
            "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31]\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "running_it\n",
            "<class 'numpy.ndarray'>\n",
            "(27000, 32, 32)\n",
            "46.46030616760254\n",
            "0.47798668896710433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5piUAH8ckqKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "814c0f25-f927-4b71-9736-3c1815df517b"
      },
      "source": [
        "print(llhmap.shape)\n",
        "llhmap_imageformat = llhmap.reshape((dimv[0],dimv[1],dimv[2]))\n",
        "\n",
        "imshow(llhmap_imageformat[1,:,:].reshape(dimv[0],dimv[1]), \\\n",
        "                    interpolation='nearest', aspect='auto')\n",
        "\n",
        "plt.colorbar()\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27000, 1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9fb8293d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD5CAYAAADlasS5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR2epLIRi95N",
        "colab_type": "text"
      },
      "source": [
        "### Idea 4: Large sparse diagonals\n",
        "\n",
        "Below is a brief concept check... it didn't work consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZNddOmJi-OX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concept check\n",
        "LamtZtZLam2 = LamtZtZLam\n",
        "t1 = time.time()\n",
        "for i in np.arange(100):\n",
        "  LamtZtZLam2 = cvxopt.spdiag([LamtZtZLam2,LamtZtZLam])\n",
        "f=sparse_chol(LamtZtZLam2)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "for i in np.arange(101):\n",
        "  f=sparse_chol(LamtZtZLam)\n",
        "t2 = time.time()\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCNtb5-TdAal",
        "colab_type": "text"
      },
      "source": [
        "### Idea 5: Smooth between iterations\n",
        "\n",
        "This idea is relatively simple. Specify a number of smoothing steps, say 10 and, at regular intervals between 1 and \"tol\" stop the iteration, smooth the estimates and then continue. This is inspired by the observation in idea 2 that reusing estimates between voxels did have some limited positive effect on time efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXkSM5mmc_gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize temporary X'X, X'Z, Z'X and Z'Z\n",
        "XtZtmp = matrix(XtZ[0,:,:])\n",
        "ZtXtmp = matrix(ZtX[0,:,:])\n",
        "ZtZtmp = cvxopt.sparse(matrix(ZtZ[0,:,:]))\n",
        "XtXtmp = matrix(XtX[0,:,:])\n",
        "\n",
        "# Initial theta value. Bates (2005) suggests using [vech(I_q1),...,vech(I_qr)] where I is the identity matrix\n",
        "theta0 = np.array([])\n",
        "for i in np.arange(r):\n",
        "  theta0 = np.hstack((theta0, mat2vech(np.eye(nparams[i])).reshape(np.int64(nparams[i]*(nparams[i]+1)/2))))\n",
        "\n",
        "# Initialize empty estimates\n",
        "beta_est = np.zeros(beta.shape)\n",
        "theta_est_3D = np.zeros((beta.shape[0], theta0.shape[0]))\n",
        "\n",
        "# Obtain a random Lambda matrix with the correct sparsity for the permutation vector\n",
        "tinds,rinds,cinds=get_mapping(nlevels, nparams)\n",
        "Lam=mapping(np.random.randn(theta0.shape[0]),tinds,rinds,cinds)\n",
        "\n",
        "# Obtain Lambda'Z'ZLambda\n",
        "LamtZtZLam = spmatrix.trans(Lam)*cvxopt.sparse(matrix(ZtZtmp))*Lam\n",
        "\n",
        "\n",
        "# Identity (Actually quicker to calculate outside of estimation)\n",
        "I = spmatrix(1.0, range(Lam.size[0]), range(Lam.size[0]))\n",
        "\n",
        "# Obtaining permutation for PLS\n",
        "P=cvxopt.amd.order(LamtZtZLam)\n",
        "\n",
        "tolArray = np.array([1e-2,1e-4,1e-6])\n",
        "\n",
        "for tolVal in tolArray:\n",
        "  \n",
        "  t1 = time.time()\n",
        "  for i in np.arange(nv):\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    XtYtmp = matrix(XtY[i,:,:]) \n",
        "    ZtYtmp = matrix(ZtY[i,:,:]) \n",
        "    YtYtmp = matrix(YtY[i,:,:]) \n",
        "    YtZtmp = matrix(YtZ[i,:,:])\n",
        "    YtXtmp = matrix(YtX[i,:,:])\n",
        "\n",
        "    if tolVal==tolArray[0]:\n",
        "      theta_est = minimize(PLS, theta0, args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=tolVal)\n",
        "    else:\n",
        "      theta_est = minimize(PLS, theta_est_3D[i,:], args=(ZtXtmp, ZtYtmp, XtXtmp, ZtZtmp, XtYtmp, YtXtmp, YtZtmp, XtZtmp, YtYtmp, n, P, I, tinds, rinds, cinds), method='L-BFGS-B', tol=tolVal)\n",
        "      \n",
        "    nit = theta_est.nit\n",
        "    theta_est_3D[i,:] = theta_est.x\n",
        "    print(nit)\n",
        "\n",
        "  t2 = time.time()\n",
        "  print(\"Time taken in seconds for this tol:\" + str(tolVal))\n",
        "  print(t2-t1)\n",
        "  print(\"Estimated time taken for this example on a nifti of size (100x100x100), in hours:\")\n",
        "  print(100*100*100*(t2-t1)/(nv*60*60))\n",
        "  \n",
        "  t1 = time.time()\n",
        "  \n",
        "  for j in np.arange(theta_est_3D.shape[1]):\n",
        "    \n",
        "    # Get the theta estimates for one theta parameter.\n",
        "    theta_est_us = theta_est_3D[:,j].reshape(dimv[0],dimv[1],dimv[2])\n",
        "    \n",
        "    # Some random affine, not hugely important\n",
        "    affine = np.diag([1, 1, 1, 1])\n",
        "    theta_est_us_nii = nib.Nifti1Image(theta_est_us, affine)\n",
        "\n",
        "    # Smoothed theta nifti\n",
        "    theta_est_s_nii = nilearn.image.smooth_img(theta_est_us_nii, 5)\n",
        "\n",
        "    # Final theta estimate\n",
        "    theta_est_3D[:,j] = theta_est_s_nii.get_fdata().reshape(theta_est_3D[:,j].shape)\n",
        "  \n",
        "  t2 = time.time()\n",
        "  \n",
        "  print(\"Time taken smoothing\")\n",
        "  print(t2-t1)\n",
        "  print(\"Estimated time taken for this smoothing on a nifti of size (100x100x100), in hours:\")\n",
        "  print(100*100*100*(t2-t1)/(nv*60*60))\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPT7ufJlX6jg",
        "colab_type": "text"
      },
      "source": [
        "### Sandbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54iwTXilX6CV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cvxopt.amd\n",
        "import cvxopt\n",
        "from cvxopt import cholmod\n",
        "import numpy as np\n",
        "import dask.array as da\n",
        "import dask\n",
        "import time\n",
        "import sparse\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ[\"SPARSE_AUTO_DENSIFY\"] = \"1\"\n",
        "runningnptime=np.zeros(1000)\n",
        "runningsptime=np.zeros(1000)\n",
        "runningdatime=np.zeros(1000)\n",
        "runningdaptime=np.zeros(1000)\n",
        "runningcvxtime=np.zeros(1000)\n",
        "runningcvxptime=np.zeros(1000)\n",
        "\n",
        "dask.config.set({'array.chunk-size':'20MiB'})\n",
        "for n in np.arange(800,1000):\n",
        "  for i in np.arange(1):\n",
        "    print(n)\n",
        "    print(i)\n",
        "    X = np.random.randn(n+1,n+1)\n",
        "    X[X<1.7]=0\n",
        "    X = X + np.eye(n+1)\n",
        "\n",
        "    XtX = np.matmul(X.transpose(), X)\n",
        "\n",
        "    XtX_tf = tf.constant(XtX)\n",
        "\n",
        "    XtX_cvxopt = cvxopt.sparse(cvxopt.matrix(XtX))\n",
        "    P = cvxopt.amd.order(XtX_cvxopt)\n",
        "\n",
        "    P_np = np.array(P[:]).reshape(n+1)\n",
        "\n",
        "    #print(P_np)\n",
        "    # To get the permuted X from the amd ordering must do X[:,P]\n",
        "    XtX_P = np.matmul((X[:,P_np]).transpose(),X[:,P_np])\n",
        "    XtX_tf_P = tf.constant(XtX_P)\n",
        "\n",
        "    #print(X[P_np,:].shape)\n",
        "\n",
        "    XtX_P_cvxopt = XtX_cvxopt[P,P]\n",
        "\n",
        "    #print(XtX_P)\n",
        "    #print(XtX_P_cvxopt)\n",
        "\n",
        "    #print(cvxopt.sparse(cvxopt.matrix(XtX_P))-XtX_P_cvxopt)\n",
        "\n",
        "\n",
        "    F=sparse_chol(XtX_cvxopt, perm=None, retF=False, retP=True, retL=True)\n",
        "\n",
        "    L_cvxopt_spchol = F['L']\n",
        "\n",
        "    #print(L_cvxopt_spchol*spmatrix.trans(L_cvxopt_spchol)-cvxopt.sparse(cvxopt.matrix(XtX_P)))\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_np_chol = np.linalg.cholesky(XtX)\n",
        "    t2 = time.time()\n",
        "    nptime=t2-t1\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_np_spchol = np.linalg.cholesky(XtX_P)\n",
        "    t2 = time.time()\n",
        "    sptime=t2-t1\n",
        "\n",
        "    XtX_da = da.from_array(XtX, chunks=\"auto\").map_blocks(sparse.COO)\n",
        "    XtX_da_P = da.from_array(XtX_P, chunks=\"auto\").map_blocks(sparse.COO)\n",
        "    print(XtX_da.chunks)\n",
        "\n",
        "    #da.map_blocks()\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_dap_chol = da.linalg.cholesky(XtX_da_P).compute()\n",
        "    t2 = time.time()\n",
        "    daptime=t2-t1\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_da_chol = da.linalg.cholesky(XtX_da).compute()\n",
        "    t2 = time.time()\n",
        "    datime=t2-t1\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_cvxp_chol = sparse_chol(XtX_P_cvxopt, perm=None, retF=False, retP=False, retL=True)\n",
        "    t2 = time.time()\n",
        "    cvxptime=t2-t1\n",
        "\n",
        "    t1 = time.time()\n",
        "    L_cvx_chol = sparse_chol(XtX_cvxopt, perm=None, retF=False, retP=False, retL=True)\n",
        "    t2 = time.time()\n",
        "    cvxtime=t2-t1\n",
        "\n",
        "    runningnptime[n] = runningnptime[n] + nptime\n",
        "    runningsptime[n] = runningsptime[n] + sptime\n",
        "    runningdatime[n] = runningdatime[n] + datime\n",
        "    runningdaptime[n] = runningdaptime[n] + daptime\n",
        "    runningcvxtime[n] = runningcvxtime[n] + cvxtime\n",
        "    runningcvxptime[n] = runningcvxptime[n] + cvxptime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYNnmvll3BEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#print(runningdatime)\n",
        "#print(runningdaptime)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.scatter(np.arange(800,1000),runningdatime[800:1000], marker=\"x\", label='Dask array without amd')\n",
        "ax1.scatter(np.arange(800,1000),runningdaptime[800:1000], marker=\"x\", label='Dask array with amd')\n",
        "ax1.scatter(np.arange(800,1000),runningcvxtime[800:1000], marker=\"x\", label='Cvxopt array without amd')\n",
        "ax1.scatter(np.arange(800,1000),runningcvxptime[800:1000], marker=\"x\", label='Cvxopt array with amd')\n",
        "ax1.scatter(np.arange(800,1000),runningnptime[800:1000], marker=\"x\", label='Numpy array without amd')\n",
        "ax1.scatter(np.arange(800,1000),runningsptime[800:1000], marker=\"x\", label='Numpy array with amd')\n",
        "plt.legend(loc='upper left');\n",
        "plt.ylim(-0.002, 0.1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFOXArMV0NX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.random.randn(10,10)\n",
        "X[X<1.7]=0\n",
        "X = X + np.eye(10)\n",
        "\n",
        "XtX = np.matmul(X.transpose(), X)\n",
        "\n",
        "XtX_cvxopt = cvxopt.sparse(cvxopt.matrix(XtX))\n",
        "P = cvxopt.amd.order(XtX_cvxopt)\n",
        "print(P)\n",
        "\n",
        "print(XtX_cvxopt.J)\n",
        "XtX_permuted = XtX[:,np.array(P[:]).reshape(P.size[0])]\n",
        "print(XtX_permuted.shape)\n",
        "XtX_permuted = scipy.sparse.csr_matrix(XtX_permuted)\n",
        "\n",
        "rowinds = XtX_cvxopt.I\n",
        "colinds = XtX_cvxopt.J\n",
        "data = XtX_cvxopt.V\n",
        "\n",
        "P = np.array(P[:]).reshape(P.size[0])\n",
        "invP = np.arange(len(P))[np.argsort(P)]\n",
        "print(invP)\n",
        "colinds_perm = invP[XtX_cvxopt.J]\n",
        "\n",
        "print(np.array(data[:]).shape)\n",
        "print(np.array(rowinds[:]).shape)\n",
        "print(np.array(colinds_perm[:]).shape)\n",
        "\n",
        "rowinds = np.array(rowinds[:])\n",
        "colinds_perm = np.array(colinds_perm[:])\n",
        "data = np.array(data[:])\n",
        "\n",
        "rowinds = rowinds.reshape(rowinds.shape[0])\n",
        "colinds_perm = colinds_perm.reshape(colinds_perm.shape[0])\n",
        "data = data.reshape(data.shape[0])\n",
        "\n",
        "XtX_permuted2 = scipy.sparse.csr_matrix((data, (rowinds, colinds_perm)))\n",
        "\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "\n",
        "print(XtX_permuted.toarray()-XtX_permuted2.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn8aEz01u2mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(XtX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWHKvosvWY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numba\n",
        "import cvxopt\n",
        "from cvxopt import cholmod\n",
        "from cvxopt import sparse\n",
        "from cvxopt import matrix\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@numba.jit(forceobj=True, parallel=True)\n",
        "def multicvxopt(XtX):\n",
        "  \n",
        "  np.linalg.cholesky(XtX)\n",
        "    \n",
        "    \n",
        "def spcholblock(XtX):\n",
        "  \n",
        "  tmp = LambdatZtZLambda[i,:,:].compute()\n",
        "  data = tmp.data\n",
        "  coords = tmp.coords\n",
        "  chol_dict = sparse_chol(spmatrix(data, coords[0,:],coords[1,:],size=(Lambda.shape[1],Lambda.shape[1]))+I, perm=P, retF=True, retP=False, retL=False)\n",
        "  \n",
        "#dask.array.map_blocks()\n",
        "\n",
        "XtX = np.zeros((1,1000,1000))\n",
        "for i in np.arange(1):\n",
        "    X = np.random.randn(1000,1000)\n",
        "    X[X<1.7]=0\n",
        "    X = X + np.eye(1000)\n",
        "\n",
        "    XtXi = np.matmul(X.transpose(), X)\n",
        "\n",
        "    XtX[i,:,:] = XtXi\n",
        "    \n",
        "t1 = time.time()\n",
        "multicvxopt(XtX)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "multicvxopt(XtX)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "for i in np.arange(XtX.shape[0]):\n",
        "\n",
        "  XtXi=cvxopt.sparse(cvxopt.matrix(XtX[i,:,:]))\n",
        "  \n",
        "  t1 = time.time()\n",
        "  F=cholmod.symbolic(XtXi)\n",
        "  cholmod.numeric(XtXi, F)\n",
        "  L=cholmod.getfactor(F)\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)\n",
        "  \n",
        "t2 = time.time()\n",
        "print(t2-t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-oH5gUphhJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparse import COO\n",
        "import sparse\n",
        "\n",
        "def GaxCholBC2(XtX):\n",
        "  \n",
        "  print(XtX)\n",
        "  \n",
        "  for i in np.arange(XtX.shape[0]):\n",
        "    \n",
        "    print(i)\n",
        "    \n",
        "    for j in np.arange(XtX.shape[1]):\n",
        "      \n",
        "      print(j)\n",
        "\n",
        "      if j > 0:\n",
        "        \n",
        "        FirstProd = XtX[i,j:,:j]\n",
        "        SecondProd = XtX[i,:j,j]\n",
        "          \n",
        "        XtX[i,j:,j] = XtX[i,j:,j] - sparse.matmul(FirstProd,SecondProd)\n",
        "\n",
        "      XtX[i,j:,j] = XtX[i,j:,j]/np.sqrt(XtX[i,j,j])\n",
        "\n",
        "  return(A)\n",
        "\n",
        "XtX = np.zeros((10000,50,50))\n",
        "for i in np.arange(10000):\n",
        "  X = np.random.randn(50,50)\n",
        "  X[X<1.7]=0\n",
        "  X = X + np.eye(50)\n",
        "\n",
        "  XtXi = np.matmul(X.transpose(), X)\n",
        "\n",
        "  XtX[i,:,:] = XtXi\n",
        "  \n",
        "XtX = sparse.COO.from_numpy(XtX)\n",
        "\n",
        "GaxCholBC2(XtX)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}